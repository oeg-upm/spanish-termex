{
    "id": "J-37",
    "original_text": "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games. To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation. For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game. We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively. Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree. It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree. Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously. We discuss several electronic commerce applications for GameShrink. To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies. Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics. General Terms: Algorithms, Economics, Theory. 1. INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s). Consequently, the optimal action of one agent can depend on the others. Game theory provides a normative framework for analyzing such strategic situations. In particular, it provides solution concepts that define what rational behavior is in such settings. The most famous and important solution concept is that of Nash equilibrium [36]. It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy. However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium. Games can be classified as either games of perfect information or imperfect information. Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type. To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes. If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed). Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world. In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time. Thus the algorithms for perfect information games do not solve games of imperfect information. For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52]. By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables. Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation. Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game. Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game. The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game. To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes. Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives. They are used in our analysis and abstraction algorithm. By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding. We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3). As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8]. The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44]. For a survey of equilibrium computation in 2-player games, see [53]. Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43]. For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35]. Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ. Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ). If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF . The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule. We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game. We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4). Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree. It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree. We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions. Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game. On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification. However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely. Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game. Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation. One broad application area that has this property is sequential negotiation (potentially over multiple issues). Another broad application area is sequential auctions (potentially over multiple goods). For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation. Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities). Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42]. Our techniques are in no way specific to an application. The main experiment that we present in this paper is on 161 a recreational game. We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world. The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event. Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments. Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5]. Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219]. However, this work was limited to tiny games that could be solved by hand. More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games. Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25]. Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies. Furthermore, the approximations were designed manually by a human expert. Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance. Rhode Island Holdem was invented as a testbed for computational game playing [47]. It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].) We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes. Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns. This is much too large for (current) linear programming algorithms to handle. We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients. We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.) GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations). Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2. We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html. While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before. This is the largest poker game solved to date by over four orders of magnitude. 2. GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form. This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations. A game with ordered signals consists of a finite number of rounds. Within a round, the players play a game on a directed tree (the tree can be different in different rounds). The only uncertainty players face stems from private signals the other players have received and from the unknown future signals. In other words, players observe each others actions, but potentially not natures actions. In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players). For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed). We also assume that the legal actions that a player has are independent of the signals received. For example, in poker, the legal betting actions are independent of the cards received. Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals. For example, in poker, this partial ordering corresponds exactly to the ranking of card hands. Definition 1. A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1. I = {1, . . . , n} is a finite set of players. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej . Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j . Gj is the stage game for round j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4. Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j. Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|. The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ . The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ . We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i . The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ. Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round. Clearly, we require ω(z) = over for all z ∈ Zr . Note that ω is independent of the signals. Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games. Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player. By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact. We will use this when designing our abstraction techniques. Formally, an information filter is as follows. Definition 2. Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game. Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j. An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl . We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF . We refer to such games as filtered ordered games. We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o . We have the following simple (but important) result: Proposition 1. A filtered ordered game is an extensive form game satisfying perfect recall. A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall. In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games. Definition 3. A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.) A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i. A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ . A strategy profile is σ = (σ1, . . . , σn). A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ. Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i. A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29]. Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1. For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3. EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games. We begin by defining a filtered signal tree which represents all of the chance moves in the game. The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game. Definition 4. Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals. The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time. The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk . We denote children of a node x as N(x). In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached. In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game. By melding these situations together, it is possible to arrive at a strategically equivalent smaller game. The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation. Definition 5. Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic. Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ). Definition 6. Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ. Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j. The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ . Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game. Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster. Theorem 2. Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ. Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation. Let σ be a Nash equilibrium of the induced game ΓF . If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF . Proof. For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF . Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium. Fix some player i ∈ I. Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj . Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set. Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z . Each node in an information set corresponds to the possible private signals the other players have received. Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated. Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .) We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game. Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player. Open circles are chance nodes with the indicated transition probabilities. The root node is the chance node for player 1s card, and the next level is for player 2s card. The payment from player 2 to player 1 is given below each leaf. In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . The following three claims show that μ as calculated above supports σ as a Nash equilibrium. Claim 1. μ is a valid belief system for ΓF . Claim 2. For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3. For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ. The proofs of Claims 1-3 are in an extended version of this paper [13]. By Claims 1 and 2, we know that condition C2 holds. By Claim 3, we know that condition C1 holds. Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals. In this subsection we show that removing either of these conditions can make our technique invalid. First, we demonstrate a failure when removing the first assumption. Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties. By merging the subtrees beginning at a and b, we get the game on the right in Figure 2. In this game, player 1s only Nash equilibrium strategy is to play left. But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games. Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure. Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1. It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4. GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions. It only needs to analyze the signal tree discussed above, rather than the entire game tree. We first present a subroutine that GameShrink uses. It is a dynamic program for computing the ordered game isomorphic relation. Again, it operates on the signal tree. Algorithm 1. OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1. If ϑ and ϑ have different parents, then return false. 2. If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3. Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4. For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5. Return true if Gϑ,ϑ has a perfect matching; otherwise, return false. By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic. We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic. The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game. Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals). Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time. Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table). The number of nodes, n, in the signal tree is O(|Θ|S ). The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine. So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation. While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree. The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.) The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S ! S! which is a lower bound on the number of nodes. For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S ! S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ). Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree. The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.) See Figure 1. In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree. For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705. Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink. Algorithm 2. GameShrink (Γ) 1. Initialize F to be the identity filter for Γ. 2. For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic?(Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3. Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible. Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2. Thus, we have the following result: Theorem 3. GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations. Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium. The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop. There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game. Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times. As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly). Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« . By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree. Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation. One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49]. Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set. Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure. This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree. Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching. We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold. One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents. We can precompute these frequencies for every game tree node. This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section). The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry. This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) We store the histograms in a 2-dimensional database. The first dimension is indexed by the private signals, the second by the public signals. The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ . We efficiently compute this using the subsets colexicographical ordering [6]. Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1. We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5. APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique. This section discusses general techniques for computing approximately optimal strategy profiles. For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy. To illustrate this, suppose we know player 2s planned strategy for some game. We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves. Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node. Thus, we can objectively determine the expected worst-case performance of player 2s strategy. This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.) This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2. Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases. There are many ways in which the penalty function could be defined and implemented. One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold). Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions). This knob also begets an anytime algorithm. One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method. This approach has inherent features which we can leverage into desirable properties in the context of solving games. In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1. There are two versions of the simplex method: the primal simplex and the dual simplex. The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached. Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.) Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively. At any point in time, they can output the best strategies found so far. Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.) Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57]. Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent. One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.) In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution. For example, many interiorpoint path-following algorithms have this property [55, Ch. 5]. We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating). A threshold on can also be used as a termination criterion for using the method as an anytime algorithm. Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6. RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11]. In contrast to our work, those approaches were not for making the game smaller and easier to solve. The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form. The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27]. An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21]. Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10]. The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism. The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations. Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms. However, that definition requires that the games to be tested for weak isomorphism are of the same size. Our focus is totally different: we find strategically equivalent smaller games. Also, their paper does not provide algorithms. Abstraction techniques have been used in artificial intelligence research before. In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]). Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions. A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2]. However, a significant difference to our work is that Sprouts is a game of perfect information. One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18]. In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.) Partition search can lead to substantial speed improvements over α-β-search. However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically. There has been some research on the use of abstraction for imperfect information games. Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players. However, this approach has significant drawbacks. First, it is highly specialized for Texas Holdem. Second, a large amount of expert knowledge and effort was used in constructing the abstraction. Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium. Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7. CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively. We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game. The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree. It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either. Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge. There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48]. Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree. Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously. To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction. We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality. The method also yields bounds on the suboptimality of the resulting strategies. We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes. That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8. REFERENCES [1] W. Ackermann. Zum Hilbertschen Aufbau der reellen Zahlen. Math. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator. Computer analysis of sprouts. Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell. Some two-person games involving bluffing. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron. Approximating game-theoretic optimal strategies for full-scale poker. In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron. The challenge of poker. Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as. Combinatorics. Cambridge University Press, 1986. [7] A. Casajus. Weak isomorphism of extensive games. Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng. Settling the complexity of 2-player Nash equilibrium. ECCC, Report No. 150, 2005. [9] V. Chv´atal. Linear Programming. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. Game transformations and game equivalence. Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny. On the strategic equivalence of extensive form games. J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson. Flows in Networks. Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm. Finding equilibria in large sequential games of imperfect information. Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm. Optimal Rhode Island Holdem poker. In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm. A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation. Mimeo, 2006. [16] A. Gilpin and T. Sandholm. A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation. In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg. Partition search. In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg. GIB: Steps toward an expert-level bridge-playing program. In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson. A global Newton method to compute Nash equilibria. J. of Econ. Theory, 110:65-86, 2003. [20] C. A. Knoblock. Automatically generating abstractions for planning. Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens. On the strategic stability of equilibria. Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo. The complexity of two-person zero-sum games in extensive form. Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo. Finding mixed strategies with small supports in extensive form games. International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel. Efficient computation of equilibria for extensive two-person games. Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer. Representations and solutions for game-theoretic problems. Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson. Sequential equilibria. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Extensive games. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. A simplified two-person poker. In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103. Princeton University Press, 1950. [29] H. W. Kuhn. Extensive games and the problem of information. In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216. Princeton University Press, 1953. [30] C. Lemke and J. Howson. Equilibrium points of bimatrix games. Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta. Playing large games using simple strategies. In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman. On state-space abstraction for anytime evaluation of Bayesian networks. SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green. Microeconomic Theory. Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan. Computation of equilibria in finite games. In Handbook of Computational Economics, volume 1, pages 87-142. Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen. Computing sequential equilibria for two-player games. In SODA, pages 107-116, 2006. [36] J. Nash. Equilibrium points in n-person games. Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley. A simple three-person poker game. In Contributions to the Theory of Games, volume 1, pages 105-116. Princeton University Press, 1950. [38] A. Perea. Rationality in extensive form games. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa. State-space approximations for extensive form games, July 2000. Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham. Simple search methods for finding a Nash equilibrium. In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii. Reduction of a game with complete memory to a matrix game. Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin. Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation. In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer. Mixed-integer programming methods for finding Nash equilibria. In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel. Exponentially many steps for finding a Nash equilibrium in a bimatrix game. In FOCS, pages 258-267, 2004. [45] R. Selten. Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit. Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten. Evolutionary stability in extensive two-person games - correction and further development. Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman. Abstraction methods for game theoretic poker. In Computers and Games, pages 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop. Computer bridge: A big win for AI planning. AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan. Efficiency of a good but not linear set union algorithm. Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalence of games in extensive form. RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern. Theory of games and economic behavior. Princeton University Press, 1947. [52] B. von Stengel. Efficient computation of behavior strategies. Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel. Computing equilibria for two-person games. In Handbook of Game Theory, volume 3. North Holland, Amsterdam, 2002. [54] R. Wilson. Computing equilibria of two-person games from the extensive form. Management Science, 18(7):448-460, 1972. [55] S. J. Wright. Primal-Dual Interior-Point Methods. SIAM, 1997. 169",
    "original_translation": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169",
    "original_sentences": [
        "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
        "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
        "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
        "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
        "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
        "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
        "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
        "We discuss several electronic commerce applications for GameShrink.",
        "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
        "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
        "General Terms: Algorithms, Economics, Theory. 1.",
        "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
        "Consequently, the optimal action of one agent can depend on the others.",
        "Game theory provides a normative framework for analyzing such strategic situations.",
        "In particular, it provides solution concepts that define what rational behavior is in such settings.",
        "The most famous and important solution concept is that of Nash equilibrium [36].",
        "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
        "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
        "Games can be classified as either games of perfect information or imperfect information.",
        "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
        "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
        "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
        "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
        "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
        "Thus the algorithms for perfect information games do not solve games of imperfect information.",
        "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
        "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
        "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
        "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
        "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
        "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
        "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
        "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
        "They are used in our analysis and abstraction algorithm.",
        "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
        "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
        "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
        "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
        "For a survey of equilibrium computation in 2-player games, see [53].",
        "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
        "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
        "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
        "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
        "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
        "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
        "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
        "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
        "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
        "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
        "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
        "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
        "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
        "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
        "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
        "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
        "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
        "Another broad application area is sequential auctions (potentially over multiple goods).",
        "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
        "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
        "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
        "Our techniques are in no way specific to an application.",
        "The main experiment that we present in this paper is on 161 a recreational game.",
        "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
        "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
        "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
        "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
        "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
        "However, this work was limited to tiny games that could be solved by hand.",
        "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
        "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
        "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
        "Furthermore, the approximations were designed manually by a human expert.",
        "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
        "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
        "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
        "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
        "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
        "This is much too large for (current) linear programming algorithms to handle.",
        "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
        "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
        "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
        "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
        "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
        "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
        "This is the largest poker game solved to date by over four orders of magnitude. 2.",
        "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
        "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
        "A game with ordered signals consists of a finite number of rounds.",
        "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
        "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
        "In other words, players observe each others actions, but potentially not natures actions.",
        "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
        "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
        "We also assume that the legal actions that a player has are independent of the signals received.",
        "For example, in poker, the legal betting actions are independent of the cards received.",
        "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
        "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
        "Definition 1.",
        "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
        "I = {1, . . . , n} is a finite set of players. 2.",
        "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
        "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
        "Gj is the stage game for round j. 3.",
        "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
        "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
        "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
        "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
        "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
        "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
        "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
        "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
        "Clearly, we require ω(z) = over for all z ∈ Zr .",
        "Note that ω is independent of the signals.",
        "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
        "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
        "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
        "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
        "We will use this when designing our abstraction techniques.",
        "Formally, an information filter is as follows.",
        "Definition 2.",
        "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
        "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
        "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
        "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
        "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
        "We refer to such games as filtered ordered games.",
        "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
        "We have the following simple (but important) result: Proposition 1.",
        "A filtered ordered game is an extensive form game satisfying perfect recall.",
        "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
        "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
        "Definition 3.",
        "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
        "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
        "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
        "A strategy profile is σ = (σ1, . . . , σn).",
        "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
        "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
        "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
        "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
        "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
        "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
        "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
        "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
        "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
        "Definition 4.",
        "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
        "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
        "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
        "We denote children of a node x as N(x).",
        "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
        "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
        "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
        "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
        "Definition 5.",
        "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
        "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
        "Definition 6.",
        "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
        "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
        "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
        "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
        "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
        "Theorem 2.",
        "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
        "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
        "Let σ be a Nash equilibrium of the induced game ΓF .",
        "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
        "Proof.",
        "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
        "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
        "Fix some player i ∈ I.",
        "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
        "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
        "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
        "Each node in an information set corresponds to the possible private signals the other players have received.",
        "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
        "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
        "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
        "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
        "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
        "Open circles are chance nodes with the indicated transition probabilities.",
        "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
        "The payment from player 2 to player 1 is given below each leaf.",
        "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
        "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
        "Claim 1. μ is a valid belief system for ΓF .",
        "Claim 2.",
        "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
        "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
        "The proofs of Claims 1-3 are in an extended version of this paper [13].",
        "By Claims 1 and 2, we know that condition C2 holds.",
        "By Claim 3, we know that condition C1 holds.",
        "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
        "In this subsection we show that removing either of these conditions can make our technique invalid.",
        "First, we demonstrate a failure when removing the first assumption.",
        "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
        "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
        "In this game, player 1s only Nash equilibrium strategy is to play left.",
        "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
        "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
        "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
        "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
        "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
        "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
        "We first present a subroutine that GameShrink uses.",
        "It is a dynamic program for computing the ordered game isomorphic relation.",
        "Again, it operates on the signal tree.",
        "Algorithm 1.",
        "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
        "If ϑ and ϑ have different parents, then return false. 2.",
        "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
        "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
        "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
        "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
        "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
        "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
        "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
        "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
        "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
        "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
        "The number of nodes, n, in the signal tree is O(|Θ|S ).",
        "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
        "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
        "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
        "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
        "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
        "S! which is a lower bound on the number of nodes.",
        "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
        "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
        "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
        "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
        "See Figure 1.",
        "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
        "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
        "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
        "Algorithm 2.",
        "GameShrink (Γ) 1.",
        "Initialize F to be the identity filter for Γ. 2.",
        "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
        "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
        "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
        "Thus, we have the following result: Theorem 3.",
        "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
        "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
        "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
        "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
        "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
        "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
        "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
        "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
        "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
        "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
        "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
        "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
        "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
        "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
        "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
        "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
        "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
        "We can precompute these frequencies for every game tree node.",
        "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
        "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
        "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
        "We store the histograms in a 2-dimensional database.",
        "The first dimension is indexed by the private signals, the second by the public signals.",
        "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
        "We efficiently compute this using the subsets colexicographical ordering [6].",
        "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
        "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
        "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
        "This section discusses general techniques for computing approximately optimal strategy profiles.",
        "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
        "To illustrate this, suppose we know player 2s planned strategy for some game.",
        "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
        "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
        "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
        "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
        "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
        "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
        "There are many ways in which the penalty function could be defined and implemented.",
        "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
        "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
        "This knob also begets an anytime algorithm.",
        "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
        "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
        "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
        "There are two versions of the simplex method: the primal simplex and the dual simplex.",
        "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
        "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
        "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
        "At any point in time, they can output the best strategies found so far.",
        "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
        "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
        "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
        "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
        "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
        "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
        "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
        "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
        "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
        "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
        "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
        "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
        "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
        "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
        "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
        "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
        "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
        "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
        "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
        "Our focus is totally different: we find strategically equivalent smaller games.",
        "Also, their paper does not provide algorithms.",
        "Abstraction techniques have been used in artificial intelligence research before.",
        "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
        "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
        "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
        "However, a significant difference to our work is that Sprouts is a game of perfect information.",
        "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
        "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
        "Partition search can lead to substantial speed improvements over α-β-search.",
        "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
        "There has been some research on the use of abstraction for imperfect information games.",
        "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
        "However, this approach has significant drawbacks.",
        "First, it is highly specialized for Texas Holdem.",
        "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
        "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
        "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
        "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
        "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
        "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
        "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
        "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
        "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
        "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
        "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
        "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
        "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
        "The method also yields bounds on the suboptimality of the resulting strategies.",
        "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
        "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
        "REFERENCES [1] W. Ackermann.",
        "Zum Hilbertschen Aufbau der reellen Zahlen.",
        "Math.",
        "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
        "Computer analysis of sprouts.",
        "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
        "Some two-person games involving bluffing.",
        "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
        "Approximating game-theoretic optimal strategies for full-scale poker.",
        "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
        "The challenge of poker.",
        "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
        "Combinatorics.",
        "Cambridge University Press, 1986. [7] A. Casajus.",
        "Weak isomorphism of extensive games.",
        "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
        "Settling the complexity of 2-player Nash equilibrium.",
        "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
        "Linear Programming.",
        "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
        "Game transformations and game equivalence.",
        "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
        "On the strategic equivalence of extensive form games.",
        "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
        "Flows in Networks.",
        "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
        "Finding equilibria in large sequential games of imperfect information.",
        "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
        "Optimal Rhode Island Holdem poker.",
        "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
        "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
        "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
        "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
        "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
        "Partition search.",
        "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
        "GIB: Steps toward an expert-level bridge-playing program.",
        "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
        "A global Newton method to compute Nash equilibria.",
        "J. of Econ.",
        "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
        "Automatically generating abstractions for planning.",
        "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
        "On the strategic stability of equilibria.",
        "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
        "The complexity of two-person zero-sum games in extensive form.",
        "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
        "Finding mixed strategies with small supports in extensive form games.",
        "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
        "Efficient computation of equilibria for extensive two-person games.",
        "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
        "Representations and solutions for game-theoretic problems.",
        "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
        "Sequential equilibria.",
        "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
        "Extensive games.",
        "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
        "A simplified two-person poker.",
        "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
        "Princeton University Press, 1950. [29] H. W. Kuhn.",
        "Extensive games and the problem of information.",
        "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
        "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
        "Equilibrium points of bimatrix games.",
        "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
        "Playing large games using simple strategies.",
        "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
        "On state-space abstraction for anytime evaluation of Bayesian networks.",
        "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
        "Microeconomic Theory.",
        "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
        "Computation of equilibria in finite games.",
        "In Handbook of Computational Economics, volume 1, pages 87-142.",
        "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
        "Computing sequential equilibria for two-player games.",
        "In SODA, pages 107-116, 2006. [36] J. Nash.",
        "Equilibrium points in n-person games.",
        "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
        "A simple three-person poker game.",
        "In Contributions to the Theory of Games, volume 1, pages 105-116.",
        "Princeton University Press, 1950. [38] A. Perea.",
        "Rationality in extensive form games.",
        "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
        "State-space approximations for extensive form games, July 2000.",
        "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
        "Simple search methods for finding a Nash equilibrium.",
        "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
        "Reduction of a game with complete memory to a matrix game.",
        "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
        "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
        "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
        "Mixed-integer programming methods for finding Nash equilibria.",
        "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
        "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
        "In FOCS, pages 258-267, 2004. [45] R. Selten.",
        "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
        "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
        "Evolutionary stability in extensive two-person games - correction and further development.",
        "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
        "Abstraction methods for game theoretic poker.",
        "In Computers and Games, pages 333-345.",
        "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
        "Computer bridge: A big win for AI planning.",
        "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
        "Efficiency of a good but not linear set union algorithm.",
        "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
        "Equivalence of games in extensive form.",
        "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
        "Theory of games and economic behavior.",
        "Princeton University Press, 1947. [52] B. von Stengel.",
        "Efficient computation of behavior strategies.",
        "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
        "Computing equilibria for two-person games.",
        "In Handbook of Game Theory, volume 3.",
        "North Holland, Amsterdam, 2002. [54] R. Wilson.",
        "Computing equilibria of two-person games from the extensive form.",
        "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
        "Primal-Dual Interior-Point Methods.",
        "SIAM, 1997. 169"
    ],
    "translated_text_sentences": [
        "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes.",
        "Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada.",
        "Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original.",
        "Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo.",
        "Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales.",
        "No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego.",
        "Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente.",
        "Discutimos varias aplicaciones de comercio electrónico para GameShrink.",
        "Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable.",
        "Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía.",
        "Términos generales: Algoritmos, Economía, Teoría. 1.",
        "INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s).",
        "Por consiguiente, la acción óptima de un agente puede depender de los demás.",
        "La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas.",
        "En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos.",
        "El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos.",
        "Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente.",
        "Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio.",
        "Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta.",
        "El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo.",
        "Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales.",
        "Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad).",
        "La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo.",
        "En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual.",
        "Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta.",
        "Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52].",
        "Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales.",
        "Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios.",
        "En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original.",
        "Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original.",
        "La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original.",
        "Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción.",
        "En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador.",
        "Son utilizados en nuestro algoritmo de análisis y abstracción.",
        "Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio.",
        "Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3).",
        "Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8].",
        "El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44].",
        "Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53].",
        "Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43].",
        "Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35].",
        "Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ.",
        "Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F).",
        "Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF.",
        "La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes.",
        "Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego.",
        "También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4).",
        "Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales.",
        "No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego.",
        "Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas.",
        "A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego.",
        "En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo.",
        "Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo.",
        "Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego.",
        "Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente.",
        "Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas).",
        "Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes).",
        "Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B.",
        "Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades).",
        "Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42].",
        "Nuestras técnicas no están de ninguna manera específicas para una aplicación.",
        "El experimento principal que presentamos en este artículo es sobre un juego recreativo.",
        "Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo.",
        "La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal.",
        "Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker.",
        "El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5].",
        "Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219].",
        "Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano.",
        "Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes.",
        "Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25].",
        "Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas.",
        "Además, las aproximaciones fueron diseñadas manualmente por un experto humano.",
        "Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias.",
        "Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47].",
        "Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].)",
        "Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos.",
        "Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas.",
        "Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar.",
        "Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos.",
        "Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo).",
        "GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas).",
        "Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2.",
        "Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html.",
        "Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes.",
        "Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud.",
        "JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva.",
        "Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas.",
        "Un juego con señales ordenadas consta de un número finito de rondas.",
        "Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas).",
        "La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas.",
        "En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza.",
        "En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales).",
        "Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado).",
        "También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas.",
        "Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas.",
        "Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales.",
        "Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas.",
        "Definición 1.",
        "Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1.",
        "Yo = {1, . . . , n} es un conjunto finito de jugadores. 2.",
        "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej.",
        "Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j.",
        "Gj es el juego de etapa para la ronda j. 3.",
        "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4.",
        "Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j.",
        "Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|.",
        "La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´.",
        "La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´.",
        "También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i.",
        "La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ.",
        "Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda.",
        "Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr.",
        "Ten en cuenta que ω es independiente de las señales.",
        "Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
        "Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados.",
        "En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador.",
        "Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego.",
        "Utilizaremos esto al diseñar nuestras técnicas de abstracción.",
        "Formalmente, un filtro de información es el siguiente.",
        "Definición 2.",
        "Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado.",
        "Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j.",
        "Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl.",
        "Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
        "Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF.",
        "Nos referimos a estos juegos como juegos ordenados filtrados.",
        "Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o.",
        "Tenemos el siguiente resultado simple (pero importante): Proposición 1.",
        "Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo.",
        "Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto.",
        "Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados.",
        "Definición 3.",
        "Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X).",
        "Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i.",
        "Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´.",
        "Un perfil estratégico es σ = (σ1, . . . , σn).",
        "Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
        "Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ.",
        "La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i.",
        "Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29].",
        "Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1.",
        "Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento.",
        "ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos.",
        "Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego.",
        "Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego.",
        "Definición 4.",
        "Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas).",
        "Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo.",
        "Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk.",
        "Denotamos a los hijos de un nodo x como N(x).",
        "Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado.",
        "En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego.",
        "Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente.",
        "Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado.",
        "Definición 5.",
        "Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego.",
        "Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ).",
        "Definición 6.",
        "Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ.",
        "Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j.",
        "La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
        "La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker.",
        "El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida.",
        "Teorema 2.",
        "Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ.",
        "Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado.",
        "Sea σ un equilibrio de Nash del juego inducido ΓF.",
        "Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF.",
        "Prueba.",
        "Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF.",
        "Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash.",
        "Repara a algún jugador i ∈ I.",
        "Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj.",
        "Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información.",
        "Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z.",
        "Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido.",
        "Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
        "En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales.",
        "Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.)",
        "Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes).",
        "Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador.",
        "Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas.",
        "El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2.",
        "El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja.",
        "En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
        "Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash.",
        "Afirmación 1. μ es un sistema de creencias válido para ΓF.",
        "Reclamo 2.",
        "Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3.",
        "Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ.",
        "Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13].",
        "Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2.",
        "Por la Reclamación 3, sabemos que se cumple la condición C1.",
        "Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales.",
        "En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica.",
        "Primero, demostramos un fallo al eliminar la primera suposición.",
        "Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares.",
        "Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2.",
        "En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda.",
        "Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva.",
        "Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo.",
        "Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1.",
        "Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original.",
        "GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones.",
        "Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego.",
        "Primero presentamos una subrutina que utiliza GameShrink.",
        "Es un programa dinámico para calcular la relación isomórfica del juego ordenado.",
        "Nuevamente, opera en el árbol de señales.",
        "Algoritmo 1.",
        "¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1.",
        "Si ϑ y ϑ tienen padres diferentes, entonces devolver falso.",
        "Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3.",
        "Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4.",
        "Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5.",
        "Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso.",
        "Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego.",
        "Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado.",
        "El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego.",
        "Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales).",
        "Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3).",
        "Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa).",
        "El número de nodos, n, en el árbol de señal es O(|Θ|S).",
        "El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?.",
        "Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo.",
        "Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego.",
        "El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol).",
        "El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S !",
        "Sí, que es una cota inferior en el número de nodos.",
        "Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S !",
        "Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ).",
        "Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales.",
        "El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego).",
        "Ver la Figura 1.",
        "En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego.",
        "Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705.",
        "Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink.",
        "Algoritmo 2.",
        "GameShrink (Γ) 1. \n\nGameShrink (Γ) 1.",
        "Inicialice F como el filtro identidad para Γ. 2.",
        "Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3.",
        "Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible.",
        "Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2.",
        "Por lo tanto, tenemos el siguiente resultado: Teorema 3.",
        "GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas.",
        "Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash.",
        "El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal.",
        "Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego.",
        "Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces.",
        "Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente).",
        "Por lo tanto, el tiempo total para GameShrink es O(2^n).",
        "Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
        "Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales.",
        "Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación.",
        "Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49].",
        "Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto.",
        "Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos.",
        "Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales.",
        "Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto.",
        "Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado.",
        "Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes.",
        "Podemos precalcular estas frecuencias para cada nodo del árbol de juego.",
        "Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección).",
        "Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente.",
        "Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
        "Almacenamos los histogramas en una base de datos bidimensional.",
        "La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas.",
        "El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜.",
        "Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6].",
        "Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1.",
        "Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5.",
        "MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada.",
        "Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos.",
        "Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia.",
        "Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego.",
        "Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios.",
        "Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo.",
        "Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2.",
        "Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador).",
        "Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2.",
        "En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta.",
        "Hay muchas formas en las que la función de penalización podría ser definida e implementada.",
        "Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral).",
        "Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones).",
        "Este botón también genera un algoritmo en cualquier momento.",
        "Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex.",
        "Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos.",
        "En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1.",
        "Hay dos versiones del método simplex: el simplex primal y el simplex dual.",
        "El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad.",
        "De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual).",
        "Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente.",
        "En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento.",
        "Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL).",
        "Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57].",
        "Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente.",
        "Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución).",
        "Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución.",
        "Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5].",
        "Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse).",
        "Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento.",
        "Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6.",
        "Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11].",
        "A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver.",
        "El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida.",
        "La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27].",
        "Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21].",
        "Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10].",
        "La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos.",
        "La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas.",
        "De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles.",
        "Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño.",
        "Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes.",
        "Además, su artículo no proporciona algoritmos.",
        "Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente.",
        "A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]).",
        "Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas.",
        "Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2].",
        "Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta.",
        "Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18].",
        "A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico).",
        "La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta.",
        "Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente.",
        "Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta.",
        "Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos.",
        "Sin embargo, este enfoque tiene inconvenientes significativos.",
        "Primero, está altamente especializado para Texas Holdem.",
        "Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción.",
        "Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego.",
        "Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7.",
        "CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo.",
        "Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original.",
        "La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales.",
        "No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego.",
        "En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente.",
        "También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48].",
        "Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego.",
        "Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente.",
        "Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción.",
        "También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente.",
        "El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes.",
        "Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos.",
        "El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8.",
        "REFERENCIAS [1] W. Ackermann.",
        "Al enfoque de Hilbert para la construcción de los números reales.",
        "Matemáticas.",
        "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator.",
        "Análisis computarizado de brotes.",
        "Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell.",
        "Algunos juegos de dos personas que implican el engaño.",
        "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron.",
        "Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala.",
        "En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron.",
        "El desafío del póker.",
        "Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás.",
        "Combinatoria.",
        "Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus.",
        "Isomorfismo débil de juegos extensivos.",
        "Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng.",
        "Resolviendo la complejidad del equilibrio de Nash de 2 jugadores.",
        "ECCC, Informe No. 150, 2005. [9] V. Chvátal.",
        "Programación Lineal.",
        "W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
        "Transformaciones de juegos y equivalencia de juegos.",
        "Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny.",
        "Sobre la equivalencia estratégica de juegos en forma extensiva.",
        "Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson.",
        "Flujos en redes.",
        "Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm.",
        "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta.",
        "Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm.",
        "Póker Texas Hold'em óptimo de Rhode Island.",
        "En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm.",
        "Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real.",
        "Mimeo, 2006. [16] A. Gilpin y T. Sandholm.",
        "Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real.",
        "En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg.",
        "Búsqueda de particiones.",
        "En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg.",
        "GIB: Pasos hacia un programa de juego de bridge de nivel experto.",
        "En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson.",
        "Un método de Newton global para calcular equilibrios de Nash.",
        "Rev. Econ.",
        "Teoría, 110:65-86, 2003. [20] C. A. Knoblock.",
        "Generando automáticamente abstracciones para la planificación.",
        "Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens.",
        "Sobre la estabilidad estratégica de los equilibrios.",
        "Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo.",
        "La complejidad de los juegos de suma cero de dos personas en forma extensiva.",
        "Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo.",
        "Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva.",
        "Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel.",
        "Cálculo eficiente de equilibrios para juegos extensivos de dos personas.",
        "Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer.",
        "Representaciones y soluciones para problemas de teoría de juegos.",
        "Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson.",
        "Equilibrios secuenciales.",
        "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
        "Juegos extensos.",
        "PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
        "Un póker simplificado para dos personas.",
        "En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103.",
        "Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn.",
        "Juegos extensivos y el problema de la información.",
        "En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216.",
        "Princeton University Press, 1953. [30] C. Lemke y J. Howson.",
        "Puntos de equilibrio de juegos bimatrix.",
        "Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta.",
        "Jugando juegos grandes utilizando estrategias simples.",
        "En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman.",
        "Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas.",
        "Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green.",
        "Teoría microeconómica.",
        "Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan.",
        "Cálculo de equilibrios en juegos finitos.",
        "En el Manual de Economía Computacional, volumen 1, páginas 87-142.",
        "Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen.",
        "Calculando equilibrios secuenciales para juegos de dos jugadores.",
        "En SODA, páginas 107-116, 2006. [36] J. Nash.",
        "Puntos de equilibrio en juegos de n personas.",
        "Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley.",
        "Un juego de póker sencillo para tres personas.",
        "En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116.",
        "Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea.",
        "Racionalidad en juegos de forma extensiva.",
        "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa.",
        "Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000.",
        "Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham.",
        "Métodos de búsqueda simples para encontrar un equilibrio de Nash.",
        "En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii.",
        "Reducción de un juego con memoria completa a un juego de matriz.",
        "Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin.",
        "Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración.",
        "En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer.",
        "Métodos de programación entera mixta para encontrar equilibrios de Nash.",
        "En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel.",
        "Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix.",
        "En FOCS, páginas 258-267, 2004. [45] R. Selten.",
        "Tratamiento teórico del modelo de oligopolio con inercia en la demanda.",
        "Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten.",
        "Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional.",
        "Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman.",
        "Métodos de abstracción para el póker teórico de juegos.",
        "En Computadoras y Juegos, páginas 333-345.",
        "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop.",
        "Bridge informático: Una gran victoria para la planificación de IA.",
        "Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan.",
        "Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal.",
        "Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson.",
        "Equivalencia de juegos en forma extensiva.",
        "Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern.",
        "Teoría de juegos y comportamiento económico.",
        "Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel.",
        "Cálculo eficiente de estrategias de comportamiento.",
        "Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel.",
        "Calculando equilibrios para juegos de dos personas.",
        "En el Manual de Teoría de Juegos, volumen 3.",
        "Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson.",
        "Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva.",
        "Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright.",
        "Métodos de Puntos Interiores Primal-Dual.",
        "SIAM, 1997. 169"
    ],
    "error_count": 6,
    "keys": {
        "equilibrium": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an <br>equilibrium</br> of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash <br>equilibrium</br> in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash <br>equilibrium</br> in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an <br>equilibrium</br> to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve <br>equilibrium</br>, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash <br>equilibrium</br> [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an <br>equilibrium</br>.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an <br>equilibrium</br> using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash <br>equilibrium</br> solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of <br>equilibrium</br> computation.",
                "Instead of developing an <br>equilibrium</br>-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any <br>equilibrium</br> in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an <br>equilibrium</br> in the smaller game (using any available <br>equilibrium</br>-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an <br>equilibrium</br> for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of <br>equilibrium</br> finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main <br>equilibrium</br> result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact <br>equilibrium</br> is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an <br>equilibrium</br> in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of <br>equilibrium</br> computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in <br>equilibrium</br> [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash <br>equilibrium</br> strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash <br>equilibrium</br> of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash <br>equilibrium</br> if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash <br>equilibrium</br> to show that σ is a Nash <br>equilibrium</br> considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash <br>equilibrium</br> We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash <br>equilibrium</br> if, for every player i, σi is a best response for σ−i.",
                "A Nash <br>equilibrium</br> always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash <br>equilibrium</br> exists in behavior strateges. 3.",
                "<br>equilibrium</br>-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main <br>equilibrium</br> result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash <br>equilibrium</br> of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash <br>equilibrium</br> of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash <br>equilibrium</br> if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash <br>equilibrium</br> of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash <br>equilibrium</br>.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash <br>equilibrium</br>.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash <br>equilibrium</br>. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash <br>equilibrium</br> strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of <br>equilibrium</br>-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash <br>equilibrium</br> does not correspond to a Nash <br>equilibrium</br> in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash <br>equilibrium</br>, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash <br>equilibrium</br>.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact <br>equilibrium</br>, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an <br>equilibrium</br> strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the <br>equilibrium</br> guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the <br>equilibrium</br> computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential <br>equilibrium</br>, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the <br>equilibrium</br> of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve <br>equilibrium</br>: even if applied to a smaller game, it might not yield a game-theoretic <br>equilibrium</br>.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash <br>equilibrium</br> in the smaller abstracted game maps directly to a Nash <br>equilibrium</br> in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the <br>equilibrium</br> for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax <br>equilibrium</br> to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash <br>equilibrium</br>.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time <br>equilibrium</br> computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time <br>equilibrium</br> computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "<br>equilibrium</br> points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "<br>equilibrium</br> points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash <br>equilibrium</br>.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash <br>equilibrium</br> in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an <br>equilibrium</br> of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash <br>equilibrium</br> in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash <br>equilibrium</br> in the original game.",
                "Using GameShrink, we find an <br>equilibrium</br> to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "To address even larger games, we introduce approximation methods that do not preserve <br>equilibrium</br>, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "The most famous and important solution concept is that of Nash <br>equilibrium</br> [36]."
            ],
            "translated_annotated_samples": [
                "Encontrar <br>equilibrio</br>s en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un <br>equilibrio</br> de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes.",
                "Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier <br>equilibrio de Nash</br> en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un <br>equilibrio de Nash</br> en el juego original.",
                "Usando GameShrink, encontramos un <br>equilibrio</br> para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente.",
                "Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el <br>equilibrio</br>, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable.",
                "El concepto de <br>equilibrio</br> de Nash [36] es el más famoso e importante en teoría de juegos."
            ],
            "translated_text": "Encontrar <br>equilibrio</br>s en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un <br>equilibrio</br> de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier <br>equilibrio de Nash</br> en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un <br>equilibrio de Nash</br> en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un <br>equilibrio</br> para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el <br>equilibrio</br>, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de <br>equilibrio</br> de Nash [36] es el más famoso e importante en teoría de juegos. ",
            "candidates": [],
            "error": [
                [
                    "equilibrio",
                    "equilibrio",
                    "equilibrio de Nash",
                    "equilibrio de Nash",
                    "equilibrio",
                    "equilibrio",
                    "equilibrio"
                ]
            ]
        },
        "sequential game": {
            "translated_key": "juego secuencial",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player <br>sequential game</br> of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "For a multi-player <br>sequential game</br> of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game."
            ],
            "translated_annotated_samples": [
                "Para un <br>juego secuencial</br> de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un <br>juego secuencial</br> de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "imperfect information": {
            "translated_key": "información imperfecta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of <br>imperfect information</br>∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of <br>imperfect information</br> is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of <br>imperfect information</br> with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or <br>imperfect information</br>.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of <br>imperfect information</br>, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of <br>imperfect information</br>.",
                "For sequential games with <br>imperfect information</br>, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of <br>imperfect information</br> are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of <br>imperfect information</br>, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of <br>imperfect information</br> because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of <br>imperfect information</br>, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for <br>imperfect information</br> games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of <br>imperfect information</br>, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of <br>imperfect information</br>.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "Finding Equilibria in Large Sequential Games of <br>imperfect information</br>∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of <br>imperfect information</br> is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "For a multi-player sequential game of <br>imperfect information</br> with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "Games can be classified as either games of perfect information or <br>imperfect information</br>.",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of <br>imperfect information</br>, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "Thus the algorithms for perfect information games do not solve games of <br>imperfect information</br>."
            ],
            "translated_annotated_samples": [
                "Encontrar equilibrios en juegos secuenciales grandes de <br>información imperfecta</br>∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de <br>información imperfecta</br> es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes.",
                "Para un juego secuencial de múltiples jugadores con <br>información imperfecta</br>, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original.",
                "Los juegos pueden clasificarse como juegos de información perfecta o <br>información imperfecta</br>.",
                "La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de <br>información imperfecta</br>, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo.",
                "Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de <br>información imperfecta</br>."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de <br>información imperfecta</br>∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de <br>información imperfecta</br> es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con <br>información imperfecta</br>, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o <br>información imperfecta</br>. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de <br>información imperfecta</br>, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de <br>información imperfecta</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "computational game theory": {
            "translated_key": "teoría computacional de juegos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in <br>computational game theory</br>, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in <br>computational game theory</br>, but current techniques do not scale to large games."
            ],
            "translated_annotated_samples": [
                "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la <br>teoría computacional de juegos</br>, pero las técnicas actuales no escalan a juegos grandes."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la <br>teoría computacional de juegos</br>, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ordered game isomorphism": {
            "translated_key": "isomorfismo de juego ordenado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the <br>ordered game isomorphism</br> and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the <br>ordered game isomorphism</br> to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "To address this, we introduce the <br>ordered game isomorphism</br> and the related ordered game isomorphic abstraction transformation.",
                "We introduce the <br>ordered game isomorphism</br> to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3)."
            ],
            "translated_annotated_samples": [
                "Para abordar esto, introducimos el <br>isomorfismo de juego ordenado</br> y la transformación de abstracción isomórfica de juego ordenado relacionada.",
                "Introducimos el <br>isomorfismo de juego ordenado</br> para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3)."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el <br>isomorfismo de juego ordenado</br> y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el <br>isomorfismo de juego ordenado</br> para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "related ordered game isomorphic abstraction transformation": {
            "translated_key": "abstracción isomórfica de juego ordenado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the <br>related ordered game isomorphic abstraction transformation</br>.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "To address this, we introduce the ordered game isomorphism and the <br>related ordered game isomorphic abstraction transformation</br>."
            ],
            "translated_annotated_samples": [
                "Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de <br>abstracción isomórfica de juego ordenado</br> relacionada."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de <br>abstracción isomórfica de juego ordenado</br> relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ordered signal space": {
            "translated_key": "espacio de señales ordenado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an <br>ordered signal space</br>, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "For a multi-player sequential game of imperfect information with observable actions and an <br>ordered signal space</br>, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game."
            ],
            "translated_annotated_samples": [
                "Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un <br>espacio de señales ordenado</br>, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un <br>espacio de señales ordenado</br>, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "observable action": {
            "translated_key": "acciones observables",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with <br>observable action</br>s and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "For a multi-player sequential game of imperfect information with <br>observable action</br>s and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game."
            ],
            "translated_annotated_samples": [
                "Para un juego secuencial de múltiples jugadores con información imperfecta, <br>acciones observables</br> y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, <br>acciones observables</br> y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "nash equilibrium": {
            "translated_key": "equilibrio de Nash",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any <br>nash equilibrium</br> in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a <br>nash equilibrium</br> in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of <br>nash equilibrium</br> [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the <br>nash equilibrium</br> solution concept, but a stronger solution concept called subgame perfect <br>nash equilibrium</br> [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a <br>nash equilibrium</br> strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a <br>nash equilibrium</br> of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a <br>nash equilibrium</br> if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a <br>nash equilibrium</br> to show that σ is a <br>nash equilibrium</br> considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and <br>nash equilibrium</br> We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a <br>nash equilibrium</br> if, for every player i, σi is a best response for σ−i.",
                "A <br>nash equilibrium</br> always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a <br>nash equilibrium</br> exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a <br>nash equilibrium</br> of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a <br>nash equilibrium</br> of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a <br>nash equilibrium</br> if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a <br>nash equilibrium</br> of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a <br>nash equilibrium</br>.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a <br>nash equilibrium</br>.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a <br>nash equilibrium</br>. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only <br>nash equilibrium</br> strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the <br>nash equilibrium</br> does not correspond to a <br>nash equilibrium</br> in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any <br>nash equilibrium</br>, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a <br>nash equilibrium</br>.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any <br>nash equilibrium</br> in the smaller abstracted game maps directly to a <br>nash equilibrium</br> in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player <br>nash equilibrium</br>.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a <br>nash equilibrium</br>.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a <br>nash equilibrium</br> in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any <br>nash equilibrium</br> in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a <br>nash equilibrium</br> in the original game.",
                "The most famous and important solution concept is that of <br>nash equilibrium</br> [36].",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the <br>nash equilibrium</br> solution concept, but a stronger solution concept called subgame perfect <br>nash equilibrium</br> [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a <br>nash equilibrium</br> strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a <br>nash equilibrium</br> of ΓF ."
            ],
            "translated_annotated_samples": [
                "Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier <br>equilibrio de Nash</br> en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un <br>equilibrio de Nash</br> en el juego original.",
                "El concepto de <br>equilibrio de Nash</br> [36] es el más famoso e importante en teoría de juegos.",
                "Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52].",
                "Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de <br>equilibrio de Nash</br> del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F).",
                "Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un <br>equilibrio de Nash</br> de ΓF."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier <br>equilibrio de Nash</br> en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un <br>equilibrio de Nash</br> en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de <br>equilibrio de Nash</br> [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de <br>equilibrio de Nash</br> del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un <br>equilibrio de Nash</br> de ΓF. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "gameshrink": {
            "translated_key": "GameShrink",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, <br>gameshrink</br>, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so <br>gameshrink</br> has time and space complexity sublinear in the size of the game tree.",
                "Using <br>gameshrink</br>, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for <br>gameshrink</br>.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, <br>gameshrink</br>, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so <br>gameshrink</br> has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our <br>gameshrink</br> algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without <br>gameshrink</br> yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "<br>gameshrink</br> required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: <br>gameshrink</br> applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "<br>gameshrink</br>: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, <br>gameshrink</br>, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that <br>gameshrink</br> uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, <br>gameshrink</br>.",
                "Algorithm 2.",
                "<br>gameshrink</br> (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, <br>gameshrink</br> applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of <br>gameshrink</br> follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "<br>gameshrink</br> finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of <br>gameshrink</br> is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for <br>gameshrink</br> is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, <br>gameshrink</br> tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for <br>gameshrink</br>, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up <br>gameshrink</br>, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying <br>gameshrink</br>, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, <br>gameshrink</br>, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of <br>gameshrink</br> is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so <br>gameshrink</br> has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using <br>gameshrink</br>, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of <br>gameshrink</br>, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of <br>gameshrink</br> (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "We present an algorithm, <br>gameshrink</br>, for abstracting the game using our isomorphism exhaustively.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so <br>gameshrink</br> has time and space complexity sublinear in the size of the game tree.",
                "Using <br>gameshrink</br>, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for <br>gameshrink</br>.",
                "We also give an algorithm, <br>gameshrink</br>, for abstracting the game using our isomorphism exhaustively (Section 4)."
            ],
            "translated_annotated_samples": [
                "Presentamos un algoritmo, <br>GameShrink</br>, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo.",
                "No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que <br>GameShrink</br> tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego.",
                "Usando <br>GameShrink</br>, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente.",
                "Discutimos varias aplicaciones de comercio electrónico para <br>GameShrink</br>.",
                "También presentamos un algoritmo, <br>GameShrink</br>, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4)."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, <br>GameShrink</br>, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que <br>GameShrink</br> tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando <br>GameShrink</br>, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para <br>GameShrink</br>. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, <br>GameShrink</br>, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "signal tree": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the <br>signal tree</br>.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the <br>signal tree</br>.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered <br>signal tree</br> which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered <br>signal tree</br>, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered <br>signal tree</br> represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered <br>signal tree</br> are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered <br>signal tree</br> corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the <br>signal tree</br> discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the <br>signal tree</br>.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the <br>signal tree</br>: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the <br>signal tree</br>, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the <br>signal tree</br> is O(|Θ|S ).",
                "The dynamic program visits each node in the <br>signal tree</br>, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the <br>signal tree</br>-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the <br>signal tree</br> is smaller than the game tree.",
                "The number of nodes in the <br>signal tree</br> is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the <br>signal tree</br> is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the <br>signal tree</br>.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the <br>signal tree</br> is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the <br>signal tree</br> is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the <br>signal tree</br> only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) <br>signal tree</br>: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the <br>signal tree</br>), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the <br>signal tree</br>.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the <br>signal tree</br> is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the <br>signal tree</br>.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the <br>signal tree</br>.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the <br>signal tree</br>.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the <br>signal tree</br>.",
                "We begin by defining a filtered <br>signal tree</br> which represents all of the chance moves in the game.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered <br>signal tree</br>, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered <br>signal tree</br> represent the set of all possible revealed filtered signals (public and private) at some point in time."
            ],
            "translated_annotated_samples": [
                "Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el <br>árbol de señales</br>.",
                "Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el <br>árbol de señales</br>.",
                "Comenzamos definiendo un <br>árbol de señal</br> filtrada que representa todos los movimientos aleatorios en el juego.",
                "Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un <br>árbol de señales</br> filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas).",
                "Los nodos en el <br>árbol de señales</br> filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el <br>árbol de señales</br>. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el <br>árbol de señales</br>. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un <br>árbol de señal</br> filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un <br>árbol de señales</br> filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el <br>árbol de señales</br> filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. ",
            "candidates": [],
            "error": [
                [
                    "árbol de señales",
                    "árbol de señales",
                    "árbol de señal",
                    "árbol de señales",
                    "árbol de señales"
                ]
            ]
        },
        "game theory": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational <br>game theory</br>, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "<br>game theory</br> provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, <br>game theory</br> has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing <br>game theory</br>-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not <br>game theory</br>-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of <br>game theory</br>, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the <br>game theory</br> Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of <br>game theory</br>, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational <br>game theory</br>, but current techniques do not scale to large games.",
                "<br>game theory</br> provides a normative framework for analyzing such strategic situations.",
                "Almost since the fields founding, <br>game theory</br> has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing <br>game theory</br>-based strategies for larger games.",
                "However, it is not <br>game theory</br>-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically."
            ],
            "translated_annotated_samples": [
                "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la <br>teoría computacional de juegos</br>, pero las técnicas actuales no escalan a juegos grandes.",
                "La <br>teoría de juegos</br> proporciona un marco normativo para analizar tales situaciones estratégicas.",
                "Casi desde los inicios del campo, la <br>teoría de juegos</br> se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219].",
                "Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la <br>teoría de juegos</br> para juegos más grandes.",
                "Sin embargo, no está basado en <br>teoría de juegos</br> (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la <br>teoría computacional de juegos</br>, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La <br>teoría de juegos</br> proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la <br>teoría de juegos</br> se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la <br>teoría de juegos</br> para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en <br>teoría de juegos</br> (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. ",
            "candidates": [],
            "error": [
                [
                    "teoría computacional de juegos",
                    "teoría de juegos",
                    "teoría de juegos",
                    "teoría de juegos",
                    "teoría de juegos"
                ]
            ]
        },
        "normative framework": {
            "translated_key": "marco normativo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a <br>normative framework</br> for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "Game theory provides a <br>normative framework</br> for analyzing such strategic situations."
            ],
            "translated_annotated_samples": [
                "La teoría de juegos proporciona un <br>marco normativo</br> para analizar tales situaciones estratégicas."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un <br>marco normativo</br> para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "rational behavior": {
            "translated_key": "comportamiento racional",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what <br>rational behavior</br> is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "In particular, it provides solution concepts that define what <br>rational behavior</br> is in such settings."
            ],
            "translated_annotated_samples": [
                "En particular, proporciona conceptos de solución que definen qué es el <br>comportamiento racional</br> en tales contextos."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el <br>comportamiento racional</br> en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "strategy profile": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a <br>strategy profile</br> (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium <br>strategy profile</br> of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A <br>strategy profile</br> is σ = (σ1, . . . , σn).",
                "A <br>strategy profile</br> with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the <br>strategy profile</br> σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A <br>strategy profile</br> σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the <br>strategy profile</br> constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "It is a <br>strategy profile</br> (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium <br>strategy profile</br> of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "A <br>strategy profile</br> is σ = (σ1, . . . , σn).",
                "A <br>strategy profile</br> with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the <br>strategy profile</br> σ."
            ],
            "translated_annotated_samples": [
                "Es un <br>perfil estratégico</br> (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente.",
                "Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un <br>perfil de estrategia</br> de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F).",
                "Un <br>perfil estratégico</br> es σ = (σ1, . . . , σn).",
                "Un <br>perfil estratégico</br> con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el <br>perfil estratégico</br> σ."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un <br>perfil estratégico</br> (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un <br>perfil de estrategia</br> de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un <br>perfil estratégico</br> es σ = (σ1, . . . , σn). Un <br>perfil estratégico</br> con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el <br>perfil estratégico</br> σ. ",
            "candidates": [],
            "error": [
                [
                    "perfil estratégico",
                    "perfil de estrategia",
                    "perfil estratégico",
                    "perfil estratégico",
                    "perfil estratégico"
                ]
            ]
        },
        "sequential game of imperfect information": {
            "translated_key": "información imperfecta",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player <br>sequential game of imperfect information</br> with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "For a multi-player <br>sequential game of imperfect information</br> with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game."
            ],
            "translated_annotated_samples": [
                "Para un juego secuencial de múltiples jugadores con <br>información imperfecta</br>, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con <br>información imperfecta</br>, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el equilibrio. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "automate abstraction": {
            "translated_key": "automatizar la abstracción",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "equilibrium find": {
            "translated_key": "equilibrio",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of <br>equilibrium find</br>ing.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of <br>equilibrium find</br>ing."
            ],
            "translated_annotated_samples": [
                "Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el <br>equilibrio</br>."
            ],
            "translated_text": "Encontrar equilibrios en juegos secuenciales grandes de información imperfecta∗ Andrew Gilpin Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. gilpin@cs.cmu.edu Tuomas Sandholm Departamento de Ciencias de la Computación Universidad Carnegie Mellon Pittsburgh, PA, EE. UU. sandholm@cs.cmu.edu RESUMEN Encontrar un equilibrio de un juego de forma extensiva de información imperfecta es un problema fundamental en la teoría computacional de juegos, pero las técnicas actuales no escalan a juegos grandes. Para abordar esto, introducimos el isomorfismo de juego ordenado y la transformación de abstracción isomórfica de juego ordenado relacionada. Para un juego secuencial de múltiples jugadores con información imperfecta, acciones observables y un espacio de señales ordenado, demostramos que cualquier equilibrio de Nash en un juego abstracto más pequeño, obtenido mediante una o más aplicaciones de la transformación, puede convertirse fácilmente en un equilibrio de Nash en el juego original. Presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo. Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio para un juego de póker con 3.1 mil millones de nodos, más de cuatro órdenes de magnitud que en el juego de póker más grande resuelto previamente. Discutimos varias aplicaciones de comercio electrónico para GameShrink. Para abordar juegos aún más grandes, introducimos métodos de aproximación que no preservan el equilibrio, pero que, no obstante, producen estrategias (ex post) cercanas a óptimas de manera demostrable. Categorías y Descriptores de Asignaturas: I.2 [Inteligencia Artificial], F. [Teoría de la Computación], J.4 [Ciencias Sociales y del Comportamiento]: Economía. Términos generales: Algoritmos, Economía, Teoría. 1. INTRODUCCIÓN En entornos con más de un agente, el resultado de un agente generalmente se ve afectado por las acciones del otro(s) agente(s). Por consiguiente, la acción óptima de un agente puede depender de los demás. La teoría de juegos proporciona un marco normativo para analizar tales situaciones estratégicas. En particular, proporciona conceptos de solución que definen qué es el comportamiento racional en tales contextos. El concepto de equilibrio de Nash [36] es el más famoso e importante en teoría de juegos. Es un perfil estratégico (una estrategia para cada agente) en el cual ningún agente tiene incentivo para desviarse hacia una estrategia diferente. Sin embargo, para que el concepto sea operativo, necesitamos técnicas algorítmicas para encontrar un equilibrio. Los juegos pueden clasificarse como juegos de información perfecta o información imperfecta. El ajedrez y el Go son ejemplos de lo primero, y, hasta hace poco, la mayoría del trabajo de juegos se ha centrado en juegos de este tipo. Para calcular una estrategia óptima en un juego de información perfecta, un agente recorre el árbol de juego y evalúa los nodos individuales. Si el agente es capaz de recorrer todo el árbol de juego, simplemente calcula una estrategia óptima de abajo hacia arriba, utilizando el principio de inducción hacia atrás. En términos de informática, esto se hace utilizando la búsqueda minimax (a menudo en conjunto con la poda αβ para reducir el tamaño del árbol de búsqueda y así mejorar la velocidad). La búsqueda Minimax se ejecuta en tiempo lineal en el tamaño del árbol de juego. La característica diferenciadora de los juegos de información imperfecta, como el póker, es que no son completamente observables: cuando es el turno de un agente de moverse, no tiene acceso a toda la información sobre el mundo. En tales juegos, la decisión de qué hacer en un momento dado generalmente no puede tomarse de manera óptima sin considerar las decisiones en todos los demás momentos (incluidas las de otros caminos de juego) porque esas otras decisiones afectan las probabilidades de encontrarse en diferentes estados en el momento actual. Por lo tanto, los algoritmos para juegos de información perfecta no resuelven juegos de información imperfecta. Para juegos secuenciales con información imperfecta, se podría intentar encontrar un equilibrio utilizando la forma normal (matricial), donde cada plan de contingencia del agente es una estrategia pura para el agente. Desafortunadamente (incluso si las estrategias equivalentes 1 en realidad producen una solución que satisface no solo el concepto de solución de equilibrio de Nash, sino un concepto de solución más fuerte llamado equilibrio de Nash perfecto en subjuegos [45]. 2 Este tipo de algoritmo aún no escala a árboles enormes (como en ajedrez o Go), pero se pueden desarrollar agentes de juego efectivos incluso entonces evaluando nodos intermedios utilizando una evaluación heurística y luego tratando esos nodos como hojas. 3 Un equilibrio en una forma normal de juego con cualquier 160 se reemplazan por una sola estrategia [27]), esta representación es generalmente exponencial en el tamaño del árbol de juego [52]. Al observar que solo es necesario considerar secuencias de movimientos en lugar de estrategias puras [41, 46, 22, 52], se llega a una representación más compacta, la forma de secuencia, que es lineal en el tamaño del árbol de juego. Para juegos de 2 jugadores, existe una formulación de programación lineal de tamaño polinómico (en el tamaño del árbol de juego) (complementariedad lineal en el caso no de suma cero) basada en la forma de secuencia, de modo que las estrategias para los jugadores 1 y 2 corresponden a variables primales y duales. Por lo tanto, los equilibrios de juegos de 2 jugadores de tamaño razonable pueden ser calculados utilizando este método. Sin embargo, este enfoque sigue generando problemas de optimización enormes (insolubles) para muchos juegos del mundo real, como el póker. En este artículo, adoptamos un enfoque diferente para abordar el difícil problema del cálculo de equilibrios. En lugar de desarrollar un método de encontrar equilibrios per se, en su lugar desarrollamos una metodología para abstraer automáticamente juegos de tal manera que cualquier equilibrio en el juego más pequeño (abstraído) corresponda directamente a un equilibrio en el juego original. Por lo tanto, al calcular un equilibrio en el juego más pequeño (utilizando cualquier algoritmo disponible para encontrar equilibrios), podemos construir un equilibrio en el juego original. La motivación es que un equilibrio para el juego más pequeño se puede calcular drásticamente más rápido que para el juego original. Con este fin, introducimos juegos con señales ordenadas (Sección 2), una amplia clase de juegos que tiene la suficiente estructura que podemos explotar con fines de abstracción. En lugar de operar directamente sobre el árbol de juego (algo que encontramos ser técnicamente desafiante), en su lugar introducimos el uso de filtros de información (Sección 2.1), que reducen la información que recibe cada jugador. Son utilizados en nuestro algoritmo de análisis y abstracción. Al operar únicamente en el espacio de los filtros, podemos mantener la estructura estratégica del juego intacta, al mismo tiempo que abstraemos los detalles del juego de una manera que no pierde información desde la perspectiva de encontrar el <br>equilibrio</br>. Introducimos el isomorfismo de juego ordenado para describir situaciones estratégicamente simétricas y la transformación de abstracción isomórfica de juego ordenado para aprovechar tales simetrías (Sección 3). Como nuestro resultado principal de equilibrio, tenemos lo siguiente: un número constante de agentes puede ser construido en tiempo cuasipolinómico [31], pero encontrar un equilibrio exacto es PPAD-completo incluso en un juego de 2 jugadores [8]. El algoritmo más prevalente para encontrar un equilibrio en un juego de 2 agentes es Lemke-Howson [30], pero en el peor de los casos requiere exponencialmente muchos pasos [44]. Para una encuesta sobre el cálculo del equilibrio en juegos de 2 jugadores, consulte [53]. Recientemente, se han demostrado eficientes algoritmos de búsqueda de equilibrio que enumeran soportes (es decir, conjuntos de estrategias puras que se juegan con probabilidad positiva) en muchos juegos [40], y se han desarrollado eficientes algoritmos de programación entera mixta que buscan en el espacio de soportes [43]. Para más de dos jugadores, se han propuesto muchos algoritmos, pero actualmente solo escalan a juegos muy pequeños [19, 34, 40]. También hubo técnicas tempranas que se aprovecharon de diferentes maneras del hecho de que en muchos juegos la gran mayoría de las estrategias puras no se juegan en equilibrio [54, 23]. Recientemente, este enfoque se extendió para manejar el cálculo de equilibrios secuenciales [26] también [35]. Teorema 2: Sea Γ un juego con señales ordenadas, y sea F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado, y sea σ un perfil de estrategia de equilibrio de Nash del juego inducido ΓF (es decir, el juego Γ utilizando el filtro F). Si σ se construye utilizando las estrategias correspondientes de σ, entonces σ es un equilibrio de Nash de ΓF. La prueba del teorema utiliza una caracterización equivalente de los equilibrios de Nash: σ es un equilibrio de Nash si y solo si existen creencias μ (creencias de los jugadores sobre información desconocida) en todos los puntos del juego alcanzables por σ, de modo que σ es secuencialmente racional (es decir, una mejor respuesta) dada μ, donde μ se actualiza utilizando la regla de Bayes. Podemos entonces usar el hecho de que σ es un equilibrio de Nash para demostrar que σ es un equilibrio de Nash considerando solo las propiedades locales del juego. También presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente nuestro isomorfismo (Sección 4). Su complejidad es ˜O(n2), donde n es el número de nodos en una estructura que llamamos el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en el tamaño del árbol de juego. Presentamos varias mejoras de velocidad relacionadas con algoritmos y estructuras de datos (Sección 4.1), y demostramos cómo una modificación simple a nuestro algoritmo produce un algoritmo de aproximación (Sección 5). Aplicaciones de comercio electrónico Los juegos secuenciales de información imperfecta son ubicuos, por ejemplo, en negociaciones y subastas. A menudo, aspectos del conocimiento de un jugador no son pertinentes para decidir qué acción debe tomar el jugador en un punto dado del juego. En el extremo trivial, algunos aspectos del conocimiento de un jugador nunca son pertinentes (por ejemplo, si está lloviendo o no no tiene ninguna influencia en la estrategia de oferta en una subasta de arte), y dichos aspectos pueden ser completamente omitidos de la especificación del modelo. Sin embargo, algunos aspectos pueden ser pertinentes en ciertos estados del juego mientras que no son pertinentes en otros estados, y por lo tanto no pueden ser excluidos completamente del modelo. Además, puede resultar altamente no evidente qué aspectos son pertinentes en qué estados del juego. Nuestro algoritmo descubre automáticamente qué aspectos son irrelevantes en diferentes estados, y elimina esos aspectos del juego, lo que resulta en una representación del juego más compacta y equivalente. Una amplia área de aplicación que tiene esta propiedad es la negociación secuencial (potencialmente sobre múltiples temas). Otra área de aplicación amplia son las subastas secuenciales (potencialmente de múltiples bienes). Por ejemplo, en esos estados de una subasta de 1 objeto donde el postor A puede inferir que su valoración es mayor que la del postor B, el postor A puede ignorar toda su otra información sobre las señales de B, aunque esa información sería relevante para inferir la valoración exacta de B. Además, en algunos estados de la subasta, un postor podría no preocuparse por qué postores exactos tienen qué valoraciones, pero le importa qué valoraciones tienen los otros postores en conjunto (ignorando sus identidades). Muchos mecanismos de subasta secuencial de grito abierto y negociación entran dentro del modelo de juego estudiado en este documento (especificado en detalle más adelante), al igual que ciertos otros juegos en el comercio electrónico, como secuencias de ofertas de tómalo o déjalo [42]. Nuestras técnicas no están de ninguna manera específicas para una aplicación. El experimento principal que presentamos en este artículo es sobre un juego recreativo. Elegimos un juego de póker en particular como problema de referencia porque produce un árbol de juego extremadamente complicado y enorme, es un juego de información imperfecta, está completamente especificado como un juego (y los datos están disponibles), y ha sido propuesto como un problema desafiante por otros [47] (hasta donde sabemos, no se han propuesto instancias de problemas desafiantes para aplicaciones de comercio electrónico que requieran resolver juegos secuenciales). 1.3 Rhode Island Holdem poker Poker es un juego de cartas enormemente popular jugado en todo el mundo. La Serie Mundial de Póker de 2005 tuvo más de $103 millones de dólares en premios totales, incluyendo $56 millones para el evento principal. Cada vez más, los jugadores de póker compiten en casinos en línea, y las cadenas de televisión transmiten regularmente torneos de póker. El póker ha sido identificado como un área de investigación importante en IA debido a la incertidumbre derivada de las cartas de los oponentes, las acciones futuras de los oponentes y los movimientos de azar, entre otras razones [5]. Casi desde los inicios del campo, la teoría de juegos se ha utilizado para analizar diferentes aspectos del póker [28; 37; 3; 51, pp. 186-219]. Sin embargo, este trabajo se limitaba a juegos pequeños que podían resolverse a mano. Más recientemente, los investigadores de IA han estado aplicando la potencia computacional del hardware moderno para calcular estrategias basadas en la teoría de juegos para juegos más grandes. Koller y Pfeffer determinaron soluciones para juegos de póker con hasta 140,000 nodos utilizando la forma de secuencia y programación lineal [25]. Se han desarrollado aproximaciones a gran escala [4], pero esos métodos no ofrecen garantías sobre el rendimiento de las estrategias calculadas. Además, las aproximaciones fueron diseñadas manualmente por un experto humano. Nuestro enfoque produce un mecanismo de abstracción automatizado junto con garantías teóricas sobre el rendimiento de las estrategias. Rhode Island Holdem fue inventado como un banco de pruebas para el juego computacional [47]. Fue diseñado de manera que fuera similar en estilo a Texas Holdem, pero no tan grande que resultara imposible idear estrategias razonablemente inteligentes. (Las reglas de Rhode Island Holdem, así como una discusión sobre cómo Rhode Island Holdem puede ser modelado como un juego con señales ordenadas, es decir, encaja en nuestro modelo, están disponibles en una versión extendida de este artículo [13].) Aplicamos las técnicas desarrolladas en este artículo para encontrar una solución exacta (minimax) para Rhode Island Holdem, que tiene un árbol de juego que supera los 3.1 mil millones de nodos. Aplicar la forma de secuencia al Rhode Island Holdem directamente sin abstracción produce un programa lineal con 91,224,226 filas y el mismo número de columnas. Esto es demasiado grande para que los algoritmos de programación lineal actuales puedan manejar. Utilizamos nuestro algoritmo GameShrink para reducir esto con abstracción sin pérdida, y dio como resultado un programa lineal con 1,237,238 filas y columnas, con 50,428,638 coeficientes no nulos. Luego aplicamos la eliminación iterada de estrategias dominadas, lo que redujo aún más esto a 1,190,443 filas y 1,181,084 columnas. (Aplicar la eliminación iterada de estrategias dominadas sin GameShrink habría dado como resultado 89,471,986 filas y 89,121,538 columnas, lo cual seguiría siendo demasiado grande para resolverlo). GameShrink tardó menos de un segundo en realizar el encogimiento (es decir, en calcular todas las transformaciones de abstracción isomórfica de juego ordenadas). Usando un IBM eServer p5 570 de 1.65GHz con 64 gigabytes de RAM (el solucionador de programas lineales realmente necesitaba 25 gigabytes), lo resolvimos en 7 días y 17 horas utilizando el método de barrera de punto interior de CPLEX versión 9.1.2. Recientemente demostramos a nuestro jugador óptimo de póker Rhode Island Holdem en la conferencia AAAI-05 [14], y está disponible para jugar en línea en http://www.cs.cmu.edu/~gilpin/gsi.html. Si bien otros han trabajado en programas de computadora para jugar Rhode Island Holdem [47], no se ha encontrado una estrategia óptima antes. Este es el juego de póker más grande resuelto hasta la fecha por más de cuatro órdenes de magnitud. JUEGOS CON SEÑALES ORDENADAS Trabajamos con una clase ligeramente restringida de juegos, en comparación con la plena generalidad de la forma extensiva. Esta clase, que llamamos juegos con señales ordenadas, está altamente estructurada, pero lo suficientemente general como para capturar una amplia gama de situaciones estratégicas. Un juego con señales ordenadas consta de un número finito de rondas. Dentro de una ronda, los jugadores juegan un juego en un árbol dirigido (el árbol puede ser diferente en diferentes rondas). La única incertidumbre a la que se enfrentan los jugadores proviene de las señales privadas que los otros jugadores han recibido y de las señales futuras desconocidas. En otras palabras, los jugadores observan las acciones de los demás, pero potencialmente no las acciones de la naturaleza. En cada ronda, puede haber señales públicas (anunciadas a todos los jugadores) y señales privadas (comunicadas de forma confidencial a jugadores individuales). Para simplificar, asumimos, como es el caso en la mayoría de los juegos recreativos, que dentro de cada ronda, el número de señales privadas recibidas es el mismo entre los jugadores (esto podría ser bastante probablemente relajado). También asumimos que las acciones legales que un jugador tiene son independientes de las señales recibidas. Por ejemplo, en el póker, las acciones legales de apuestas son independientes de las cartas recibidas. Finalmente, la suposición más fuerte es que existe un orden parcial sobre conjuntos de señales, y las ganancias aumentan (no necesariamente de forma estricta) en estas señales. Por ejemplo, en el póker, este orden parcial corresponde exactamente a la clasificación de las manos de cartas. Definición 1. Un juego con señales ordenadas es una tupla Γ = I, G, L, Θ, κ, γ, p, , ω, u donde: 1. Yo = {1, . . . , n} es un conjunto finito de jugadores. 2. G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , es una colección finita de árboles dirigidos finitos con nodos V j y aristas Ej. Que Zj denote los nodos hoja de Gj y que Nj (v) denote los vecinos salientes de v ∈ V j. Gj es el juego de etapa para la ronda j. 3. L = L1 , . . . , Lr , Lj : V j \\ Zj → I indica qué jugador actúa (elige un borde saliente) en cada nodo interno en la ronda j. 4. Θ es un conjunto finito de señales. 5. κ = κ1 , . . . , κr y γ = γ1 , . . . , γr son vectores de enteros no negativos, donde κj y γj denotan el número de señales públicas y privadas (por jugador), respectivamente, reveladas en la ronda j. Cada señal θ ∈ Θ solo puede ser revelada una vez, y en cada ronda cada jugador recibe el mismo número de señales privadas, por lo que requerimos que Pr j=1 κj + nγj ≤ |Θ|. La información pública revelada en la ronda j es αj ∈ Θκj y la información pública revelada en todas las rondas hasta la ronda j es ˜αj = ` α1 , . . . , αj ´. La información privada revelada al jugador i ∈ I en la ronda j es βj i ∈ Θγj y la información privada revelada al jugador i ∈ I en todas las rondas hasta la ronda j es ˜βj i = ` β1 i , . . . , βj i ´. También escribimos ˜βj = ˜βj 1, . . . , ˜βj n para representar toda la información privada hasta la ronda j, y ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n es ˜βj con ˜βj i reemplazado por ˜β j i. La información total revelada hasta la ronda j, ˜αj , ˜βj, se considera legal si no se repiten señales. 6. p es una distribución de probabilidad sobre Θ, con p(θ) > 0 para todo θ ∈ Θ. Las señales se extraen de Θ según p sin reemplazo, por lo que si X es el conjunto de señales ya reveladas, entonces p(x | X) = ( p(x)P y /∈X p(y) si x /∈ X 0 si x ∈ X. 7. es un orden parcial de subconjuntos de Θ y está definido al menos para aquellos pares requeridos por u. 8. ω : rS j=1 Zj → {over, continue} es una asignación de nodos terminales dentro de un juego de etapas a uno de dos valores: over, en cuyo caso el juego termina, o continue, en cuyo caso el juego continúa hasta la siguiente ronda. Claramente, necesitamos ω(z) = sobre para todo z ∈ Zr. Ten en cuenta que ω es independiente de las señales. Deje ωj sobre = {z ∈ Zj | ω(z) = sobre} y ωj cont = {z ∈ Zj | ω(z) = continuar}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj sobre × j k=1 Θκk × n i=1 j k=1 Θγk → Rn es una función de utilidad tal que para cada j, 1 ≤ j ≤ r, para cada i ∈ I, y para cada ˜z ∈ j−1 k=1 ωk cont × ωj sobre, al menos una de las siguientes dos condiciones se cumple: (a) La utilidad es independiente de la señal: uj i (˜z, ϑ) = uj i (˜z, ϑ ) para todas las ϑ legales, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) está definida para todas las señales legales (˜αj , ˜βj i ), (˜αj , ˜β j i ) a través de la ronda j y la utilidad de un jugador aumenta en sus señales privadas, manteniendo todo lo demás igual: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i . Utilizaremos el término juego con señales ordenadas y el término juego ordenado de manera intercambiable. 2.1 Filtros de información En esta subsección, definimos un filtro de información para juegos ordenados. En lugar de revelar completamente una señal (ya sea pública o privada) a un jugador, la señal primero pasa a través de este filtro, que emite una señal simplificada al jugador. Al variar el filtro aplicado a un juego, podemos obtener una amplia variedad de juegos manteniendo intacto el espacio de acción subyacente del juego. Utilizaremos esto al diseñar nuestras técnicas de abstracción. Formalmente, un filtro de información es el siguiente. Definición 2. Que Γ = I, G, L, Θ, κ, γ, p, , ω, u sea un juego ordenado. Sea Sj ⊆ j k=1 Θκk × j k=1 Θγk el conjunto de señales legales (es decir, sin señales repetidas) para un jugador hasta la ronda j. Un filtro de información para Γ es una colección F = F1 , . . . , Fr donde cada Fj es una función Fj : Sj → 2Sj tal que se cumplen cada una de las siguientes condiciones: 1. (Veracidad) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) para todos los (˜αj , ˜βj i ) legales. 2. (Independencia) El rango de Fj es una partición de Sj . 3. (Preservación de la información) Si dos valores de una señal son distinguibles en la ronda k, entonces son distinguibles para cada ronda j > k. Sea mj = Pj l=1 κl +γl. Requerimos que para todos los legales (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ y (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ). Un juego con señales ordenadas Γ y un filtro de información F para Γ define un nuevo juego ΓF. Nos referimos a estos juegos como juegos ordenados filtrados. Nos queda el juego original si usamos el filtro de identidad Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o. Tenemos el siguiente resultado simple (pero importante): Proposición 1. Un juego ordenado filtrado es un juego en forma extensiva que cumple con el perfecto recuerdo. Una prueba simple procede construyendo un juego en forma extensiva directamente a partir del juego ordenado, y mostrando que cumple con el recuerdo perfecto. Al determinar los pagos en un juego con señales filtradas, tomamos el promedio de todas las señales reales en la clase filtrada, ponderado por la probabilidad de que ocurra cada señal real. 2.2 Estrategias y equilibrio de Nash Estamos ahora listos para definir estrategias de comportamiento en el contexto de juegos ordenados filtrados. Definición 3. Una estrategia de comportamiento para el jugador i en la ronda j de Γ = I, G, L, Θ, κ, γ, p, , ω, u con filtro de información F es una distribución de probabilidad sobre acciones posibles, y está definida para cada jugador i, cada ronda j, y cada v ∈ V j \\Zj para Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Rango Fj → Δ n w ∈ V j | (v, w) ∈ Ej o. (Δ(X) es el conjunto de distribuciones de probabilidad sobre un conjunto finito X). Una estrategia de comportamiento para el jugador i en la ronda j es σj i = (σj i,v1 , . . . , σj i,vm ) para cada vk ∈ V j \\ Zj donde Lj (vk) = i. Una estrategia de comportamiento para el jugador i en Γ es σi = ` σ1 i , . . . , σr i ´. Un perfil estratégico es σ = (σ1, . . . , σn). Un perfil estratégico con σi reemplazado por σi es (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn). Por abuso de notación, diremos que el jugador i recibe un pago esperado de ui(σ) cuando todos los jugadores están jugando el perfil estratégico σ. La estrategia σi se dice que es la mejor respuesta del jugador i a σ−i si para todas las demás estrategias σi del jugador i tenemos ui(σi, σ−i) ≥ ui(σi, σ−i). σ es un equilibrio de Nash si, para cada jugador i, σi es la mejor respuesta para σ−i. Un equilibrio de Nash siempre existe en juegos de forma extensiva finitos [36], y existe en estrategias de comportamiento para juegos con memoria perfecta [29]. Usando estas observaciones, tenemos el siguiente corolario de la Proposición 1: Corolario 1. Para cualquier juego ordenado filtrado, existe un equilibrio de Nash en estrategias de comportamiento. ABSTRACCIONES QUE CONSERVAN EL EQUILIBRIO En esta sección, presentamos nuestra técnica principal para reducir el tamaño de los juegos. Comenzamos definiendo un árbol de señal filtrada que representa todos los movimientos aleatorios en el juego. Los bordes en negrita (es decir, los dos primeros niveles del árbol) en los árboles de juego en la Figura 1 corresponden a los árboles de señal filtrada en cada juego. Definición 4. Asociado con cada juego ordenado Γ = I, G, L, Θ, κ, γ, p, , ω, u y filtro de información F hay un árbol de señales filtradas, un árbol dirigido en el que cada nodo corresponde a algunas señales reveladas (filtradas) y las aristas corresponden a la revelación de señales específicas (filtradas). Los nodos en el árbol de señales filtradas representan el conjunto de todas las posibles señales filtradas reveladas (públicas y privadas) en algún momento en el tiempo. Las señales públicas filtradas reveladas en la ronda j corresponden a los nodos en los niveles κj comenzando en el nivel Pj−1 k=1 ` κk + nγk ´ y las señales privadas reveladas en la ronda j corresponden a los nodos en los niveles nγj comenzando en el nivel Pj k=1 κk + Pj−1 k=1 nγk. Denotamos a los hijos de un nodo x como N(x). Además, asociamos pesos a las aristas correspondientes a la probabilidad de que la arista particular sea elegida dado que su padre fue alcanzado. En muchos juegos, hay ciertas situaciones en el juego que pueden considerarse estratégicamente equivalentes a otras situaciones en el juego. Al fusionar estas situaciones, es posible llegar a un juego más pequeño estratégicamente equivalente. Las dos siguientes definiciones formalizan esta noción a través de la introducción de la relación isomórfica de juego ordenado y la transformación de abstracción isomórfica de juego ordenado. Definición 5. Dos subárboles que comienzan en los nodos internos x e y de un árbol de señal filtrada están ordenados isomórficamente en el juego si x e y tienen el mismo padre y existe una biyección f: N(x) → N(y), tal que para w ∈ N(x) y v ∈ N(y), v = f(w) implica que los pesos en las aristas (x, w) y (y, v) son iguales y los subárboles que comienzan en w y v están ordenados isomórficamente en el juego. Dos hojas (correspondientes a las señales filtradas ϑ y ϑ hasta la ronda r) están ordenadas de forma isomorfa en el juego si para todo ˜z ∈ r−1 j=1 ωj cont × ωr sobre, ur (˜z, ϑ) = ur (˜z, ϑ ). Definición 6. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y sea F un filtro de información para Γ. Sea ϑ y ϑ dos nodos donde los subárboles en el árbol de señal filtrada inducida correspondientes a los nodos ϑ y ϑ son isomorfos en el juego ordenado, y ϑ y ϑ están en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk para alguna ronda j. La transformación de abstracción isomórfica del juego ordenado se da creando un nuevo filtro de información F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i si ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ si ˜αj , ˜βj i ∈ ϑ ∪ ϑ . La Figura 1 muestra la transformación de abstracción isomórfica del juego ordenado aplicada dos veces a un pequeño juego de póker. El Teorema 2, nuestro resultado principal de equilibrio, muestra cómo la transformación de abstracción isomórfica del juego ordenado puede ser utilizada para calcular equilibrios de manera más rápida. Teorema 2. Sea Γ = I, G, L, Θ, κ, γ, p, , ω, u un juego ordenado y F un filtro de información para Γ. Sea F un filtro de información construido a partir de F mediante una aplicación de la transformación de abstracción isomórfica del juego ordenado. Sea σ un equilibrio de Nash del juego inducido ΓF. Si tomamos σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ es un equilibrio de Nash de ΓF. Prueba. Para un juego en forma extensiva, un sistema de creencias μ asigna una probabilidad a cada nodo de decisión x tal que P x∈h μ(x) = 1 para cada conjunto de información h. Un perfil estratégico σ es secuencialmente racional en h dado el sistema de creencias μ si ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) para todas las demás estrategias τi, donde i es el jugador que controla h. Un resultado básico [33, Proposición 9.C.1] que caracteriza los equilibrios de Nash dicta que σ es un equilibrio de Nash si y solo si existe un sistema de creencias μ tal que para cada conjunto de información h con Pr(h | σ) > 0, se cumplen las siguientes dos condiciones: (C1) σ es secuencialmente racional en h dado μ; y (C2) μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Dado que σ es un equilibrio de Nash de Γ, existe tal sistema de creencias μ para ΓF. Usando μ, construiremos un sistema de creencias μ para Γ y demostraremos que se cumplen las condiciones C1 y C2, apoyando así a σ como un equilibrio de Nash. Repara a algún jugador i ∈ I. Cada uno de los conjuntos de información en alguna ronda j corresponde a las señales filtradas Fj ˜α∗j , ˜β∗j i, historial en las primeras j − 1 rondas (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, y el historial hasta ahora en la ronda j, v ∈ V j \\ Zj. Deje que ˜z = (z1, . . . , zj−1, v) represente todas las acciones de los jugadores que conducen a este conjunto de información. Por lo tanto, podemos especificar de manera única este conjunto de información utilizando la información Fj ˜α∗j , ˜β∗j i , ˜z. Cada nodo en un conjunto de información corresponde a las posibles señales privadas que los otros jugadores han recibido. Denote por ˜β algún legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)). En otras palabras, existen (˜αj , ˜βj 1, . . . , ˜βj n) tal que (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) para k = i, y no se repiten señales. Usando tal conjunto de señales (˜αj , ˜βj 1, . . . , ˜βj n), sea ˆβ el conjunto (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (Abusaremos de la notación y escribiremos F j −i ˆβ = ˆβ.) Ahora podemos calcular μ directamente a partir de μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i o ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z si Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i y ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figura 1: GameShrink aplicado a un pequeño juego de póker de dos personas con cuatro cartas (dos Jotas y dos Reyes). Junto a cada árbol de juego se encuentra el rango del filtro de información F. Las líneas punteadas indican conjuntos de información, que están etiquetados por el jugador controlador. Los círculos abiertos son nodos de probabilidad con las probabilidades de transición indicadas. El nodo raíz es el nodo de probabilidad para la carta del jugador 1, y el siguiente nivel es para la carta del jugador 2. El pago de jugador 2 a jugador 1 se muestra debajo de cada hoja. En este ejemplo, el algoritmo reduce el árbol de juego de 53 nodos a 19 nodos, donde p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) . Las tres afirmaciones siguientes muestran que μ, tal como se calculó anteriormente, respalda a σ como un equilibrio de Nash. Afirmación 1. μ es un sistema de creencias válido para ΓF. Reclamo 2. Para todos los conjuntos de información h con Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) para todo x ∈ h. Afirmación 3. Para todos los conjuntos de información h con Pr(h | σ) > 0, σ es secuencialmente racional en h dado μ. Las pruebas de las Afirmaciones 1-3 se encuentran en una versión extendida de este artículo [13]. Por las afirmaciones 1 y 2, sabemos que se cumple la condición C2. Por la Reclamación 3, sabemos que se cumple la condición C1. Por lo tanto, σ es un equilibrio de Nash. 3.1 No trivialidad de la generalización más allá de este modelo Nuestro modelo no captura juegos secuenciales generales de información imperfecta porque está restringido de dos maneras (como se discutió anteriormente): 1) hay una estructura especial que conecta las acciones de los jugadores y las acciones de la suerte (por un lado, se asume que los jugadores observan las acciones de los demás, pero las acciones de la naturaleza pueden no ser observables públicamente), y 2) hay un orden común de señales. En esta subsección mostramos que eliminar cualquiera de estas condiciones puede invalidar nuestra técnica. Primero, demostramos un fallo al eliminar la primera suposición. Considera el juego en la Figura 2.6. Los nodos a y b están en el mismo conjunto de información, tienen el mismo nodo padre (de probabilidad), tienen subárboles isomórficos con los mismos pagos, y los nodos c y d también tienen propiedades estructurales similares. Al fusionar los subárboles que comienzan en a y b, obtenemos el juego de la derecha en la Figura 2. En este juego, la única estrategia de equilibrio de Nash del jugador 1 es jugar a la izquierda. Pero en el juego original, el jugador 1 sabe que el nodo c nunca será alcanzado, por lo que debería jugar a la derecha en ese conjunto de información. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figura 2: Ejemplo que ilustra la dificultad en desarrollar una teoría de abstracciones que preserven el equilibrio para juegos generales en forma extensiva. Eliminar la segunda suposición (que las funciones de utilidad se basan en un orden común de señales) también puede provocar un fallo. Considera un juego de cartas simple de tres cartas con una baraja que contiene dos Jotas (J1 y J2) y un Rey (K), donde la función de utilidad del jugador 1 se basa en el orden 6 Agradecemos a Albert Xin Jiang por proporcionar este ejemplo. 165 K J1 ∼ J2 pero la función de utilidad del jugador 2 se basa en el orden J2 K J1. Es fácil comprobar que en el juego abstracto (donde el Jugador 1 trata a J1 y J2 como equivalentes) el equilibrio de Nash no corresponde a un equilibrio de Nash en el juego original. GAMESHRINK: UN ALGORITMO EFICIENTE PARA CALCULAR TRANSFORMACIONES DE ABSTRACCIÓN DE JUEGOS ISOMÓRFICOS ORDENADOS. Esta sección presenta un algoritmo, GameShrink, para llevar a cabo las abstracciones. Solo necesita analizar el árbol de señales discutido anteriormente, en lugar de todo el árbol de juego. Primero presentamos una subrutina que utiliza GameShrink. Es un programa dinámico para calcular la relación isomórfica del juego ordenado. Nuevamente, opera en el árbol de señales. Algoritmo 1. ¿El juego ordenado es isomórfico? (Γ, ϑ, ϑ ) 1. Si ϑ y ϑ tienen padres diferentes, entonces devolver falso. Si ϑ y ϑ son ambas hojas del árbol de señales: (a) Si ur (ϑ | ˜z) = ur (ϑ | ˜z) para todo ˜z ∈ r−1 j=1 ωj cont × ωr, entonces devolver verdadero. (b) De lo contrario, devolver falso. 3. Crear un grafo bipartito Gϑ,ϑ = (V1, V2, E) con V1 = N(ϑ) y V2 = N(ϑ). 4. Para cada v1 ∈ V1 y v2 ∈ V2: Si OrderedGameIsomorphic? (Γ, v1, v2) crea un borde (v1, v2) 5. Devuelve verdadero si Gϑ,ϑ tiene un emparejamiento perfecto; de lo contrario, devuelve falso. Al evaluar este programa dinámico de abajo hacia arriba, el Algoritmo 1 determina, en tiempo polinómico en el tamaño del árbol de señales, si un par de nodos x e y de igual profundidad están ordenados de manera isomórfica en el juego. Podemos acelerar aún más este cálculo examinando solo los nodos con el mismo padre, ya que sabemos (del paso 1) que ningún nodo con padres diferentes es isomorfo al juego ordenado. El test en el paso 2(a) se puede calcular en tiempo O(1) consultando la relación de la especificación del juego. Cada llamada a OrderedGameIsomorphic? realiza a lo sumo un cálculo de emparejamiento perfecto en un grafo bipartito con O(|Θ|) nodos y O(|Θ|2) aristas (recordemos que Θ es el conjunto de señales). Utilizando el algoritmo de Ford-Fulkerson [12] para encontrar un emparejamiento maximal, esto toma tiempo O(|Θ|3). Sea S el número máximo de señales posiblemente reveladas en el juego (por ejemplo, en Rhode Island Holdem, S = 4 porque cada uno de los dos jugadores tiene una carta en la mano y además hay dos cartas en la mesa). El número de nodos, n, en el árbol de señal es O(|Θ|S). El programa dinámico visita cada nodo en el árbol de señales, con cada visita requiriendo O(|Θ|2) llamadas a la rutina OrderedGameIsomorphic?. Por lo tanto, se necesita O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) tiempo para calcular la relación isomórfica del juego ordenado completo. Si bien esto es exponencial en el número de señales reveladas, ahora mostramos que es polinómico en el tamaño del árbol de señales, y por lo tanto polinómico en el tamaño del árbol de juego. Agradecemos a una persona anónima por este ejemplo, ya que el árbol de señales es más pequeño que el árbol de juego. El número de nodos en el árbol de señal es n = 1 + ΣX i=1 ΣY j=1 (|Θ| − j + 1) (Cada término en la suma corresponde al número de nodos en una profundidad específica del árbol). El número de hojas es SY j=1 (|Θ| − j + 1) = |Θ| S ! Sí, que es una cota inferior en el número de nodos. Para |Θ| grande podemos usar la relación `n k ´ ∼ nk k! para obtener |Θ| S ! Sí! ∼ „ |Θ|S S! « S! = |Θ|S y por lo tanto el número de hojas en el árbol de señal es Ω(|Θ|S ). Por lo tanto, O(|Θ|S+5 ) = O(n|Θ|5 ), lo cual demuestra que realmente podemos calcular la relación isomórfica del juego ordenado en tiempo polinómico en el número de nodos, n, del árbol de señales. El algoritmo a menudo se ejecuta en tiempo (y espacio) sublineal en el tamaño del árbol de juego porque el árbol de señal es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales. (Tenga en cuenta que la entrada al algoritmo no es un árbol de juego explícito, sino una especificación de las reglas, por lo que el algoritmo no necesita leer el árbol de juego). Ver la Figura 1. En general, si un juego ordenado tiene r rondas, y cada juego de etapa de rondas tiene al menos b hojas no terminales, entonces el tamaño del árbol de señales es a lo sumo 1 br del tamaño del árbol de juego. Por ejemplo, en Rhode Island Holdem, el árbol de juego tiene 3.1 mil millones de nodos, mientras que el árbol de señales solo tiene 6,632,705. Dado el procedimiento OrderedGameIsomorphic? para determinar isomorfismos de juegos ordenados en un juego ordenado, estamos listos para presentar el algoritmo principal, GameShrink. Algoritmo 2. GameShrink (Γ) 1. \n\nGameShrink (Γ) 1. Inicialice F como el filtro identidad para Γ. 2. Para j de 1 a r: Para cada par de nodos hermanos ϑ, ϑ en el nivel Pj−1 k=1 ` κk + nγk ´ o Pj k=1 κk + Pj−1 k=1 nγk en el árbol de señal filtrada (de acuerdo con F): Si OrderedGameIsomorphic? (Γ, ϑ, ϑ), entonces Fj (ϑ) ← Fj (ϑ) ← Fj (ϑ) ∪ Fj (ϑ). 3. Salida F. Dado como entrada un juego ordenado Γ, GameShrink aplica las ideas de reducción presentadas anteriormente de la manera más agresiva posible. Una vez que termina, no hay nodos contractibles (ya que compara cada par de nodos en cada nivel del árbol de señales), y produce el filtro de información correspondiente F. La corrección de GameShrink se sigue de una aplicación repetida del Teorema 2. Por lo tanto, tenemos el siguiente resultado: Teorema 3. GameShrink encuentra todos los isomorfismos de juegos ordenados y aplica las transformaciones de abstracción isomórfica de juegos asociadas. Además, para cualquier equilibrio de Nash, σ, del juego abstracto, el perfil estratégico construido para el juego original a partir de σ es un equilibrio de Nash. El factor dominante en el tiempo de ejecución de GameShrink se encuentra en la r-ésima iteración del bucle principal. Hay como máximo 166 nodos `|Θ| S ´ S! en este nivel, donde nuevamente tomamos S como el número máximo de señales posiblemente reveladas en el juego. Por lo tanto, el bucle interno se ejecuta O „`|Θ| S ´ S! 2 « veces. Como se discute en la siguiente subsección, utilizamos una estructura de datos de unión-búsqueda para representar el filtro de información F. Cada iteración del bucle interno posiblemente realiza una operación de unión en la estructura de datos; realizar M operaciones en una estructura de unión-búsqueda que contiene N elementos toma un tiempo amortizado de O(α(M, N)) por operación, donde α(M, N) es la función inversa de Ackermann [1, 49] (que crece extremadamente lentamente). Por lo tanto, el tiempo total para GameShrink es O(2^n). Por la desigualdad `n k ´ ≤ nk k! , esto es O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ . Nuevamente, aunque esto es exponencial en S, es aproximadamente O(n2), donde n es el número de nodos en el árbol de señales. Además, GameShrink tiende a ejecutarse en tiempo y espacio sublineales en el tamaño del árbol de juego porque el árbol de señales es significativamente más pequeño que el árbol de juego en la mayoría de los juegos no triviales, como se discutió anteriormente. 4.1 Mejoras de eficiencia Diseñamos varias técnicas de mejora de velocidad para GameShrink, y todas están incorporadas en nuestra implementación. Una técnica es el uso de la estructura de datos de unión-búsqueda para almacenar la información del filtro F. Esta estructura de datos utiliza tiempo casi lineal en el número de operaciones [49]. Inicialmente, cada nodo en el árbol de señalización es su propio conjunto (esto corresponde al filtro de información de identidad); cuando dos nodos se contraen, se unen en un nuevo conjunto. Al finalizar, las señales filtradas para el juego abstracto corresponden exactamente a los conjuntos disjuntos en la estructura de datos. Este es un método eficiente para registrar las contracciones dentro del árbol de juego, y los requisitos de memoria son lineales solo en el tamaño del árbol de señales. Determinar si dos nodos están ordenados de forma isomorfa en un juego requiere que determinemos si un grafo bipartito tiene un emparejamiento perfecto. Podemos eliminar algunos de estos cálculos utilizando condiciones necesarias fáciles de verificar para que se cumpla la relación isomórfica del juego ordenado. Una de esas condiciones es verificar que los nodos tengan el mismo número de oportunidades de ser clasificados como más altos, más bajos y iguales que los oponentes. Podemos precalcular estas frecuencias para cada nodo del árbol de juego. Esto acelera considerablemente GameShrink, y podemos aprovechar esta base de datos en múltiples ejecuciones del algoritmo (por ejemplo, al probar diferentes niveles de abstracción; ver la siguiente sección). Los índices de esta base de datos dependen de las señales privadas y públicas, pero no del orden en que fueron reveladas, por lo que dos nodos pueden tener la misma entrada de base de datos correspondiente. Esto hace que la base de datos sea significativamente más compacta. (Por ejemplo, en Texas Holdem, la base de datos se reduce por un factor de `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.) Almacenamos los histogramas en una base de datos bidimensional. La primera dimensión está indexada por las señales privadas, la segunda por las señales públicas. El problema de calcular el índice en (cualquiera) una de las dimensiones es exactamente el problema de calcular una biyección entre todos los subconjuntos de tamaño r de un conjunto de tamaño n e enteros en ˆ 0, . . . , `n r ´ − 1 ˜. Calculamos esto de manera eficiente utilizando el orden colexicográfico de los subconjuntos [6]. Sea {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, el conjunto de r señales y suponga que ci < ci+1. Calculamos un índice único para este conjunto de señales de la siguiente manera: índice(c1, . . . , cr) = Π i=1 `ci i ´ . 5. MÉTODOS DE APROXIMACIÓN Algunos juegos son demasiado grandes para calcular un equilibrio exacto, incluso después de utilizar la técnica de abstracción presentada. Esta sección discute técnicas generales para calcular perfiles de estrategia aproximadamente óptimos. Para un juego de dos jugadores, siempre podemos evaluar el rendimiento en el peor de los casos de una estrategia, proporcionando así una evaluación objetiva de la fortaleza de la estrategia. Para ilustrar esto, supongamos que conocemos la estrategia planeada del jugador 2 para algún juego. Podemos entonces fijar las probabilidades de las acciones del jugador 2 en el árbol de juego como si fueran movimientos aleatorios. Entonces, el jugador 1 se enfrenta a un problema de decisión de un solo agente, que puede resolverse de abajo hacia arriba, maximizando la ganancia esperada en cada nodo. Por lo tanto, podemos determinar objetivamente el rendimiento esperado en el peor de los casos de la estrategia del jugador 2. Esto será muy útil cuando queramos evaluar qué tan bien se desempeña una estrategia dada cuando sabemos que no es una estrategia de equilibrio. (Una variación de esta técnica también puede aplicarse en juegos de n personas donde solo se mantienen fijas las estrategias de un jugador). Esta técnica proporciona garantías ex post sobre el rendimiento en el peor de los casos de una estrategia, y puede ser utilizada independientemente del método que se utilice para calcular las estrategias. 5.1 Aproximaciones del espacio de estados Al modificar ligeramente GameShrink, podemos obtener un algoritmo que produce árboles de juego aún más pequeños, a expensas de perder las garantías de equilibrio de Teorema 2. En lugar de requerir que los pagos en los nodos terminales coincidan exactamente, podemos en su lugar calcular una penalización que aumenta a medida que la diferencia en utilidad entre dos nodos aumenta. Hay muchas formas en las que la función de penalización podría ser definida e implementada. Una posibilidad es crear pesos en los bordes en los grafos bipartitos utilizados en el Algoritmo 1, y luego en lugar de requerir emparejamientos perfectos en el grafo no ponderado, requeriríamos emparejamientos perfectos con bajo costo (es decir, considerar dos nodos como isomorfos de juego ordenado si el grafo bipartito correspondiente tiene un emparejamiento perfecto con un costo por debajo de cierto umbral). Por lo tanto, con este umbral como parámetro, tenemos un control para ajustar que en un extremo (umbral = 0) produce una abstracción óptima y en el otro extremo (umbral = ∞) produce un juego altamente abstracto (esto, de hecho, restringiría a los jugadores a ignorar todas las señales, pero aún observando las acciones). Este botón también genera un algoritmo en cualquier momento. Se pueden resolver versiones cada vez menos abstractas del juego y evaluar la calidad de la solución en cada iteración utilizando el método ex post discutido anteriormente. 5.2 Aproximaciones algorítmicas En el caso de juegos de suma cero de dos jugadores, el cálculo del equilibrio puede modelarse como un programa lineal (PL), que a su vez puede resolverse utilizando el método simplex. Este enfoque tiene características inherentes que podemos aprovechar para obtener propiedades deseables en el contexto de resolver juegos. En la PL, las soluciones primales corresponden a las estrategias del jugador 2, y las soluciones duales corresponden a las estrategias del jugador 1. Hay dos versiones del método simplex: el simplex primal y el simplex dual. El simplex primal mantiene la viabilidad primal y avanza encontrando soluciones primales cada vez mejores hasta que el vector de solución dual sea viable, momento en el que se alcanza la optimalidad. De manera análoga, el método simplex dual mantiene la factibilidad dual y avanza encontrando soluciones duales cada vez mejores hasta que el vector de solución primal sea factible. (Se puede pensar en el método simplex dual como correr el método simplex primal en el problema dual). Por lo tanto, los métodos simplex primal y dual sirven como algoritmos en cualquier momento (para una abstracción dada) para los jugadores 2 y 1, respectivamente. En cualquier momento, pueden generar las mejores estrategias encontradas hasta el momento. Además, para cualquier solución factible del PL, podemos obtener límites sobre la calidad de las estrategias al examinar las soluciones primal y dual. (Cuando se utiliza el método simplex primal, las soluciones duales se pueden leer en el tableau del PL). Cada solución factible del dual produce una cota superior sobre el valor óptimo del primal, y viceversa [9, p. 57]. Por lo tanto, sin necesidad de realizar más cálculos, obtenemos límites inferiores sobre la utilidad esperada de la estrategia de cada agente contra el peor oponente posible de ese agente. Un problema con el método simplex es que no es un algoritmo primal-dual, es decir, no mantiene la factibilidad primal y dual a lo largo de su ejecución. (De hecho, solo obtiene la factibilidad primal y dual al final de la ejecución). Por el contrario, existen métodos de puntos interiores para la programación lineal que mantienen la factibilidad primal y dual durante toda la ejecución. Por ejemplo, muchos algoritmos de seguimiento de trayectorias de puntos interiores tienen esta propiedad [55, Cap. 5]. Observamos que al ejecutar un método de programación lineal de este tipo se obtiene un método para encontrar -equilibrios (es decir, perfiles de estrategia en los que ningún agente puede aumentar su utilidad esperada más que al desviarse). Un umbral también puede ser utilizado como criterio de terminación para utilizar el método como un algoritmo en cualquier momento. Además, los métodos de puntos interiores en esta clase tienen un tiempo de ejecución en el peor de los casos de tiempo polinómico, a diferencia del algoritmo simplex, que requiere exponencialmente muchos pasos en el peor de los casos. 6. Investigaciones RELACIONADAS Se han introducido funciones que transforman juegos en forma extensiva [50, 11]. A diferencia de nuestro trabajo, esos enfoques no eran para hacer el juego más pequeño y fácil de resolver. El resultado principal es que un juego se puede derivar de otro mediante una secuencia de esas transformaciones si y solo si los juegos tienen la misma forma normal pura reducida. La forma normal reducida pura es la forma extensiva del juego representada como un juego en forma normal donde se eliminan los duplicados de estrategias puras (es decir, aquellas con pagos idénticos) y los jugadores básicamente seleccionan clases de equivalencia de estrategias [27]. Una extensión de ese trabajo muestra un resultado similar, pero para transformaciones ligeramente diferentes y juegos en forma normal reducida mixta [21]. Existen tratamientos modernos de este trabajo previo sobre transformaciones de juegos [38, Cap. 6], [10]. La reciente noción de isomorfismo débil en juegos de forma extensiva [7] está relacionada con nuestra noción de isomorfismo de juegos restringidos. La motivación de ese trabajo era justificar conceptos de solución argumentando que son invariantes con respecto a transformaciones isomórficas. De hecho, el autor muestra, entre otras cosas, que muchos conceptos de solución, incluyendo Nash, perfecto, perfecto en subjuegos y equilibrio secuencial, son invariantes con respecto a isomorfismos débiles. Sin embargo, esa definición requiere que los juegos que se van a probar para el isomorfismo débil sean del mismo tamaño. Nuestro enfoque es totalmente diferente: encontramos juegos más pequeños estratégicamente equivalentes. Además, su artículo no proporciona algoritmos. Las técnicas de abstracción han sido utilizadas en la investigación de inteligencia artificial anteriormente. A diferencia de nuestro trabajo, la mayoría (pero no todos) de la investigación que involucra abstracción ha sido para problemas de un solo agente (por ejemplo, [20, 32]). Además, el uso de la abstracción generalmente conduce a soluciones subóptimas, a diferencia de las técnicas presentadas en este documento, que producen soluciones óptimas. Una excepción notable es el uso de la abstracción para calcular estrategias óptimas para el juego de Sprouts [2]. Sin embargo, una diferencia significativa con nuestro trabajo es que Sprouts es un juego de información perfecta. Uno de los primeros trabajos de investigación en utilizar la abstracción en entornos multiagente fue el desarrollo de la búsqueda de particiones, que es el algoritmo detrás de GIB, el primer jugador de bridge de computadora de nivel experto en el mundo [17, 18]. A diferencia de otros algoritmos de búsqueda de árboles de juego que almacenan una posición de juego particular en cada nodo del árbol de búsqueda, la búsqueda por particiones almacena grupos de posiciones que son similares. (Típicamente, la similitud entre dos posiciones de juego se calcula ignorando los componentes menos importantes de cada posición de juego y luego comprobando si las posiciones abstractas son similares, en algún sentido definido por expertos en un dominio específico). La búsqueda por partición puede llevar a mejoras sustanciales de velocidad sobre la búsqueda alfa-beta. Sin embargo, no está basado en teoría de juegos (no considera conjuntos de información en el árbol de juego), y por lo tanto no resuelve el equilibrio de un juego de información imperfecta, como el póker. Otra diferencia es que la abstracción está definida por un humano experto mientras que nuestras abstracciones se determinan automáticamente. Se ha realizado investigación sobre el uso de la abstracción en juegos de información imperfecta. Principalmente, Billings et al [4] describen una abstracción construida manualmente para el póker Texas Holdem, e incluyen resultados prometedores contra jugadores expertos. Sin embargo, este enfoque tiene inconvenientes significativos. Primero, está altamente especializado para Texas Holdem. Segundo, se utilizó una gran cantidad de conocimiento experto y esfuerzo en la construcción de la abstracción. Tercero, la abstracción no preserva el equilibrio: incluso si se aplica a un juego más pequeño, es posible que no genere un equilibrio teórico del juego. Las ideas prometedoras para la abstracción en el contexto de juegos en forma extensiva general han sido descritas en un resumen extendido [39], pero hasta donde sabemos, no han sido completamente desarrolladas. 7. CONCLUSIONES Y DISCUSIÓN Introdujimos la transformación de abstracción isomórfica del juego ordenado y presentamos un algoritmo, GameShrink, para abstraer el juego utilizando exhaustivamente el isomorfismo. Demostramos que en juegos con señales ordenadas, cualquier equilibrio de Nash en el juego abstracto más pequeño se mapea directamente a un equilibrio de Nash en el juego original. La complejidad de GameShrink es ˜O(n2), donde n es el número de nodos en el árbol de señales. No es más grande que el árbol de juego, y en juegos no triviales es drásticamente más pequeño, por lo que GameShrink tiene complejidad temporal y espacial sublineal en 8 Bridge también es un juego de información imperfecta, y la búsqueda de particiones tampoco encuentra el equilibrio para ese juego. En su lugar, la búsqueda de particiones se utiliza en conjunto con muestreo estadístico para simular la incertidumbre en el puente. También existen otros programas de puente que utilizan técnicas de búsqueda para juegos de información perfecta en conjunto con muestreo estadístico y abstracción definida por expertos [48]. Técnicas (no relacionadas con la teoría de juegos) como estas son poco probables de ser competitivas en el póker debido a la mayor importancia del ocultamiento de información y el faroleo, 168 el tamaño del árbol de juego. Usando GameShrink, encontramos un equilibrio minimax para Rhode Island Holdem, un juego de póker con 3.1 mil millones de nodos en el árbol del juego, más de cuatro órdenes de magnitud que en el mayor juego de póker resuelto previamente. Para mejorar aún más la escalabilidad, introdujimos una variante de aproximación de GameShrink, que puede ser utilizada como un algoritmo en cualquier momento al variar un parámetro que controla la grosería de la abstracción. También discutimos cómo (en un juego de suma cero de dos jugadores), la programación lineal puede ser utilizada en cualquier momento para generar estrategias aproximadamente óptimas de calidad creciente. El método también proporciona límites sobre la suboptimalidad de las estrategias resultantes. Actualmente estamos trabajando en utilizar estas técnicas para el póker Texas Holdem de límite para 2 jugadores a escala completa, un juego de cartas muy popular cuyo árbol de juego tiene alrededor de 1018 nodos. El tamaño del árbol de juego nos ha obligado a utilizar la versión de aproximación de GameShrink (así como la abstracción basada en rondas) [16, 15]. 8. REFERENCIAS [1] W. Ackermann. Al enfoque de Hilbert para la construcción de los números reales. Matemáticas. Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson y D. Sleator. Análisis computarizado de brotes. Informe técnico CMU-CS-91-144, 1991. [3] R. Bellman y D. Blackwell. Algunos juegos de dos personas que implican el engaño. PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, y D. Szafron. Aproximando estrategias óptimas de teoría de juegos para el póker a gran escala. En IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer y D. Szafron. El desafío del póker. Inteligencia Artificial, 134:201-240, 2002. [6] B. Bollobás. Combinatoria. Cambridge University Press, 1986. [7] A. Casajus. \n\nEditorial de la Universidad de Cambridge, 1986. [7] A. Casajus. Isomorfismo débil de juegos extensivos. Ciencias Sociales Matemáticas, 46:267-290, 2003. [8] X. Chen y X. Deng. Resolviendo la complejidad del equilibrio de Nash de 2 jugadores. ECCC, Informe No. 150, 2005. [9] V. Chvátal. Programación Lineal. W. H. Freeman & Co., 1983. [10] B. P. de Bruin. \n\nW. H. Freeman & Co., 1983. [10] B. P. de Bruin. Transformaciones de juegos y equivalencia de juegos. Nota técnica x-1999-01, Universidad de Ámsterdam, Instituto de Lógica, Lenguaje y Computación, 1999. [11] S. Elmes y P. J. Reny. Sobre la equivalencia estratégica de juegos en forma extensiva. Revista de Teoría Económica, 62:1-23, 1994. [12] L. R. Ford, Jr. y D. R. Fulkerson. Flujos en redes. Princeton University Press, 1962. [13] A. Gilpin y T. Sandholm. Encontrar equilibrios en juegos secuenciales grandes de información imperfecta. Informe técnico CMU-CS-05-158, Universidad Carnegie Mellon, 2005. [14] A. Gilpin y T. Sandholm. Póker Texas Hold'em óptimo de Rhode Island. En AAAI, páginas 1684-1685, Pittsburgh, PA, EE. UU., 2005. [15] A. Gilpin y T. Sandholm. Un jugador competitivo de póker Texas Holdem a través de abstracción automatizada y cálculo de equilibrio en tiempo real. Mimeo, 2006. [16] A. Gilpin y T. Sandholm. Un jugador de póker Texas Holdem basado en abstracción automatizada y cálculo de equilibrio en tiempo real. En AAMAS, Hakodate, Japón, 2006. [17] M. L. Ginsberg. Búsqueda de particiones. En AAAI, páginas 228-233, Portland, Oregón, 1996. [18] M. L. Ginsberg. GIB: Pasos hacia un programa de juego de bridge de nivel experto. En IJCAI, Estocolmo, Suecia, 1999. [19] S. Govindan y R. Wilson. Un método de Newton global para calcular equilibrios de Nash. Rev. Econ. Teoría, 110:65-86, 2003. [20] C. A. Knoblock. Generando automáticamente abstracciones para la planificación. Inteligencia Artificial, 68(2):243-302, 1994. [21] E. Kohlberg y J.-F. Mertens. Sobre la estabilidad estratégica de los equilibrios. Econometrica, 54:1003-1037, 1986. [22] D. Koller y N. Megiddo. La complejidad de los juegos de suma cero de dos personas en forma extensiva. Juegos y Comportamiento Económico, 4(4):528-552, Oct. 1992. [23] D. Koller y N. Megiddo. Encontrar estrategias mixtas con soportes pequeños en juegos de forma extensiva. Revista Internacional de Teoría de Juegos, 25:73-92, 1996. [24] D. Koller, N. Megiddo y B. von Stengel. Cálculo eficiente de equilibrios para juegos extensivos de dos personas. Juegos y Comportamiento Económico, 14(2):247-259, 1996. [25] D. Koller y A. Pfeffer. Representaciones y soluciones para problemas de teoría de juegos. Inteligencia Artificial, 94(1):167-215, julio de 1997. [26] D. M. Kreps y R. Wilson. Equilibrios secuenciales. Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.\nEconometrica, 50(4):863-894, 1982. [27] H. W. Kuhn. Juegos extensos. PNAS, 36:570-576, 1950. [28] H. W. Kuhn. \n\nPNAS, 36:570-576, 1950. [28] H. W. Kuhn. Un póker simplificado para dos personas. En Contribuciones a la Teoría de Juegos, volumen 1 de los Anales de Estudios de Matemáticas, 24, páginas 97-103. Prensa de la Universidad de Princeton, 1950. [29] H. W. Kuhn. Juegos extensivos y el problema de la información. En Contribuciones a la Teoría de Juegos, volumen 2 de los Anales de Estudios de Matemáticas, 28, páginas 193-216. Princeton University Press, 1953. [30] C. Lemke y J. Howson. Puntos de equilibrio de juegos bimatrix. Revista de la Sociedad de Matemáticas Industriales y Aplicadas, 12:413-423, 1964. [31] R. Lipton, E. Markakis y A. Mehta. Jugando juegos grandes utilizando estrategias simples. En ACM-EC, páginas 36-41, 2003. [32] C.-L. Liu y M. Wellman. Abstracción de espacio de estados para la evaluación en cualquier momento de redes bayesianas. Boletín de SIGART, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston y J. R. Green. Teoría microeconómica. Oxford University Press, 1995. [34] R. D. McKelvey y A. McLennan. Cálculo de equilibrios en juegos finitos. En el Manual de Economía Computacional, volumen 1, páginas 87-142. Elsevier, 1996. [35] P. B. Miltersen y T. B. Sørensen. Calculando equilibrios secuenciales para juegos de dos jugadores. En SODA, páginas 107-116, 2006. [36] J. Nash. Puntos de equilibrio en juegos de n personas. Proc. de la Academia Nacional de Ciencias, 36:48-49, 1950. [37] J. F. Nash y L. S. Shapley. Un juego de póker sencillo para tres personas. En Contribuciones a la Teoría de Juegos, volumen 1, páginas 105-116. Princeton University Press, 1950. [38] A. Perea. \n\nPrensa de la Universidad de Princeton, 1950. [38] A. Perea. Racionalidad en juegos de forma extensiva. Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller y K. Takusagawa. Aproximaciones de espacio de estados para juegos en forma extensiva, julio de 2000. Conferencia presentada en el Primer Congreso Internacional de la Sociedad de Teoría de Juegos, Bilbao, España. [40] R. Porter, E. Nudelman y Y. Shoham. Métodos de búsqueda simples para encontrar un equilibrio de Nash. En AAAI, páginas 664-669, San José, CA, EE. UU., 2004. [41] I. Romanovskii. Reducción de un juego con memoria completa a un juego de matriz. Matemáticas Soviéticas, 3:678-681, 1962. [42] T. Sandholm y A. Gilpin. Secuencias de ofertas de tómalo o déjalo: Subastas casi óptimas sin revelación completa de la valoración. En AAMAS, Hakodate, Japón, 2006. [43] T. Sandholm, A. Gilpin y V. Conitzer. Métodos de programación entera mixta para encontrar equilibrios de Nash. En AAAI, páginas 495-501, Pittsburgh, PA, EE. UU., 2005. [44] R. Savani y B. von Stengel. Exponencialmente muchos pasos para encontrar un equilibrio de Nash en un juego de bimatrix. En FOCS, páginas 258-267, 2004. [45] R. Selten. Tratamiento teórico del modelo de oligopolio con inercia en la demanda. Revista de Ciencias Políticas, 12:301-324, 1965. [46] R. Selten. Estabilidad evolutiva en juegos extensivos de dos personas - corrección y desarrollo adicional. Ciencias Sociales Matemáticas, 16:223-266, 1988. [47] J. Shi y M. Littman. Métodos de abstracción para el póker teórico de juegos. En Computadoras y Juegos, páginas 333-345. Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau y T. Throop. Bridge informático: Una gran victoria para la planificación de IA. Revista de Inteligencia Artificial, 19(2):93-105, 1998. [49] R. E. Tarjan. Eficiencia de un algoritmo de unión de conjuntos bueno pero no lineal. Revista de la ACM, 22(2):215-225, 1975. [50] F. Thompson. Equivalencia de juegos en forma extensiva. Memorando RM-759 de RAND, The RAND Corporation, enero de 1952. [51] J. von Neumann y O. Morgenstern. Teoría de juegos y comportamiento económico. Princeton University Press, 1947. [52] B. von Stengel. \n\nPrensa de la Universidad de Princeton, 1947. [52] B. von Stengel. Cálculo eficiente de estrategias de comportamiento. Juegos y Comportamiento Económico, 14(2):220-246, 1996. [53] B. von Stengel. Calculando equilibrios para juegos de dos personas. En el Manual de Teoría de Juegos, volumen 3. Holanda del Norte, Ámsterdam, 2002. [54] R. Wilson. Calculando los equilibrios de juegos de dos personas a partir de la forma extensiva. Ciencia de la Gestión, 18(7):448-460, 1972. [55] S. J. Wright. Métodos de Puntos Interiores Primal-Dual. SIAM, 1997. 169 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "computer poker": {
            "translated_key": "póquer de computadora",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Finding Equilibria in Large Sequential Games of Imperfect Information∗ Andrew Gilpin Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA gilpin@cs.cmu.edu Tuomas Sandholm Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA sandholm@cs.cmu.edu ABSTRACT Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games.",
                "To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation.",
                "For a multi-player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game.",
                "We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively.",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes-over four orders of magnitude more than in the largest poker game solved previously.",
                "We discuss several electronic commerce applications for GameShrink.",
                "To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close-to-optimal strategies.",
                "Categories and Subject Descriptors: I.2 [Artificial Intelligence], F. [Theory of Computation], J.4 [Social and Behavioral Sciences]: Economics.",
                "General Terms: Algorithms, Economics, Theory. 1.",
                "INTRODUCTION In environments with more than one agent, an agents outcome is generally affected by the actions of the other agent(s).",
                "Consequently, the optimal action of one agent can depend on the others.",
                "Game theory provides a normative framework for analyzing such strategic situations.",
                "In particular, it provides solution concepts that define what rational behavior is in such settings.",
                "The most famous and important solution concept is that of Nash equilibrium [36].",
                "It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy.",
                "However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium.",
                "Games can be classified as either games of perfect information or imperfect information.",
                "Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type.",
                "To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes.",
                "If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom-up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ-pruning to reduce the search tree size and thus enhance speed).",
                "Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agents turn to move, she does not have access to all of the information about the world.",
                "In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time.",
                "Thus the algorithms for perfect information games do not solve games of imperfect information.",
                "For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45]. 2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game-playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves. 3 An -equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52].",
                "By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2-player games, there is a polynomial-sized (in the size of the game tree) linear programming formulation (linear complementarity in the non-zero-sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables.",
                "Thus, the equilibria of reasonable-sized 2-player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real-world games, such as poker. 1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation.",
                "Instead of developing an equilibrium-finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game.",
                "Thus, by computing an equilibrium in the smaller game (using any available equilibrium-finding algorithm), we are able to construct an equilibrium in the original game.",
                "The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game.",
                "To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes.",
                "Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives.",
                "They are used in our analysis and abstraction algorithm.",
                "By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding.",
                "We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3).",
                "As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD-complete even in a 2-player game [8].",
                "The most prevalent algorithm for finding an equilibrium in a 2-agent game is Lemke-Howson [30], but it takes exponentially many steps in the worst case [44].",
                "For a survey of equilibrium computation in 2-player games, see [53].",
                "Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43].",
                "For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40]. 4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23]. 5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35].",
                "Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ).",
                "If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .",
                "The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes rule.",
                "We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game.",
                "We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4).",
                "Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree.",
                "We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5). 1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions.",
                "Often aspects of a players knowledge are not pertinent for deciding what action the player should take at a given point in the game.",
                "On the trivial end, some aspects of a players knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification.",
                "However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely.",
                "Furthermore, it may be highly non-obvious which aspects are pertinent in which states of the game.",
                "Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation.",
                "One broad application area that has this property is sequential negotiation (potentially over multiple issues).",
                "Another broad application area is sequential auctions (potentially over multiple goods).",
                "For example, in those states of a 1-object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about Bs signals, although that information would be relevant for inferring Bs exact valuation.",
                "Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities).",
                "Many open-cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take-it-or-leave-it offers [42].",
                "Our techniques are in no way specific to an application.",
                "The main experiment that we present in this paper is on 161 a recreational game.",
                "We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games). 1.3 Rhode Island Holdem poker Poker is an enormously popular card game played around the world.",
                "The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event.",
                "Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments.",
                "Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents cards, opponents future actions, and chance moves, among other reasons [5].",
                "Almost since the fields founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp. 186-219].",
                "However, this work was limited to tiny games that could be solved by hand.",
                "More recently, AI researchers have been applying the computational power of modern hardware to computing game theory-based strategies for larger games.",
                "Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25].",
                "Large-scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies.",
                "Furthermore, the approximations were designed manually by a human expert.",
                "Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies performance.",
                "Rhode Island Holdem was invented as a testbed for computational game playing [47].",
                "It was designed so that it was similar in style to Texas Holdem, yet not so large that devising reasonably intelligent strategies would be impossible. (The rules of Rhode Island Holdem, as well as a discussion of how Rhode Island Holdem can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].)",
                "We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Holdem, which has a game tree exceeding 3.1 billion nodes.",
                "Applying the sequence form to Rhode Island Holdem directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns.",
                "This is much too large for (current) linear programming algorithms to handle.",
                "We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns-with 50,428,638 non-zero coefficients.",
                "We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns. (Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.)",
                "GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations).",
                "Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior-point barrier method of CPLEX version 9.1.2.",
                "We recently demonstrated our optimal Rhode Island Holdem poker player at the AAAI-05 conference [14], and it is available for play on-line at http://www.cs.cmu.edu/ ~gilpin/gsi.html.",
                "While others have worked on computer programs for playing Rhode Island Holdem [47], no optimal strategy has been found before.",
                "This is the largest poker game solved to date by over four orders of magnitude. 2.",
                "GAMES WITH ORDERED SIGNALS We work with a slightly restricted class of games, as compared to the full generality of the extensive form.",
                "This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations.",
                "A game with ordered signals consists of a finite number of rounds.",
                "Within a round, the players play a game on a directed tree (the tree can be different in different rounds).",
                "The only uncertainty players face stems from private signals the other players have received and from the unknown future signals.",
                "In other words, players observe each others actions, but potentially not natures actions.",
                "In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players).",
                "For simplicity, we assume-as is the case in most recreational games-that within each round, the number of private signals received is the same across players (this could quite likely be relaxed).",
                "We also assume that the legal actions that a player has are independent of the signals received.",
                "For example, in poker, the legal betting actions are independent of the cards received.",
                "Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals.",
                "For example, in poker, this partial ordering corresponds exactly to the ranking of card hands.",
                "Definition 1.",
                "A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: 1.",
                "I = {1, . . . , n} is a finite set of players. 2.",
                "G = G1 , . . . , Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .",
                "Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .",
                "Gj is the stage game for round j. 3.",
                "L = L1 , . . . , Lr , Lj : V j \\ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. 4.",
                "Θ is a finite set of signals. 5. κ = κ1 , . . . , κr and γ = γ1 , . . . , γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j.",
                "Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ|.",
                "The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , . . . , αj ´ .",
                "The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , . . . , βj i ´ .",
                "We 162 also write ˜βj = ˜βj 1, . . . , ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, . . . , ˜βj i−1, ˜β j i , ˜βj i+1, . . . , ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .",
                "The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated. 6. p is a probability distribution over Θ, with p(θ) > 0 for all θ ∈ Θ.",
                "Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y /∈X p(y) if x /∈ X 0 if x ∈ X. 7. is a partial ordering of subsets of Θ and is defined for at least those pairs required by u. 8. ω : rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round.",
                "Clearly, we require ω(z) = over for all z ∈ Zr .",
                "Note that ω is independent of the signals.",
                "Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. 9. u = (u1 , . . . , ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk . (b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a players utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i  ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .",
                "We will use the term game with ordered signals and the term ordered game interchangeably. 2.1 Information filters In this subsection, we define an information filter for ordered games.",
                "Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player.",
                "By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact.",
                "We will use this when designing our abstraction techniques.",
                "Formally, an information filter is as follows.",
                "Definition 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game.",
                "Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j.",
                "An information filter for Γ is a collection F = F1 , . . . , Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: 1. (Truthfulness) (˜αj , ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). 2. (Independence) The range of Fj is a partition of Sj . 3. (Information preservation) If two values of a signal are distinguishable in round k, then they are distinguishable fpr each round j > k. Let mj = Pj l=1 κl +γl .",
                "We require that for all legal (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ and (θ1, . . . , θmk , . . . , θmj ) ⊆ Θ: (θ1, . . . , θmk ) /∈ Fk (θ1, . . . , θmk ) =⇒ (θ1, . . . , θmk , . . . , θmj ) /∈ Fj (θ1, . . . , θmk , . . . , θmj ).",
                "A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .",
                "We refer to such games as filtered ordered games.",
                "We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .",
                "We have the following simple (but important) result: Proposition 1.",
                "A filtered ordered game is an extensive form game satisfying perfect recall.",
                "A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall.",
                "In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring. 2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games.",
                "Definition 3.",
                "A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \\Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o . (Δ(X) is the set of probability distributions over a finite set X.)",
                "A behavior strategy for player i in round j is σj i = (σj i,v1 , . . . , σj i,vm ) for each vk ∈ V j \\ Zj where Lj (vk) = i.",
                "A behavior strategy for player i in Γ is σi = ` σ1 i , . . . , σr i ´ .",
                "A strategy profile is σ = (σ1, . . . , σn).",
                "A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, . . . , σi−1, σi, σi+1, . . . , σn).",
                "By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ.",
                "Strategy σi is said to be player is best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i). σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i.",
                "A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29].",
                "Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1.",
                "For any filtered ordered game, a Nash equilibrium exists in behavior strateges. 3.",
                "EQUILIBRIUM-PRESERVING ABSTRACTIONS In this section, we present our main technique for reducing the size of games.",
                "We begin by defining a filtered signal tree which represents all of the chance moves in the game.",
                "The bold edges (i.e. the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game.",
                "Definition 4.",
                "Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals.",
                "The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time.",
                "The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .",
                "We denote children of a node x as N(x).",
                "In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached.",
                "In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game.",
                "By melding these situations together, it is possible to arrive at a strategically equivalent smaller game.",
                "The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation.",
                "Definition 5.",
                "Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic.",
                "Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ).",
                "Definition 6.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ.",
                "Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round j.",
                "The ordered game isomorphic abstraction transformation is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i /∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .",
                "Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game.",
                "Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster.",
                "Theorem 2.",
                "Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ.",
                "Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation.",
                "Let σ be a Nash equilibrium of the induced game ΓF .",
                "If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .",
                "Proof.",
                "For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h. A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls h. A basic result [33, Proposition 9.C.1] characterizing Nash equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .",
                "Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium.",
                "Fix some player i ∈ I.",
                "Each of is information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, . . . , zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \\ Zj .",
                "Let ˜z = (z1, . . . , zj−1, v) represent all of the player actions leading to this information set.",
                "Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .",
                "Each node in an information set corresponds to the possible private signals the other players have received.",
                "Denote by ˜β some legal (Fj (˜αj , ˜βj 1), . . . , Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), . . . , Fj (˜αj , ˜βj n)).",
                "In other words, there exists (˜αj , ˜βj 1, . . . , ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated.",
                "Using such a set of signals (˜αj , ˜βj 1, . . . , ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), . . . , F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), . . . , F j (˜αj , ˜βj n). (We will abuse notation and write F j −i ˆβ = ˆβ .)",
                "We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0-1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -1 -1 -1 -1 -1-1 -1 -1 -1 -1 -10 0 0 0 0 0 0 0 0 -1 -2 -2 -1 -2 -2 -1 -2 -2 -1 -2 -2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0-1 -1 -1 -1 -1 -1 -1 -2 -2 -1 -2 -2 2 2 2 2 2 2 -1 -1-1 -1 0 0 0 1 2 2 -1 -1-1 -1 0 0 0 1 2 2 c b C B F B f b -1 -10 0 0 c b B F B f b -1 -1-1 -2 -2 c b C BF B f b 0 0 0-1 -1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 -1 -1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1/4 1/4 1/4 1/4 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/3 1/4 1/41/2 1/3 1/3 1/3 1/32/3 1/32/3 1/2 1/2 1/3 2/3 2/3 1/3 Figure 1: GameShrink applied to a tiny two-person four-card (two Jacks and two Kings) poker game.",
                "Next to each game tree is the range of the information filter F. Dotted lines denote information sets, which are labeled by the controlling player.",
                "Open circles are chance nodes with the indicated transition probabilities.",
                "The root node is the chance node for player 1s card, and the next level is for player 2s card.",
                "The payment from player 2 to player 1 is given below each leaf.",
                "In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes. where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .",
                "The following three claims show that μ as calculated above supports σ as a Nash equilibrium.",
                "Claim 1. μ is a valid belief system for ΓF .",
                "Claim 2.",
                "For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h. Claim 3.",
                "For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ.",
                "The proofs of Claims 1-3 are in an extended version of this paper [13].",
                "By Claims 1 and 2, we know that condition C2 holds.",
                "By Claim 3, we know that condition C1 holds.",
                "Thus, σ is a Nash equilibrium. 3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others actions, but natures actions might not be publicly observable), and 2) there is a common ordering of signals.",
                "In this subsection we show that removing either of these conditions can make our technique invalid.",
                "First, we demonstrate a failure when removing the first assumption.",
                "Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties.",
                "By merging the subtrees beginning at a and b, we get the game on the right in Figure 2.",
                "In this game, player 1s only Nash equilibrium strategy is to play left.",
                "But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set. 1/4 1/4 1/4 1/4 2 2 2 1 1 1 2 1 2 3 0 3 0 -10 10 1/2 1/4 1/4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10-10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium-preserving abstractions for general extensive form games.",
                "Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure.",
                "Consider a simple three-card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example. 165 K J1 ∼ J2 but player 2s utility function is based on the ordering J2 K J1.",
                "It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 4.",
                "GAMESHRINK: AN EFFICIENT ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions.",
                "It only needs to analyze the signal tree discussed above, rather than the entire game tree.",
                "We first present a subroutine that GameShrink uses.",
                "It is a dynamic program for computing the ordered game isomorphic relation.",
                "Again, it operates on the signal tree.",
                "Algorithm 1.",
                "OrderedGameIsomorphic? (Γ, ϑ, ϑ ) 1.",
                "If ϑ and ϑ have different parents, then return false. 2.",
                "If ϑ and ϑ are both leaves of the signal tree: (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true. (b) Otherwise, return false. 3.",
                "Create a bipartite graph Gϑ,ϑ = (V1, V2, E) with V1 = N(ϑ) and V2 = N(ϑ ). 4.",
                "For each v1 ∈ V1 and v2 ∈ V2: If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) 5.",
                "Return true if Gϑ,ϑ has a perfect matching; otherwise, return false.",
                "By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic.",
                "We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic.",
                "The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game.",
                "Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals).",
                "Using the Ford-Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time.",
                "Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Holdem, S = 4 because each of the two players has one card in the hand plus there are two cards on the table).",
                "The number of nodes, n, in the signal tree is O(|Θ|S ).",
                "The dynamic program visits each node in the signal tree, with each visit requiring O(|Θ|2 ) calls to the OrderedGameIsomorphic? routine.",
                "So, it takes O(|Θ|S |Θ|3 |Θ|2 ) = O(|Θ|S+5 ) time to compute the entire ordered game isomorphic relation.",
                "While this is exponential in the number of revealed signals, we now show that it is polynomial in the size of the signal tree-and thus polynomial in the size of the game tree 7 We thank an anonymous person for this example. because the signal tree is smaller than the game tree.",
                "The number of nodes in the signal tree is n = 1 + SX i=1 iY j=1 (|Θ| − j + 1) (Each term in the summation corresponds to the number of nodes at a specific depth of the tree.)",
                "The number of leaves is SY j=1 (|Θ| − j + 1) = |Θ| S !",
                "S! which is a lower bound on the number of nodes.",
                "For large |Θ| we can use the relation `n k ´ ∼ nk k! to get |Θ| S !",
                "S! ∼ „ |Θ|S S! « S! = |Θ|S and thus the number of leaves in the signal tree is Ω(|Θ|S ).",
                "Thus, O(|Θ|S+5 ) = O(n|Θ|5 ), which proves that we can indeed compute the ordered game isomorphic relation in time polynomial in the number of nodes, n, of the signal tree.",
                "The algorithm often runs in sublinear time (and space) in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games. (Note that the input to the algorithm is not an explicit game tree, but a specification of the rules, so the algorithm does not need to read in the game tree.)",
                "See Figure 1.",
                "In general, if an ordered game has r rounds, and each rounds stage game has at least b nonterminal leaves, then the size of the signal tree is at most 1 br of the size of the game tree.",
                "For example, in Rhode Island Holdem, the game tree has 3.1 billion nodes while the signal tree only has 6,632,705.",
                "Given the OrderedGameIsomorphic? routine for determining ordered game isomorphisms in an ordered game, we are ready to present the main algorithm, GameShrink.",
                "Algorithm 2.",
                "GameShrink (Γ) 1.",
                "Initialize F to be the identity filter for Γ. 2.",
                "For j from 1 to r: For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic? (Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). 3.",
                "Output F. Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible.",
                "Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F. The correctness of GameShrink follows by a repeated application of Theorem 2.",
                "Thus, we have the following result: Theorem 3.",
                "GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations.",
                "Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium.",
                "The dominating factor in the run time of GameShrink is in the rth iteration of the main for-loop.",
                "There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game.",
                "Thus, the inner for-loop executes O „`|Θ| S ´ S! 2 « times.",
                "As discussed in the next subsection, we use a union-find data structure to represent the information filter F. Each iteration of the inner for-loop possibly performs a union operation on the data structure; performing M operations on a union-find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermanns function [1, 49] (which grows extremely slowly).",
                "Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .",
                "By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .",
                "Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above. 4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation.",
                "One technique is the use of the union-find data structure for storing the information filter F. This data structure uses time almost linear in the number of operations [49].",
                "Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set.",
                "Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure.",
                "This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree.",
                "Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching.",
                "We can eliminate some of these computations by using easy-to-check necessary conditions for the ordered game isomorphic relation to hold.",
                "One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents.",
                "We can precompute these frequencies for every game tree node.",
                "This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section).",
                "The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry.",
                "This makes the database significantly more compact. (For example in Texas Holdem, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ / `50 5 ´ = 20.)",
                "We store the histograms in a 2-dimensional database.",
                "The first dimension is indexed by the private signals, the second by the public signals.",
                "The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, . . . , `n r ´ − 1 ˜ .",
                "We efficiently compute this using the subsets colexicographical ordering [6].",
                "Let {c1, . . . , cr}, ci ∈ {0, . . . , n − 1}, denote the r signals and assume that ci < ci+1.",
                "We compute a unique index for this set of signals as follows: index(c1, . . . , cr) = Pr i=1 `ci i ´ . 5.",
                "APPROXIMATION METHODS Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique.",
                "This section discusses general techniques for computing approximately optimal strategy profiles.",
                "For a two-player game, we can always evaluate the worst-case performance of a strategy, thus providing some objective evaluation of the strength of the strategy.",
                "To illustrate this, suppose we know player 2s planned strategy for some game.",
                "We can then fix the probabilities of player 2s actions in the game tree as if they were chance moves.",
                "Then player 1 is faced with a single-agent decision problem, which can be solved bottomup, maximizing expected payoff at every node.",
                "Thus, we can objectively determine the expected worst-case performance of player 2s strategy.",
                "This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy. (A variation of this technique may also be applied in n-person games where only one players strategies are held fixed.)",
                "This technique provides ex post guarantees about the worst-case performance of a strategy, and can be used independently of the method that is used to compute the strategies. 5.1 State-space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2.",
                "Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases.",
                "There are many ways in which the penalty function could be defined and implemented.",
                "One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold).",
                "Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions).",
                "This knob also begets an anytime algorithm.",
                "One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above. 5.2 Algorithmic approximations In the case of two-player zero-sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method.",
                "This approach has inherent features which we can leverage into desirable properties in the context of solving games.",
                "In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player 1.",
                "There are two versions of the simplex method: the primal simplex and the dual simplex.",
                "The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached.",
                "Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible. (The dual simplex method can be thought of as running the primal simplex method on the dual problem.)",
                "Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively.",
                "At any point in time, they can output the best strategies found so far.",
                "Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions. (When using the primal simplex method, dual solutions may be read off of the LP tableau.)",
                "Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p. 57].",
                "Thus, without requiring further computation, we get lower bounds on the expected utility of each agents strategy against that agents worst-case opponent.",
                "One problem with the simplex method is that it is not a primal-dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution. (In fact, it only obtains primal and dual feasibility at the very end of execution.)",
                "In contrast, there are interior-point methods for linear programming that maintain primal and dual feasibility throughout the execution.",
                "For example, many interiorpoint path-following algorithms have this property [55, Ch. 5].",
                "We observe that running such a linear programming method yields a method for finding -equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating).",
                "A threshold on can also be used as a termination criterion for using the method as an anytime algorithm.",
                "Furthermore, interior-point methods in this class have polynomial-time worst-case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. 6.",
                "RELATED RESEARCH Functions that transform extensive form games have been introduced [50, 11].",
                "In contrast to our work, those approaches were not for making the game smaller and easier to solve.",
                "The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form.",
                "The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27].",
                "An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21].",
                "Modern treatments of this prior work on game transformations exist [38, Ch. 6], [10].",
                "The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism.",
                "The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations.",
                "Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms.",
                "However, that definition requires that the games to be tested for weak isomorphism are of the same size.",
                "Our focus is totally different: we find strategically equivalent smaller games.",
                "Also, their paper does not provide algorithms.",
                "Abstraction techniques have been used in artificial intelligence research before.",
                "In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g. [20, 32]).",
                "Furthermore, the use of abstraction typically leads to sub-optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions.",
                "A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2].",
                "However, a significant difference to our work is that Sprouts is a game of perfect information.",
                "One of the first pieces of research to use abstraction in multi-agent settings was the development of partition search, which is the algorithm behind GIB, the worlds first expertlevel computer bridge player [17, 18].",
                "In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar. (Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar-in some domain-specific expert-defined sense-to each other.)",
                "Partition search can lead to substantial speed improvements over α-β-search.",
                "However, it is not game theory-based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically.",
                "There has been some research on the use of abstraction for imperfect information games.",
                "Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Holdem poker, and include promising results against expert players.",
                "However, this approach has significant drawbacks.",
                "First, it is highly specialized for Texas Holdem.",
                "Second, a large amount of expert knowledge and effort was used in constructing the abstraction.",
                "Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game-theoretic equilibrium.",
                "Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. 7.",
                "CONCLUSIONS AND DISCUSSION We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively.",
                "We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game.",
                "The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree.",
                "It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either.",
                "Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge.",
                "There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert-defined abstraction [48].",
                "Such (non-game-theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing. 168 the size of the game tree.",
                "Using GameShrink, we found a minimax equilibrium to Rhode Island Holdem, a poker game with 3.1 billion nodes in the game tree-over four orders of magnitude more than in the largest poker game solved previously.",
                "To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction.",
                "We also discussed how (in a two-player zero-sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality.",
                "The method also yields bounds on the suboptimality of the resulting strategies.",
                "We are currently working on using these techniques for full-scale 2-player limit Texas Holdem poker, a highly popular card game whose game tree has about 1018 nodes.",
                "That game tree size has required us to use the approximation version of GameShrink (as well as round-based abstraction) [16, 15]. 8.",
                "REFERENCES [1] W. Ackermann.",
                "Zum Hilbertschen Aufbau der reellen Zahlen.",
                "Math.",
                "Annalen, 99:118-133, 1928. [2] D. Applegate, G. Jacobson, and D. Sleator.",
                "Computer analysis of sprouts.",
                "Technical Report CMU-CS-91-144, 1991. [3] R. Bellman and D. Blackwell.",
                "Some two-person games involving bluffing.",
                "PNAS, 35:600-605, 1949. [4] D. Billings, N. Burch, A. Davidson, R. Holte, J. Schaeffer, T. Schauenberg, and D. Szafron.",
                "Approximating game-theoretic optimal strategies for full-scale poker.",
                "In IJCAI, 2003. [5] D. Billings, A. Davidson, J. Schaeffer, and D. Szafron.",
                "The challenge of poker.",
                "Artificial Intelligence, 134:201-240, 2002. [6] B. Bollob´as.",
                "Combinatorics.",
                "Cambridge University Press, 1986. [7] A. Casajus.",
                "Weak isomorphism of extensive games.",
                "Mathematical Social Sciences, 46:267-290, 2003. [8] X. Chen and X. Deng.",
                "Settling the complexity of 2-player Nash equilibrium.",
                "ECCC, Report No. 150, 2005. [9] V. Chv´atal.",
                "Linear Programming.",
                "W. H. Freeman & Co., 1983. [10] B. P. de Bruin.",
                "Game transformations and game equivalence.",
                "Technical note x-1999-01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999. [11] S. Elmes and P. J. Reny.",
                "On the strategic equivalence of extensive form games.",
                "J. of Economic Theory, 62:1-23, 1994. [12] L. R. Ford, Jr. and D. R. Fulkerson.",
                "Flows in Networks.",
                "Princeton University Press, 1962. [13] A. Gilpin and T. Sandholm.",
                "Finding equilibria in large sequential games of imperfect information.",
                "Technical Report CMU-CS-05-158, Carnegie Mellon University, 2005. [14] A. Gilpin and T. Sandholm.",
                "Optimal Rhode Island Holdem poker.",
                "In AAAI, pages 1684-1685, Pittsburgh, PA, USA, 2005. [15] A. Gilpin and T. Sandholm.",
                "A competitive Texas Holdem poker player via automated abstraction and real-time equilibrium computation.",
                "Mimeo, 2006. [16] A. Gilpin and T. Sandholm.",
                "A Texas Holdem poker player based on automated abstraction and real-time equilibrium computation.",
                "In AAMAS, Hakodate, Japan, 2006. [17] M. L. Ginsberg.",
                "Partition search.",
                "In AAAI, pages 228-233, Portland, OR, 1996. [18] M. L. Ginsberg.",
                "GIB: Steps toward an expert-level bridge-playing program.",
                "In IJCAI, Stockholm, Sweden, 1999. [19] S. Govindan and R. Wilson.",
                "A global Newton method to compute Nash equilibria.",
                "J. of Econ.",
                "Theory, 110:65-86, 2003. [20] C. A. Knoblock.",
                "Automatically generating abstractions for planning.",
                "Artificial Intelligence, 68(2):243-302, 1994. [21] E. Kohlberg and J.-F. Mertens.",
                "On the strategic stability of equilibria.",
                "Econometrica, 54:1003-1037, 1986. [22] D. Koller and N. Megiddo.",
                "The complexity of two-person zero-sum games in extensive form.",
                "Games and Economic Behavior, 4(4):528-552, Oct. 1992. [23] D. Koller and N. Megiddo.",
                "Finding mixed strategies with small supports in extensive form games.",
                "International Journal of Game Theory, 25:73-92, 1996. [24] D. Koller, N. Megiddo, and B. von Stengel.",
                "Efficient computation of equilibria for extensive two-person games.",
                "Games and Economic Behavior, 14(2):247-259, 1996. [25] D. Koller and A. Pfeffer.",
                "Representations and solutions for game-theoretic problems.",
                "Artificial Intelligence, 94(1):167-215, July 1997. [26] D. M. Kreps and R. Wilson.",
                "Sequential equilibria.",
                "Econometrica, 50(4):863-894, 1982. [27] H. W. Kuhn.",
                "Extensive games.",
                "PNAS, 36:570-576, 1950. [28] H. W. Kuhn.",
                "A simplified two-person poker.",
                "In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97-103.",
                "Princeton University Press, 1950. [29] H. W. Kuhn.",
                "Extensive games and the problem of information.",
                "In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193-216.",
                "Princeton University Press, 1953. [30] C. Lemke and J. Howson.",
                "Equilibrium points of bimatrix games.",
                "Journal of the Society for Industrial and Applied Mathematics, 12:413-423, 1964. [31] R. Lipton, E. Markakis, and A. Mehta.",
                "Playing large games using simple strategies.",
                "In ACM-EC, pages 36-41, 2003. [32] C.-L. Liu and M. Wellman.",
                "On state-space abstraction for anytime evaluation of Bayesian networks.",
                "SIGART Bulletin, 7(2):50-57, 1996. [33] A. Mas-Colell, M. Whinston, and J. R. Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [34] R. D. McKelvey and A. McLennan.",
                "Computation of equilibria in finite games.",
                "In Handbook of Computational Economics, volume 1, pages 87-142.",
                "Elsevier, 1996. [35] P. B. Miltersen and T. B. Sørensen.",
                "Computing sequential equilibria for two-player games.",
                "In SODA, pages 107-116, 2006. [36] J. Nash.",
                "Equilibrium points in n-person games.",
                "Proc. of the National Academy of Sciences, 36:48-49, 1950. [37] J. F. Nash and L. S. Shapley.",
                "A simple three-person poker game.",
                "In Contributions to the Theory of Games, volume 1, pages 105-116.",
                "Princeton University Press, 1950. [38] A. Perea.",
                "Rationality in extensive form games.",
                "Kluwer Academic Publishers, 2001. [39] A. Pfeffer, D. Koller, and K. Takusagawa.",
                "State-space approximations for extensive form games, July 2000.",
                "Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain. [40] R. Porter, E. Nudelman, and Y. Shoham.",
                "Simple search methods for finding a Nash equilibrium.",
                "In AAAI, pages 664-669, San Jose, CA, USA, 2004. [41] I. Romanovskii.",
                "Reduction of a game with complete memory to a matrix game.",
                "Soviet Mathematics, 3:678-681, 1962. [42] T. Sandholm and A. Gilpin.",
                "Sequences of take-it-or-leave-it offers: Near-optimal auctions without full valuation revelation.",
                "In AAMAS, Hakodate, Japan, 2006. [43] T. Sandholm, A. Gilpin, and V. Conitzer.",
                "Mixed-integer programming methods for finding Nash equilibria.",
                "In AAAI, pages 495-501, Pittsburgh, PA, USA, 2005. [44] R. Savani and B. von Stengel.",
                "Exponentially many steps for finding a Nash equilibrium in a bimatrix game.",
                "In FOCS, pages 258-267, 2004. [45] R. Selten.",
                "Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit.",
                "Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301-324, 1965. [46] R. Selten.",
                "Evolutionary stability in extensive two-person games - correction and further development.",
                "Mathematical Social Sciences, 16:223-266, 1988. [47] J. Shi and M. Littman.",
                "Abstraction methods for game theoretic poker.",
                "In Computers and Games, pages 333-345.",
                "Springer-Verlag, 2001. [48] S. J. J. Smith, D. S. Nau, and T. Throop.",
                "Computer bridge: A big win for AI planning.",
                "AI Magazine, 19(2):93-105, 1998. [49] R. E. Tarjan.",
                "Efficiency of a good but not linear set union algorithm.",
                "Journal of the ACM, 22(2):215-225, 1975. [50] F. Thompson.",
                "Equivalence of games in extensive form.",
                "RAND Memo RM-759, The RAND Corporation, Jan. 1952. [51] J. von Neumann and O. Morgenstern.",
                "Theory of games and economic behavior.",
                "Princeton University Press, 1947. [52] B. von Stengel.",
                "Efficient computation of behavior strategies.",
                "Games and Economic Behavior, 14(2):220-246, 1996. [53] B. von Stengel.",
                "Computing equilibria for two-person games.",
                "In Handbook of Game Theory, volume 3.",
                "North Holland, Amsterdam, 2002. [54] R. Wilson.",
                "Computing equilibria of two-person games from the extensive form.",
                "Management Science, 18(7):448-460, 1972. [55] S. J. Wright.",
                "Primal-Dual Interior-Point Methods.",
                "SIAM, 1997. 169"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}