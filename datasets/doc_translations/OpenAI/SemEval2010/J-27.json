{
    "id": "J-27",
    "original_text": "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price. Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable. Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand. Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast. The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts. Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples. We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17]. Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1. INTRODUCTION A market is an institution by which economic agents meet and make transactions. Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist. The preference relation is therefore the key factor in understanding consumer behavior. One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint. This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory. Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave. This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable? Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint? Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference. Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable. These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions. Hence, an infinite amount of information is needed to refute the theory. It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility. Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations. If such parameters exist, we conclude that the stipulated utility form is consistent with the observations. This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices. The downside of this approach is that real life data is often inconsistent with convenient functional forms. Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization. Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data. He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions? He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference. Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function. Afriat [1] gives another set of rationalizability conditions the observations must satisfy. Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally. It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]). Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency. Varian [20] took this one step further progressing from consistency to forecasting. Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP. Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric. Knoblauch [9] shows these envelopes can be computed efficiently. Varian [21] provides an up to date survey on this line of research. A different approach is presented by Blundell et al. [3, 4]. These papers introduce a model where an agent observes prices and Engel curves for these prices. This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior. This model is in a sense a hybrid between Mas-Colell and Afriats aproaches. The former requires full information for all prices, the latter for a finite number of prices. On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories. The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information. Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget. Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds. Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner. However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations. Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast. In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions. We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable. Our first result is negative. We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable. However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable. In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy. In section 2 we briefly discuss the basic assumptions of demand theory and their implications. In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17]. We show that this algorithm is computationally efficient and can be used as a learning algorithm. In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions. We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity. We also sketch results on upper bounds. In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2. UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles. A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility. The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y). This reflects the assumption that agents will always prefer more of any one good. This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities. However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed. The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing. This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other. These assumptions imply that the utility function is concave and monotone on the observations. The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set. W.l.g. we assume u has marginal utility zero outside [0, 1]d . Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices. We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d. Note that with this metric ∆d is compact. A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d. This property reflects an assumption that preferences and demands have some sort of stability. It rules out different demands for the similar prices. We may therefore assume from here on that demand functions are single valued. 3. REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen. It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi. Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0. Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0. We call the latter condition the Afriat condition (AC). This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient. Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A. The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight. Theorem 1. There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC. Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC. In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible. The construction provides a utility function that is consistent with the observations. Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm. The construction is executed in two steps. First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise. The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles. Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints. Now we describe how to choose the sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise. D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn. Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 . We show that for this choice of s, D(A, s) contains no negative weight cycle. Suppose C = (i1, . . . , ik) is a cycle in D(A, s). If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done. Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1). For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv. Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s). If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction. Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q). Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0. Let p denote a vertex in C with the second smallest potential. Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero. To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set. Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4. SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling. This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations. The labels are usually binary values indicating the membership of the observed points in the set that is being learned. However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors. The learning problem has three major components: estimation, approximation and complexity. The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces. The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class. The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function. A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family. Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree. The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients. The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial. The complexity problem would be the assessment of the time required to compute the polynomial coefficients. In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class. It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed. If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points. The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling. The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations. The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast. In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices. Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +. The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity. An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4. Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree. In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation. Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability. Rather we are content with having small mean square errors on all coordinates. Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ. For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 . A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h). In the case of revealed preference, there is a function that takes the sample error to zero. Nevertheless, the upper bounds theorem we use does not require the sample error to be zero. Definition 1. A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ. There may be several learning algorithms for C with different sample complexities. The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p). A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p). For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]). An analog to this notion of dimension for real functions is the fat shattering dimension. We use an adaptation of this notion to real vector valued function sets. Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +. Definition 2. For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1. We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ. If this size is unbounded then the dimension is infinite. To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity. Lemma 2. Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}. Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d . Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d . This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3. Suppose that C is a class of functions mapping from Γ to Rd +. Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs. Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample. We construct such a distribution. Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}. Let fb be a function chosen uniformly at random from CS. It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss. Therefore Eb(||fb(p) − h(p)||∞) > 2ε. Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε. This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 . W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension. The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted. Theorem 4. Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞. Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m . Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5. LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations. As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from. We compute the fat shattering dimension for two classes of demands. The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable. The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz. We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant. Theorem 5. Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center. Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1). For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience). To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i . To show that such a function exists it suffices to show that Afriats conditions are satisfied. Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1. This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi . In fact, pick a utility function whose level sets are parallel to the budget constraint. Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference. To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling. For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices. Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j. This implies that if there is a negative cycle then all the points in the cycle must belong to the same level. The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope. Thus, the polytope defines a utility function for which these demands are utility maximizing. The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level. It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles. In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support. Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set. We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes. We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6. Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L . A standard packing argument implies n ≤ (L γ )d ✷ 6. ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7. REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference. Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference? European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function. The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis. The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality. Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory. Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption. In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42",
    "original_translation": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i. Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat. Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1. Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi. De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina. Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i. Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo. Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad. La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una función de utilidad monótona cóncava y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes. En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto. Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado. Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio. Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6. Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L. Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6. AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas. Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada? Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero. La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas. La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava. Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada. Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42",
    "original_sentences": [
        "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
        "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
        "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
        "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
        "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
        "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
        "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
        "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
        "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
        "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
        "The preference relation is therefore the key factor in understanding consumer behavior.",
        "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
        "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
        "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
        "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
        "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
        "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
        "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
        "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
        "Hence, an infinite amount of information is needed to refute the theory.",
        "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
        "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
        "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
        "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
        "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
        "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
        "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
        "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
        "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
        "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
        "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
        "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
        "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
        "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
        "Varian [20] took this one step further progressing from consistency to forecasting.",
        "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
        "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
        "Knoblauch [9] shows these envelopes can be computed efficiently.",
        "Varian [21] provides an up to date survey on this line of research.",
        "A different approach is presented by Blundell et al. [3, 4].",
        "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
        "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
        "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
        "The former requires full information for all prices, the latter for a finite number of prices.",
        "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
        "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
        "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
        "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
        "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
        "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
        "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
        "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
        "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
        "Our first result is negative.",
        "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
        "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
        "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
        "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
        "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
        "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
        "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
        "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
        "We also sketch results on upper bounds.",
        "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
        "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
        "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
        "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
        "This reflects the assumption that agents will always prefer more of any one good.",
        "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
        "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
        "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
        "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
        "These assumptions imply that the utility function is concave and monotone on the observations.",
        "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
        "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
        "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
        "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
        "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
        "Note that with this metric ∆d is compact.",
        "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
        "This property reflects an assumption that preferences and demands have some sort of stability.",
        "It rules out different demands for the similar prices.",
        "We may therefore assume from here on that demand functions are single valued. 3.",
        "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
        "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
        "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
        "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
        "We call the latter condition the Afriat condition (AC).",
        "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
        "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
        "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
        "Theorem 1.",
        "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
        "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
        "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
        "The construction provides a utility function that is consistent with the observations.",
        "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
        "The construction is executed in two steps.",
        "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
        "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
        "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
        "Now we describe how to choose the sis.",
        "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
        "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
        "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
        "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
        "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
        "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
        "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
        "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
        "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
        "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
        "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
        "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
        "Let p denote a vertex in C with the second smallest potential.",
        "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
        "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
        "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
        "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
        "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
        "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
        "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
        "The learning problem has three major components: estimation, approximation and complexity.",
        "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
        "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
        "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
        "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
        "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
        "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
        "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
        "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
        "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
        "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
        "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
        "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
        "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
        "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
        "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
        "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
        "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
        "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
        "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
        "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
        "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
        "Rather we are content with having small mean square errors on all coordinates.",
        "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
        "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
        "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
        "In the case of revealed preference, there is a function that takes the sample error to zero.",
        "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
        "Definition 1.",
        "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
        "There may be several learning algorithms for C with different sample complexities.",
        "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
        "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
        "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
        "An analog to this notion of dimension for real functions is the fat shattering dimension.",
        "We use an adaptation of this notion to real vector valued function sets.",
        "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
        "Definition 2.",
        "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
        "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
        "If this size is unbounded then the dimension is infinite.",
        "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
        "Lemma 2.",
        "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
        "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
        "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
        "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
        "Suppose that C is a class of functions mapping from Γ to Rd +.",
        "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
        "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
        "We construct such a distribution.",
        "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
        "Let fb be a function chosen uniformly at random from CS.",
        "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
        "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
        "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
        "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
        "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
        "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
        "Theorem 4.",
        "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
        "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
        "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
        "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
        "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
        "We compute the fat shattering dimension for two classes of demands.",
        "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
        "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
        "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
        "Theorem 5.",
        "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
        "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
        "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
        "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
        "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
        "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
        "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
        "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
        "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
        "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
        "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
        "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
        "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
        "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
        "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
        "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
        "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
        "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
        "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
        "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
        "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
        "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
        "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
        "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
        "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
        "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
        "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
        "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
        "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
        "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
        "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
        "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
        "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
        "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
    ],
    "translated_text_sentences": [
        "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio.",
        "Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable.",
        "Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda.",
        "Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción.",
        "El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones.",
        "Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas.",
        "También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17].",
        "Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1.",
        "INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones.",
        "La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes.",
        "La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor.",
        "Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria.",
        "Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor.",
        "Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas.",
        "Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría?",
        "¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria?",
        "Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada.",
        "Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables.",
        "Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda.",
        "Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría.",
        "A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad.",
        "La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski.",
        "Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones.",
        "Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos.",
        "El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes.",
        "Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad.",
        "Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos.",
        "¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas?",
        "Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada.",
        "Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona.",
        "Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir.",
        "Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente.",
        "Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]).",
        "Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia.",
        "Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción.",
        "El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP.",
        "Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria.",
        "Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente.",
        "Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación.",
        "Un enfoque diferente es presentado por Blundell et al. [3, 4].",
        "Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios.",
        "Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores.",
        "Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats.",
        "El primero requiere información completa para todos los precios, el segundo para un número finito de precios.",
        "Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios.",
        "La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica.",
        "Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto.",
        "Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados.",
        "Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable.",
        "Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones.",
        "Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico.",
        "En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat.",
        "Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible.",
        "Nuestro primer resultado es negativo.",
        "Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC.",
        "Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC.",
        "En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión.",
        "En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones.",
        "En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17].",
        "Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje.",
        "En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales.",
        "Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra.",
        "También esbozamos resultados sobre límites superiores.",
        "En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2.",
        "La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos.",
        "Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada.",
        "La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y).",
        "Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien.",
        "Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades.",
        "Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados.",
        "La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes.",
        "Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro.",
        "Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones.",
        "La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto.",
        "Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d.",
        "Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios.",
        "Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
        "Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d.",
        "Ten en cuenta que con esta métrica ∆d es compacto.",
        "Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d.",
        "Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad.",
        "Descarta diferentes demandas por precios similares.",
        "Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3.",
        "Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero.",
        "Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi.",
        "Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0.",
        "Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0.",
        "Llamamos a esta última condición la condición de Afriat (AC).",
        "Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente.",
        "Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A.",
        "La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo.",
        "Teorema 1.",
        "Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC.",
        "Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC.",
        "En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible.",
        "La construcción proporciona una función de utilidad que es consistente con las observaciones.",
        "Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje.",
        "La construcción se ejecuta en dos pasos.",
        "Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario.",
        "El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos.",
        "Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones.",
        "Ahora describimos cómo elegir el sis.",
        "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso.",
        "D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn.",
        "Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1.",
        "Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo.",
        "Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s).",
        "Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado.",
        "De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1).",
        "Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv.",
        "Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s).",
        "Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción.",
        "Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q).",
        "Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0.",
        "Que p denote un vértice en C con el segundo menor potencial.",
        "Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero.",
        "Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado.",
        "Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4.",
        "APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas.",
        "Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras.",
        "Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo.",
        "Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales.",
        "El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad.",
        "El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce.",
        "El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente.",
        "El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo.",
        "Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia.",
        "Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado.",
        "El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes.",
        "El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio.",
        "El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio.",
        "En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase.",
        "También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija.",
        "Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos.",
        "La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado.",
        "La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras.",
        "El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción.",
        "En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados.",
        "Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +.",
        "La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra.",
        "Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4.",
        "Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo.",
        "En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación.",
        "Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad.",
        "Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas.",
        "Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ.",
        "Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2.",
        "Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h).",
        "En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero.",
        "Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero.",
        "Definición 1.",
        "Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ.",
        "Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra.",
        "El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p).",
        "Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p).",
        "Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]).",
        "Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa.",
        "Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales.",
        "Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +.",
        "Definición 2.",
        "Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1.",
        "Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ.",
        "Si este tamaño no tiene límites, entonces la dimensión es infinita.",
        "Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra.",
        "Lema 2.",
        "Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}.",
        "Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d.",
        "Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d.",
        "Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3.",
        "Supongamos que C es una clase de funciones que mapean de Γ a Rd +.",
        "Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades.",
        "Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande.",
        "Construimos tal distribución.",
        "Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}.",
        "Sea fb una función elegida de forma uniforme al azar de CS.",
        "Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa.",
        "Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε.",
        "Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε.",
        "Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0.",
        "Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita.",
        "El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite.",
        "Teorema 4.",
        "Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞.",
        "Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m.",
        "Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5.",
        "APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones.",
        "Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan.",
        "Calculamos la dimensión de fragmentación de grasa para dos clases de demandas.",
        "El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC.",
        "La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso.",
        "Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos.",
        "Teorema 5.",
        "Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro.",
        "Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1).",
        "Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional).",
        "Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i.",
        "Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat.",
        "Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1.",
        "Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi.",
        "De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria.",
        "Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina.",
        "Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado.",
        "Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i.",
        "Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j.",
        "Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel.",
        "Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo.",
        "Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad.",
        "La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel.",
        "Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una función de utilidad monótona cóncava y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes.",
        "En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto.",
        "Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado.",
        "Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio.",
        "Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6.",
        "Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +.",
        "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L.",
        "Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6.",
        "AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7.",
        "REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas.",
        "Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada?",
        "Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero.",
        "La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado.",
        "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas.",
        "La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava.",
        "Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada.",
        "Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo.",
        "En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42"
    ],
    "error_count": 11,
    "keys": {
        "learning from revealed preference": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>learning from revealed preference</br> [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "<br>learning from revealed preference</br> Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "<br>learning from revealed preference</br> [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "<br>learning from revealed preference</br> Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations."
            ],
            "translated_annotated_samples": [
                "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio.",
                "APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i. Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat. Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1. Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi. De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina. Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i. Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo. Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad. La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una función de utilidad monótona cóncava y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes. En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto. Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado. Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio. Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6. Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L. Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6. AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas. Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada? Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero. La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas. La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava. Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada. Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "complexity problem": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The <br>complexity problem</br> is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The <br>complexity problem</br> would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "The <br>complexity problem</br> is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "The <br>complexity problem</br> would be the assessment of the time required to compute the polynomial coefficients."
            ],
            "translated_annotated_samples": [
                "El <br>problema de la complejidad</br> se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo.",
                "El <br>problema de complejidad</br> sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El <br>problema de la complejidad</br> se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El <br>problema de complejidad</br> sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i. Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat. Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1. Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi. De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina. Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i. Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo. Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad. La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una función de utilidad monótona cóncava y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes. En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto. Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado. Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio. Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6. Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L. Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6. AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas. Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada? Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero. La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas. La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava. Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada. Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42 ",
            "candidates": [],
            "error": [
                [
                    "problema de la complejidad",
                    "problema de complejidad"
                ]
            ]
        },
        "forecast": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the <br>forecast</br>.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good <br>forecast</br> for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good <br>forecast</br> or the degree of confidence in such a <br>forecast</br>.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a <br>forecast</br> and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to <br>forecast</br> for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to <br>forecast</br> demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to <br>forecast</br> the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the <br>forecast</br> it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the <br>forecast</br>.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to <br>forecast</br> demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by <br>forecast</br> and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the <br>forecast</br>.",
                "Both these methods would most likely give a good <br>forecast</br> for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good <br>forecast</br> or the degree of confidence in such a <br>forecast</br>.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a <br>forecast</br> and a probabilistic estimate on its accuracy.",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to <br>forecast</br> for these prices."
            ],
            "translated_annotated_samples": [
                "Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la <br>predicción</br>.",
                "Ambos métodos probablemente proporcionarían un buen <br>pronóstico</br> para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable.",
                "Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen <br>pronóstico</br> o el grado de confianza en dicho <br>pronóstico</br>.",
                "En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un <br>pronóstico</br> y una estimación probabilística sobre su precisión.",
                "Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la <br>predicción</br>. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen <br>pronóstico</br> para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen <br>pronóstico</br> o el grado de confianza en dicho <br>pronóstico</br>. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un <br>pronóstico</br> y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. ",
            "candidates": [],
            "error": [
                [
                    "predicción",
                    "pronóstico",
                    "pronóstico",
                    "pronóstico",
                    "pronóstico"
                ]
            ]
        },
        "probably approximately correct": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the <br>probably approximately correct</br> (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is <br>probably approximately correct</br> (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "In the <br>probably approximately correct</br> (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "A set of demand functions C is <br>probably approximately correct</br> (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ."
            ],
            "translated_annotated_samples": [
                "En el paradigma <br>probablemente aproximadamente correcto</br> (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase.",
                "Un conjunto de funciones de demanda C es probablemente aprendible de manera <br>aproximadamente correcta</br> (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma <br>probablemente aproximadamente correcto</br> (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera <br>aproximadamente correcta</br> (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i. Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat. Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1. Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi. De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina. Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i. Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo. Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad. La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una función de utilidad monótona cóncava y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes. En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto. Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado. Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio. Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6. Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L. Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6. AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas. Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada? Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero. La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas. La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava. Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada. Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42 ",
            "candidates": [],
            "error": [
                [
                    "probablemente aproximadamente correcto",
                    "aproximadamente correcta"
                ]
            ]
        },
        "monotone concave utility function": {
            "translated_key": "función de utilidad monótona cóncava",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a <br>monotone concave utility function</br> and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with <br>monotone concave utility function</br> maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a <br>monotone concave utility function</br> and subject to a budget constraint?",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with <br>monotone concave utility function</br> maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles."
            ],
            "translated_annotated_samples": [
                "¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una <br>función de utilidad monótona cóncava</br> y sujeto a una restricción presupuestaria?",
                "Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una <br>función de utilidad monótona cóncava</br> y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una <br>función de utilidad monótona cóncava</br> y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i. Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat. Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1. Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi. De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina. Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i. Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo. Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad. La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una <br>función de utilidad monótona cóncava</br> y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes. En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto. Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado. Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio. Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6. Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L. Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6. AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas. Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada? Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero. La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas. La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava. Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada. Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "demand function": {
            "translated_key": "función de demanda",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire <br>demand function</br> and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed <br>demand function</br> after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The <br>demand function</br> of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a <br>demand function</br> that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A <br>demand function</br> is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a <br>demand function</br> fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a <br>demand function</br> fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire <br>demand function</br> and rely heavily on the differential properties of demand functions.",
                "Both these methods would most likely give a good forecast for a fixed <br>demand function</br> after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "The <br>demand function</br> of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a <br>demand function</br> that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "A <br>demand function</br> is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a <br>demand function</br> fb supported by concave utility such that fb(pi) = yb i ."
            ],
            "translated_annotated_samples": [
                "Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la <br>función de demanda</br> y dependen en gran medida de las propiedades diferenciales de las funciones de demanda.",
                "Ambos métodos probablemente proporcionarían un buen pronóstico para una <br>función de demanda</br> fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable.",
                "La <br>función de demanda</br> del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una <br>función de demanda</br> que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto.",
                "Una <br>función de demanda</br> es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d.",
                "Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una <br>función de demanda</br> fb respaldada por utilidad cóncava tal que fb(pi) = yb i."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la <br>función de demanda</br> y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una <br>función de demanda</br> fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La <br>función de demanda</br> del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una <br>función de demanda</br> que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una <br>función de demanda</br> es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una <br>función de demanda</br> fb respaldada por utilidad cóncava tal que fb(pi) = yb i. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "rationalizability": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that <br>rationalizability</br> of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to <br>rationalizability</br> by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of <br>rationalizability</br> conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for <br>rationalizability</br> are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for <br>rationalizability</br>; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "He showes that <br>rationalizability</br> of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to <br>rationalizability</br> by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of <br>rationalizability</br> conditions the observations must satisfy.",
                "It is interesting to note that these necessary and sufficient conditions for <br>rationalizability</br> are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "This argument shows that AC is necessary for <br>rationalizability</br>; the surprising result in Afriats theorem is that this condition is also sufficient."
            ],
            "translated_annotated_samples": [
                "Él demuestra que la <br>racionalización</br> de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada.",
                "Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la <br>racionalizabilidad</br> por una función de utilidad estrictamente cóncava y monótona.",
                "Afriat [1] propone otro conjunto de <br>condiciones de racionalidad</br> que las observaciones deben cumplir.",
                "Es interesante notar que estas condiciones necesarias y suficientes para la <br>racionalización</br> son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]).",
                "Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la <br>racionalización</br> de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la <br>racionalizabilidad</br> por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de <br>condiciones de racionalidad</br> que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la <br>racionalización</br> son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. ",
            "candidates": [],
            "error": [
                [
                    "racionalización",
                    "racionalizabilidad",
                    "condiciones de racionalidad",
                    "racionalización"
                ]
            ]
        },
        "finite set of observation": {
            "translated_key": "conjunto finito de observaciones",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a <br>finite set of observation</br>s is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a <br>finite set of observation</br>s is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "He askes when can it be determined that a <br>finite set of observation</br>s is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a <br>finite set of observation</br>s is equivalent to the strong axiom of revealed preference."
            ],
            "translated_annotated_samples": [
                "¿Él pregunta cuándo se puede determinar que un <br>conjunto finito de observaciones</br> es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas?",
                "Él demuestra que la racionalización de un <br>conjunto finito de observaciones</br> es equivalente al fuerte axioma de la preferencia revelada."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un <br>conjunto finito de observaciones</br> es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un <br>conjunto finito de observaciones</br> es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y Lipschitz en el ingreso. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la constante de Lipschitz de ingresos. Teorema 5. Sea C un conjunto de funciones de demanda de Rd + a Rd +, entonces fatC(γ) = ∞. Prueba 1: Para ε > 0, sea pi = 2−i p para i = 1, . . . , n un conjunto de vectores de precios que inducen conjuntos de presupuesto paralelos Bi y sea x1, . . . , xn la intersección de estos hiperplanos con una línea ortogonal que pasa por el centro. Sean H0 y H1 hiperplanos que no son paralelos a p y sean xi ∈ Bi ∩ (xi + H+ 0 ) y xi ∈ Bi ∩ (xi + H− 1 ) para i = 1 . . . n (ver figura 1). Para cualquier etiquetado b = (b1, . . . , bn) ∈ {0, 1}n, sea y = y(b) = (y1, . . . , yn) un conjunto de demandas tal que yi = xi si bi = 0 e yi = xi si bi = 1 (omitimos un índice adicional b en y por conveniencia notacional). Para demostrar que p1, . . . , pn está destrozado, basta con encontrar para cada b una función de demanda fb respaldada por utilidad cóncava tal que fb(pi) = yb i. Para demostrar que tal función existe, basta con mostrar que se cumplen las condiciones de Afriat. Dado que yi está en el conjunto de presupuesto 40, yi · 2−i p = 1, por lo tanto pi · (yj − yi) = 2j−i − 1. Esto muestra que pi · (yj − yi) ≤ 0 si y solo si j < i, por lo tanto no puede haber ciclos negativos y se cumple la condición. ✷ Prueba 2: Las funciones de utilidad que satisfacen la condición de Afriat en la primera prueba podrían ser triviales asignando la misma utilidad a xi que a xi. De hecho, elige una función de utilidad cuyos conjuntos de nivel sean paralelos a la restricción presupuestaria. Por lo tanto, la ruptura de los precios p1, . . . , pn es el resultado de la indiferencia en lugar de una preferencia genuina. Para evitar este problema reproducimos el teorema construyendo funciones de utilidad u tales que u(xi) = u(xi) para todo i y, por lo tanto, una función de utilidad distinta se asocia con cada etiquetado. Para i = 1, . . . n, dejemos que pi1, . . . , pid sean vectores de precios que satisfacen las siguientes condiciones: 1. los conjuntos de presupuesto Bs i son hiperplanos de soporte de un politopo convexo Λi 2. yi es un vértice de Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) para s = 1, . . . d y j = 1, . . . , n. Finalmente, dejemos que yi1, . . . , yid sean puntos en las facetas de Λi que intersectan a yi, de manera que ||pjr||1 · ||yi − yis||∞ = o(1) para todos los j, s y r. Llamamos al conjunto de puntos yi, yi1, . . . , yid la demanda del nivel i y a pi, pi1, . . . , pid los precios del nivel i. Aplicando la desigualdad de H¨older obtenemos |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) Esto muestra que pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) por lo tanto pir · (yjs − yir) ≤ 0 si y solo si j < i o i = j. Esto implica que si hay un ciclo negativo, entonces todos los puntos en el ciclo deben pertenecer al mismo nivel. Los puntos de cualquier nivel yacen en las facetas de un politopo Λi y los precios pis son hiperplanos de soporte del politopo. Por lo tanto, el politopo define una función de utilidad para la cual estas demandas maximizan la utilidad. La otra dirección del teorema de Afriat implica, por lo tanto, que no puede haber ciclos negativos entre puntos en el mismo nivel. Se deduce que no hay ciclos negativos para la unión de observaciones de todos los niveles, por lo tanto, la secuencia de observaciones (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) es consistente con la maximización de una función de utilidad monótona cóncava y nuevamente, por el teorema de Afriat, existe una función de utilidad u que respalda una función de demanda fb ✷ La prueba anterior se basa en el hecho de que un agente tiene una alta utilidad y utilidad marginal para paquetes muy grandes. En muchos casos es razonable asumir que el marginal para paquetes muy grandes es muy pequeño, o incluso que la utilidad o la utilidad marginal tienen un soporte compacto. Desafortunadamente, reescalar el ejemplo anterior muestra que incluso un conjunto compacto puede contener un conjunto grande destrozado. Sin embargo, observamos que en este caso obtenemos una función de utilidad que produce funciones de demanda muy sensibles a pequeños cambios de precio. Mostramos que la clase de funciones de utilidad que tienen utilidades marginales con soporte compacto y para las cuales las funciones de demanda relevantes son Lipschitzianas en ingresos tiene una dimensión de fragmentación finita. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0) H0 H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figura 1: Función de utilidad fragmentando x1 y x2 Teorema 6. Sea C un conjunto de funciones de demanda L-ingreso-Lipschitz de ∆d a Rd + para alguna constante global L ∈ R. Entonces fatC(γ) ≤ ( L γ )d Prueba: Sea p1, . . . , pn ∈ ∆d un conjunto destrozado con testigos x1, . . . , xn ∈ Rd +. W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ lo que implica xi + H− 1 ∩ xj + H+ 1 = ∅, para una etiqueta b = (b1, . . . , bn) ∈ {0, 1}n tal que bi = 0 y bj = 1, ||fb(pi) − fb(pj)||∞ > γ por lo tanto ||pi − pj||∞ > γ L. Un argumento de empaquetamiento estándar implica que n ≤ (L γ )d ✷ 6. AGRADECIMIENTOS Los autores desean agradecer a Eli Shamir, Ehud Kalai, Julio González Díaz, Rosa Matzkin, Gad Allon y Adam Galambos por las discusiones y sugerencias útiles. 7. REFERENCIAS [1] Afriat S. N. (1967) La construcción de una función de utilidad a partir de datos de gastos. International Economic Review 8, 67-77. [2] Anthony M. y Bartlett P. L. (1999) Aprendizaje de redes neuronales: Fundamentos teóricos. Cambridge University Press. [3] Blundell R., Browning M. y Crawford I. (2003) Curvas de Engel no paramétricas y preferencias reveladas. Econometrica, 71(1):205-240. [4] Blundell R. (2005) ¿Qué tan reveladora es la preferencia revelada? Revista Económica Europea 3, 211 - 235. [5] Diewert E. (1973) Afriat y la Teoría de la Preferencia Revelada Revisión de Estudios Económicos 40, 419 - 426. [6] Farkas J. (1902) ¨Sobre la Teoría de las Desigualdades Simples Journal für die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Preferencia Revelada y la Función de Utilidad Economica 17, 159 - 174. [8] Kearns M. y Vazirani U. (1994) Una Introducción a la Teoría Computacional del Aprendizaje The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) Un Límite Superior Ajustado en la Función de Utilidad Métrica del Dinero. La American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) La recuperabilidad de las preferencias de los consumidores a partir de la demanda del mercado. Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) Sobre el análisis de preferencias reveladas. La Revisión de Estudios Económicos, 45(1):121-131. [12] Mas-Colell A., Whinston M. y Green J. R. (1995) Teoría Microeconómica Oxford University Press. [13] Matzkin R. y Richter M. (1991) Prueba de Racionalidad Estrictamente Cóncava. Revista de Teoría Económica, 53:287-303. [14] Papadimitriou C. H. y Steiglitz K. (1982) Optimización Combinatoria Dover Publications inc. [15] Richter M. (1966) Teoría de la Preferencia Revelada. Econometrica, 34(3):635-645. [16] Uzawa H. (1960) Preferencia y elección racional en la teoría del consumo. En K. J. Arrow, S. Karlin y P. Suppes, editores, Modelos Matemáticos en Ciencias Sociales, Stanford University Press, Stanford, CA. [17] Teo C. P. y Vohra R. V. (2003) Teorema de Afriat y Ciclos Negativos, Documento de Trabajo [18] Samuelson P. A. (1948) Teoría del Consumo en Términos de Preferencia Revelada, Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Teoría del Aprendizaje Estadístico, John Wiley & Sons Inc. [20] Varian H. R. (1982) El Enfoque No Paramétrico para el Análisis de la Demanda, Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Preferencia Revelada, En Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Conferencias sobre Politopos, Springer. 42 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "observation finite set": {
            "translated_key": "conjunto finito de observaciones",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "income-lipschitz": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of <br>income-lipschitz</br> and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global <br>income-lipschitz</br> constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-<br>income-lipschitz</br>, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and <br>income-lipschitz</br>.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the <br>income-lipschitz</br> constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-<br>income-lipschitz</br> demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of <br>income-lipschitz</br> and showed that demand functions with this property are rationalizable.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global <br>income-lipschitz</br> constant. 2.",
                "A demand function is L-<br>income-lipschitz</br>, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and <br>income-lipschitz</br>.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the <br>income-lipschitz</br> constant."
            ],
            "translated_annotated_samples": [
                "Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de <br>Lipschitz de ingreso</br> y demostraron que las funciones de demanda con esta propiedad son racionalizables.",
                "En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2.",
                "Una función de demanda es <br>L-ingreso-Lipschitz</br>, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d.",
                "La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y <br>Lipschitz en el ingreso</br>.",
                "Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la <br>constante de Lipschitz de ingresos</br>."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de <br>Lipschitz de ingreso</br> y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la dimensión de fragmentación de grasa, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la dimensión de fragmentación de grasa es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de dimensión de fragmentación de conjuntos gordos y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la dimensión de fat shattering de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es <br>L-ingreso-Lipschitz</br>, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la dimensión de fragmentación de grasa. Utilizamos una adaptación de esta noción a conjuntos de funciones vectoriales reales. Sea Γ ⊂ Rd + y sea C un conjunto de funciones reales de Γ a Rd +. Definición 2. Para γ > 0, un conjunto de puntos p1, . . . , pn ∈ Γ es γ-roto por una clase de funciones reales C si existen x1, . . . , xn ∈ Rd + y hiperplanos afines paralelos H0, H1 ⊂ Rd tales que 0 ∈ H− 0 ∩ H+ 1, dist(H0, H1) > γ y para cada b = (b1, . . . , bn) ∈ {0, 1}n existe una función fb ∈ C tal que fb(pi) ∈ xi + H+ 0 si bi = 0 y f(pi) ∈ xi + H− 1 si bi = 1. Definimos la dimensión de γ-fragmentación de C, denotada como fatC(γ), como el tamaño máximo de un conjunto γ-fragmentado en Γ. Si este tamaño no tiene límites, entonces la dimensión es infinita. Para demostrar la utilidad de esta noción, la utilizamos para derivar un límite inferior en la complejidad de la muestra. Lema 2. Supongamos que las funciones {fb : b ∈ {0, 1}n } son testigos del shattering de {p1, . . . , pn}. Entonces, para cualquier x ∈ Rd + y etiquetas b, b ∈ {0, 1}n tales que bi = bi, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb (pi) − x||∞ > γ 2d. Prueba: Dado que el máximo excede la media, se sigue que si fb y fb corresponden a etiquetas tales que bi = bi, entonces ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d. Esto implica que para cualquier x ∈ Rd +, ya sea ||fb(pi) − x||∞ > γ 2d o ||fb(pi) − x||∞ > γ 2d ✷ Teorema 3. Supongamos que C es una clase de funciones que mapean de Γ a Rd +. Entonces, cualquier algoritmo de aprendizaje L para C tiene una complejidad de muestra que satisface mL(ε, δ) ≥ 1 2 fatC(4dε). Una versión análoga de este teorema para funciones de valores reales con un límite más ajustado se puede encontrar en [2], esta versión será suficiente para nuestras necesidades. Prueba: Supongamos que n = 1 2 fatC(4dε), entonces existe un conjunto ΓS = {p1, . . . , p2n} que es destrozado por C. Basta con demostrar que al menos una distribución requiere una muestra grande. Construimos tal distribución. Sea σ la distribución uniforme en ΓS y CS = {fb : b ∈ {0, 1}2n } sea el conjunto de funciones que evidencian la fragmentación de {p1. . . . , pn}. Sea fb una función elegida de forma uniforme al azar de CS. Se deduce del lema 2 (con γ = 2d) que para cualquier función fija h, la probabilidad de que ||fb(p) − h(p)||∞ > 2ε para p ∈ ΓS es al menos tan alta como obtener cara en una moneda justa. Por lo tanto, Eb(||fb(p) − h(p)||∞) > 2ε. Supongamos que para una secuencia de observaciones z = ((pi1 , x1), . . . , (pin , xn)) un algoritmo de aprendizaje L encuentra una función h. La observación anterior y Fubini implican que Eb(erσ(h, fb)) > ε. Al realizar una aleatorización en el espacio muestral, obtenemos que Eb,z(erσ(h, fb)) > ε. Esto muestra que Eh,z(erσ(h, fb0 )) > ε para algún fb0. Dado que estamos analizando lo que es esencialmente un conjunto finito, podemos asumir que el error está acotado, por lo tanto la probabilidad de que erσ(h, fb0 ) > ε no puede ser demasiado pequeña, por lo tanto fb0 no es PAC-aprendible con una muestra de tamaño n ✷ El siguiente teorema proporciona una cota superior sobre la complejidad de la muestra requerida para aprender un conjunto de funciones con dimensión de fat shattering finita. El teorema se demuestra en [2] para funciones de valores reales, la prueba para el caso de vectores reales es análoga y por lo tanto se omite. Teorema 4. Sea C un conjunto de funciones de valores reales de X a [0, 1] con fatC(γ) < ∞. Sea A el algoritmo SEM aproximado para C y define L(z) = A(z, ε0 6 ) para z ∈ Zm y ε0 = 16√ m. Entonces L es un algoritmo de aprendizaje para C con complejidad de muestra dada por: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « para cualquier ε, δ > 0.5. APRENDIENDO DE LAS PREFERENCIAS REVELADAS El Algoritmo 1 es un algoritmo de aprendizaje eficiente en el sentido de que encuentra una hipótesis con error de muestra cero en un tiempo polinómico en el número de observaciones. Como hemos visto en la sección 4, el número de observaciones requeridas para aprender PAC la demanda depende de la dimensión de fat shattering de la clase de funciones de demanda, la cual a su vez depende de la clase de funciones de utilidad de las que se derivan. Calculamos la dimensión de fragmentación de grasa para dos clases de demandas. El primero es la clase de todas las funciones de demanda, mostramos que esta clase tiene una dimensión de fragmentación infinita (damos dos pruebas) y por lo tanto no es aprendible de manera PAC. La segunda clase que consideramos es la clase de funciones de demanda derivadas de utilidades con soporte acotado y <br>Lipschitz en el ingreso</br>. Mostramos que la clase tiene una dimensión de fat shattering finita que depende del soporte y de la <br>constante de Lipschitz de ingresos</br>. ",
            "candidates": [],
            "error": [
                [
                    "Lipschitz de ingreso",
                    "L-ingreso-Lipschitz",
                    "Lipschitz en el ingreso",
                    "constante de Lipschitz de ingresos"
                ]
            ]
        },
        "fat shattering dimension": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the <br>fat shattering dimension</br>, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the <br>fat shattering dimension</br> is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of <br>fat shattering dimension</br> and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the <br>fat shattering dimension</br> of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the <br>fat shattering dimension</br>.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-<br>fat shattering dimension</br> of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite <br>fat shattering dimension</br>.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the <br>fat shattering dimension</br> of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the <br>fat shattering dimension</br> for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite <br>fat shattering dimension</br> that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite <br>fat shattering dimension</br>. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "We show, by computing the <br>fat shattering dimension</br>, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the <br>fat shattering dimension</br> is finite and therefore the corresponding sets are PAC-learnable.",
                "We introduce the notion of <br>fat shattering dimension</br> and use it to devise a lower bound on the sample complexity.",
                "In section 5 we study the learnability of demand functions and directly compute the <br>fat shattering dimension</br> of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "An analog to this notion of dimension for real functions is the <br>fat shattering dimension</br>."
            ],
            "translated_annotated_samples": [
                "Mostramos, al calcular la <br>dimensión de fragmentación de grasa</br>, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC.",
                "Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la <br>dimensión de fragmentación de grasa</br> es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC.",
                "Introducimos la noción de <br>dimensión de fragmentación de conjuntos gordos</br> y la utilizamos para diseñar un límite inferior en la complejidad de la muestra.",
                "En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la <br>dimensión de fat shattering</br> de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2.",
                "Un análogo a esta noción de dimensión para funciones reales es la <br>dimensión de fragmentación de grasa</br>."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la <br>dimensión de fragmentación de grasa</br>, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la <br>dimensión de fragmentación de grasa</br> es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de <br>dimensión de fragmentación de conjuntos gordos</br> y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la <br>dimensión de fat shattering</br> de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de fat shattering, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. Antes de que podamos proceder con la definición formal, debemos aclarar lo que queremos decir con pronóstico y tender a estar de acuerdo. En el caso del aprendizaje discreto, nos gustaría obtener una función h que con alta probabilidad coincida con f. Luego tomaríamos la probabilidad Pσ(f(x) = h(x)) como medida de la calidad de la estimación. Las funciones de demanda son funciones vectoriales reales y, por lo tanto, no esperamos que f y h coincidan con alta probabilidad. Más bien estamos satisfechos con tener errores cuadráticos medios pequeños en todas las coordenadas. Por lo tanto, nuestra medida del error de estimación está dada por: erσ(f, h) = Z (||f − h||∞)2 dσ. Para las observaciones dadas S = {(p1, x1), . . . , (pn, xn)} medimos la concordancia mediante el error muestral erS(S, h) = Σ j (||xj − h(pj)||∞)2. Un algoritmo de minimización del error de muestra (SEM) es un algoritmo que encuentra una hipótesis que minimiza erS(S, h). En el caso de la preferencia revelada, hay una función que lleva el error muestral a cero. Sin embargo, el teorema de los límites superiores que utilizamos no requiere que el error de la muestra sea cero. Definición 1. Un conjunto de funciones de demanda C es probablemente aprendible de manera aproximadamente correcta (PAC) por el conjunto de hipótesis H si para cualquier ε, δ > 0, f ∈ C y distribución σ en los precios, existe un algoritmo L que, para un conjunto de observaciones de longitud mL = mL(ε, δ) = Poly(1/δ, 1/ε), encuentra una función h de H tal que erσ(f, h) < ε con probabilidad 1 − δ. Puede haber varios algoritmos de aprendizaje para C con diferentes complejidades de muestra. El mL mínimo se llama la complejidad de la muestra de C. Nótese que en la definición no se menciona la complejidad temporal para encontrar h en H y evaluar h(p). Un conjunto C es eficientemente PAC-aprendible si hay un algoritmo de tiempo Poly(1 δ , 1 ε ) para elegir h y evaluar h(p). Para conjuntos de funciones discretas, los límites de complejidad de la muestra pueden derivarse de la dimensión VC del conjunto (ver [19, 8]). Un análogo a esta noción de dimensión para funciones reales es la <br>dimensión de fragmentación de grasa</br>. ",
            "candidates": [],
            "error": [
                [
                    "dimensión de fragmentación de grasa",
                    "dimensión de fragmentación de grasa",
                    "dimensión de fragmentación de conjuntos gordos",
                    "dimensión de fat shattering",
                    "dimensión de fragmentación de grasa"
                ]
            ]
        },
        "reveal preference": {
            "translated_key": "preferencia revelada",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "machine learn": {
            "translated_key": "aprendizaje automático",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the fat shattering dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the fat shattering dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of fat shattering dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the fat shattering dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of fat shattering, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the fat shattering dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-fat shattering dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite fat shattering dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the fat shattering dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the fat shattering dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite fat shattering dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite fat shattering dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "fat shatter": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Learning From Revealed Preference [Extended Abstract] Eyal Beigman CMS-EMS Kellogg School of Management Northwestern University Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Kellogg School of Management Northwestern University Evanston IL 60208 r-vohra@northwestern.edu ABSTRACT A sequence of prices and demands are rationalizable if there exists a concave, continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price.",
                "Afriat [1] presented necessary and sufficient conditions for a finite sequence to be rationalizable.",
                "Varian [20] and later Blundell et al. [3, 4] continued this line of work studying nonparametric methods to forecasts demand.",
                "Their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast.",
                "The present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts.",
                "Our results show that the class of all demand functions has unbounded complexity and therefore is not learnable, but that there exist interesting and potentially useful classes that are learnable from finite samples.",
                "We also present a learning algorithm that is an adaptation of a new proof of Afriats theorem due to Teo and Vohra [17].",
                "Categories and Subject Descriptors F.2 [Theory of Computation]: Analysis of Algorithms and Problem Complexity; J.4 [Computer Applications]: Social and Behavioral Sciences-Economics; I.2.6 [Learning]: Parameter Learning General Terms Economics, Algorithms, Theory 1.",
                "INTRODUCTION A market is an institution by which economic agents meet and make transactions.",
                "Classical economic theory explains the incentives of the agents to engage in this behavior through the agents preference over the set of available bundles indicating that agents attempt to replace their current bundle with bundles that are both more preferred and attainable if such bundles exist.",
                "The preference relation is therefore the key factor in understanding consumer behavior.",
                "One of the common assumptions in this theory is that the preference relation is represented by a utility function and that agents strive to maximize their utility given a budget constraint.",
                "This pattern of behavior is the essence of supply and demand, general equilibria and other aspects of consumer theory.",
                "Furthermore, as we elaborate in section 2, basic observations on market demand behavior suggest that utility functions are monotone and concave.",
                "This brings us to the question, first raised by Samuelson [18], to what degree is this theory refutable?",
                "Given observations of price and demand, under what circumstances can we conclude that the data is consistent with the behavior of a utility maximizing agent equipped with a monotone concave utility function and subject to a budget constraint?",
                "Samuelson gave a necessary but insufficient condition on the underlying preference known as the weak axiom of revealed preference.",
                "Uzawa [16] and Mas-Colell [10, 11] introduced a notion of income-Lipschitz and showed that demand functions with this property are rationalizable.",
                "These properties do not require any parametric assumptions and are technically refutable, but they do assume knowledge of the entire demand function and rely heavily on the differential properties of demand functions.",
                "Hence, an infinite amount of information is needed to refute the theory.",
                "It is often the case that apart form the demand observations there is additional information on the system and it is sensible to make parametric assumptions, namely, to stipulate some functional form of utility.",
                "Consistency with utility maximization would then depend on fixing the parameters of the utility function to be consistent with the observations and with a set of equations called the Slutski equations.",
                "If such parameters exist, we conclude that the stipulated utility form is consistent with the observations.",
                "This approach is useful when there is reason to make these stipulations, it gives an explicit utility function which can be used to make precise forecasts on demand for unob36 served prices.",
                "The downside of this approach is that real life data is often inconsistent with convenient functional forms.",
                "Moreover, if the observations are inconsistent it is unclear whether this is a refutation of the stipulated functional form or of utility maximization.",
                "Addressing these issues Houthakker [7] noted that an observer can see only finite quantities of data.",
                "He askes when can it be determined that a finite set of observations is consistent with utility maximization without making parametric assumptions?",
                "He showes that rationalizability of a finite set of observations is equivalent to the strong axiom of revealed preference.",
                "Richter [15] showes that strong axiom of revealed preference is equivalent to rationalizability by a strictly concave monotone utility function.",
                "Afriat [1] gives another set of rationalizability conditions the observations must satisfy.",
                "Varian [20] introduces the generalized axiom of revealed preference (GARP), an equivalent form of Afriats consistency condition that is easier to verify computationally.",
                "It is interesting to note that these necessary and sufficient conditions for rationalizability are essentially versions of the well known Farkas lemma [6] (see also [22]).",
                "Afriat [1] proved his theorem by an explicit construction of a utility function witnessing consistency.",
                "Varian [20] took this one step further progressing from consistency to forecasting.",
                "Varians forecasting algorithm basically rules out bundles that are revealed inferior to observed bundles and finds a bundle from the remaining set that together with the observations is consistent with GARP.",
                "Furthermore, he introduces Samuelsons money metric as a canonical utility function and gives upper and lower envelope utility functions for the money metric.",
                "Knoblauch [9] shows these envelopes can be computed efficiently.",
                "Varian [21] provides an up to date survey on this line of research.",
                "A different approach is presented by Blundell et al. [3, 4].",
                "These papers introduce a model where an agent observes prices and Engel curves for these prices.",
                "This gives an improvement on Varians original bounds, though the basic idea is still to rule out demands that are revealed inferior.",
                "This model is in a sense a hybrid between Mas-Colell and Afriats aproaches.",
                "The former requires full information for all prices, the latter for a finite number of prices.",
                "On the other hand the approach taken by Blundell et al. requires full information only on a finite number of price trajectories.",
                "The motivation for this crossover is to utilize income segmentation in the population to restructure econometric information.",
                "Different segments of the population face the same prices with different budgets, and as much as aggregate data can testify on individual preferences, show how demand varies with the budget.",
                "Applying non parametric statistical methods, they reconstruct a trajectory from the observed demands of different segments and use it to obtain tighter bounds.",
                "Both these methods would most likely give a good forecast for a fixed demand function after sufficiently many observations assuming they were spread out in a reasonable manner.",
                "However, these methods do not consider the complexity of the demand functions and do not use any probabilistic model of the observations.",
                "Therefore, they are unable to provide any estimate of the number of observations that would be sufficient for a good forecast or the degree of confidence in such a forecast.",
                "In this paper we examine the feasibility of demand forecasting with a high degree of confidence using Afriats conditions.",
                "We formulate the question in terms of whether the class of demand functions derived from monotone concave utilities is efficiently PAC-learnable.",
                "Our first result is negative.",
                "We show, by computing the <br>fat shatter</br>ing dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the <br>fat shatter</br>ing dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "In these cases, assuming the probability distribution by which the observed price-demand pairs are generated is fixed, we are in a position to offer a forecast and a probabilistic estimate on its accuracy.",
                "In section 2 we briefly discuss the basic assumptions of demand theory and their implications.",
                "In section 3 we present a new proof to Afriats theorem incorporating an algorithm for efficiently generating a forecasting function due to Teo and Vohra [17].",
                "We show that this algorithm is computationally efficient and can be used as a learning algorithm.",
                "In section 4 we give a brief introduction to PAC learning including several modifications to learning real vector valued functions.",
                "We introduce the notion of <br>fat shatter</br>ing dimension and use it to devise a lower bound on the sample complexity.",
                "We also sketch results on upper bounds.",
                "In section 5 we study the learnability of demand functions and directly compute the <br>fat shatter</br>ing dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "UTILITY AND DEMAND A utility function u : Rn + → R is a function relating bundles of goods to a cardinal in a manner reflecting the preferences over the bundles.",
                "A rational agent with a budget that w.l.g equals 1 facing a price vector p ∈ Rn + will choose from her budget set B(p) = {x ∈ Rn + : p · x ≤ 1} a bundle x ∈ Rn + that maximizes her private utility.",
                "The first assumption we make is that the function is monotone increasing, namely, if x ≥ y, in the sense that the inequality holds coordinatewise, then u(x) ≥ u(y).",
                "This reflects the assumption that agents will always prefer more of any one good.",
                "This, of course, does not necessarily hold in practice, as in many cases excess supply may lead to storage expenses or other externalities.",
                "However, in such cases the demand will be an interior point of the budget set and the less preferred bundles wont be observed.",
                "The second assumption we make on the utility is that all the marginals (partial derivatives) are monotone decreasing.",
                "This is the law of diminishing marginal utility which assumes that the larger the excess of one good over the other the less we value each additional good of one kind over the other.",
                "These assumptions imply that the utility function is concave and monotone on the observations.",
                "The demand function of the agent is the correspondence fu : Rn + → Rn + satisfying f(p) = argmax{u(x) : p · x ≤ I} In general this correspondence is not necessarily single valued, but it is implicit in the proof of Afriats theorem that any set of observations can be rationalized by a demand function that is single valued for unobserved prices. 37 Since large quantities of any good are likely to create utility decreasing externalities, we assume the prices are limited to a compact set.",
                "W.l.g. we assume u has marginal utility zero outside [0, 1]d .",
                "Any budget set that is not a subset of the support is maximized on any point outside the support and it is therefore difficult to forecast for these prices.",
                "We are thus interested in forecasts for prices below the simplex ∆d = conv{(0, . . . , 1, . . . , 0)}.",
                "For these prices we take the metric dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} for p, p ∈ ∆d.",
                "Note that with this metric ∆d is compact.",
                "A demand function is L-income-Lipschitz, for L ∈ R+, if ||f(p) − f(p )||∞ dP (p, p ) ≤ L for any p, p ∈ ∆d.",
                "This property reflects an assumption that preferences and demands have some sort of stability.",
                "It rules out different demands for the similar prices.",
                "We may therefore assume from here on that demand functions are single valued. 3.",
                "REVEALED PREFERENCE A sequence of prices and demands (p1, x1), . . . , (pn, xn) is rationalizable if there exists a utility function u such that xi = fu(pi) for i = 1, . . . , n. We begin with a trivial observation, if pi · xj ≤ pi · xi and xi = f(pi) then xi is preferred over xj since the latter is in the budget set when the former was chosen.",
                "It is therefore revealed that u(xj) ≤ u(xi) implying pj · xj ≤ pj · xi.",
                "Suppose there is a sequence (pi1 , xi1 ), . . . , (pik , xik ) such that pij · (xij − xij+1 ) ≤ 0 for j = 1 . . . k − 1 and pik · (xik − xi1 ) ≤ 0.",
                "Then the same reasoning shows that u(xi1 ) = u(xi2 ) = . . . = u(xik ) implying pi1 · (xi1 − xi2 ) = pi2 · (xi2 − xi3 ) = . . . = pik−1 ·(xik−1 −xik ) = 0.",
                "We call the latter condition the Afriat condition (AC).",
                "This argument shows that AC is necessary for rationalizability; the surprising result in Afriats theorem is that this condition is also sufficient.",
                "Let A be an n × n matrix with entries aij = pi · (xj − xi) (aij and aji are independent), aii = 0 and let D(A) be the weighted digraph associated with A.",
                "The matrix satisfies AC if every cycle with negative total weight includes at least one edge with positive weight.",
                "Theorem 1.",
                "There exists y = (y1, . . . , yn) ∈ Rn and s = (s1, . . . , sn) ∈ Rn + satisfying the set of inequalities L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n iff D(A) satisfies AC.",
                "Proof : If L(A) is feasible then it is easy to see that u(x) = min i {yi + sipi(x − xi)} is a concave utility function that is consistent with the observations, and from our previous remark it follows that D(A) satisfies AC.",
                "In the other direction it is shown by explicit construction that Afriats condition for D(A) implies L(A) is feasible.",
                "The construction provides a utility function that is consistent with the observations.",
                "Teo and Vohra [17] give a strongly polynomial time algorithm for this construction which will be the heart of our learning algorithm.",
                "The construction is executed in two steps.",
                "First, the algorithm finds s ∈ Rn + such that the weighted digraph D(A, s) defined by the matrix ˜aij = siaij has no cycle with negative total weight if D(A) satisfies AC and returns a negative cycle otherwise.",
                "The dual of a shortest path problem is given by the constraints: yj − yi ≤ siaij i = j It is a standard result (see [14] p 109) that the system is feasible iff D(A, s) has no negative cycles.",
                "Thus, in the second step, if D(A) satisfies AC, the algorithm calls a SHORTEST PATH algorithm to find y ∈ Rn satisfying the constraints.",
                "Now we describe how to choose the sis.",
                "Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} and T = {(i, j) : aij > 0} and let G = ([n], S ∪ E) be a digraph with weights wij = −1 if (i, j) ∈ S and wij = 0 otherwise.",
                "D(A) has no negative cycles, hence G is acyclic and breadth first search can assign potentials φi such that φj ≤ φi + wij for (i, j) ∈ S ∪ E. We relabel the vertices so that φ1 ≥ φ2 ≥ . . . ≥ φn.",
                "Let δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij if φi < φi−1 and δi = 1 otherwise, and define si = iY j=2 δj = δi · si−1 .",
                "We show that for this choice of s, D(A, s) contains no negative weight cycle.",
                "Suppose C = (i1, . . . , ik) is a cycle in D(A, s).",
                "If φ is constant on C then aij ij+1 = 0 for j = 1, . . . , k and we are done.",
                "Otherwise let iv ∈ C be the vertex with smallest potential satisfying w.l.o.g. φ(iv) < φ(iv+1).",
                "For any cycle C in the digraph D(A, s), let (v, u) be an edge in C such that (i) v has the smallest potential among all vertices in C, and (ii) φu > φv.",
                "Such an edge exists, otherwise φi is identical for all vertices i in C. In this case, all edges in C have non-negative edge weight in D(A, s).",
                "If (iv, iv+1) ∈ S ∪ E, then we have φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) a contradiction.",
                "Hence (iv, iv+1) ∈ T. Now, note that all vertices q in C with the same potential as iv must be incident to an edge (q, t) in C such that φ(t) ≥ φ(q).",
                "Hence the edge (q, t) must have non-negative weight. i.e., aq,t ≥ 0.",
                "Let p denote a vertex in C with the second smallest potential.",
                "Now, C has weight svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, i.e., C has non-negative weight ✷ Algorithm 1 returns in polynomial time a hypothesis that is a piecewise linear function and agrees with the labeling of the observation namely sample error zero.",
                "To use this function to forecast demand for unobserved prices we need algorithm 2 which maximizes the function on a given budget set.",
                "Since u(x) = mini{yi + sipi(x − xi)} this is a linear program and can be solved in time polynomial in d, n as well as the size of the largest number in the input. 38 Algorithm 1 Utility Algorithm Input (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} for all (i, j) ∈ S do wij ← −1 end for for all (i, j) ∈ E do wij ← 0 end for while there exist unvisited vertices do visit new vertex j assign potential to φj end while reorder indices so φ1 ≤ φ2 . . . ≤ φn for all 1 ≤ i ≤ n do δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for SHORTEST PATH(yj − yi ≤ siaij) Return y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ Algorithm 2 Evaluation Input y1, . . . , yn ∈ Rd and s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) for i = 1, . . . , n px ≤ 1 Return x for which z is maximized 4.",
                "SUPERVISED LEARNING In a supervised learning problem, a learning algorithm is given a finite sample of labeled observations as input and is required to return a model of the functional relationship underlying the labeling.",
                "This model, referred to as a hypothesis, is usually a computable function that is used to forecast the labels of future observations.",
                "The labels are usually binary values indicating the membership of the observed points in the set that is being learned.",
                "However, we are not limited to binary values and, indeed, in the demand functions we are studying the labels are real vectors.",
                "The learning problem has three major components: estimation, approximation and complexity.",
                "The estimation problem is concerned with the tradeoff between the size of the sample given to the algorithm and the degree of confidence we have in the forecast it produces.",
                "The approximation problem is concerned with the ability of hypotheses from a certain class to approximate target functions from a possibly different class.",
                "The complexity problem is concerned with the computational complexity of finding a hypothesis that approximates the target function.",
                "A parametric paradigm assumes that the underlying functional relationship comes from a well defined family, such as the Cobb-Douglas production functions; the system must learn the parameters characterizing this family.",
                "Suppose that a learning algorithm observes a finite set of production data which it assumes comes from a Cobb-Douglas production function and returns a hypothesis that is a polynomial of bounded degree.",
                "The estimation problem in this case would be to assess the sample size needed to obtain a good estimate of the coefficients.",
                "The approximation problem would be to assess the error sustained from approximating a rational function by a polynomial.",
                "The complexity problem would be the assessment of the time required to compute the polynomial coefficients.",
                "In the probably approximately correct (PAC) paradigm, the learning of a target function is done by a class of hypothesis functions, that does or does not include the target function itself; it does not necessitate any parametric assumptions on this class.",
                "It is also assumed that the observations are generated independently by some distribution on the domain of the relation and that this distribution is fixed.",
                "If the class of target functions has finite dimensionality then a function in the class is characterized by its values on a finite number of points.",
                "The basic idea is to observe the labeling of a finite number of points and find a function from a class of hypotheses which tends to agree with this labeling.",
                "The theory tells us that if the sample is large enough then any function that tends to agree with the labeling will, with high probability, be a good approximation of the target function for future observations.",
                "The prime objective of PAC theory is to develop the relevant notion of dimensionality and to formalize the tradeoff between dimensionality, sample size and the level of confidence in the forecast.",
                "In the revealed preference setting, our objective is to use a set of observations of prices and demand to forecast demand for unobserved prices.",
                "Thus the target function is a mapping from prices to bundles, namely f : Rd + → Rd +.",
                "The theory of PAC learning for real valued functions is concerned predominantly with functions from Rd to R. In this section we introduce modifications to the classical notions of PAC learning to vector valued functions and use them to prove a lower bound for sample complexity.",
                "An upper bound on the sample complexity can also be proved for our definition of <br>fat shatter</br>ing, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4.",
                "Before we can proceed with the formal definition, we must clarify what we mean by forecast and tend to agree.",
                "In the case of discrete learning, we would like to obtain a function h that with high probability agrees with f. We would then take the probability Pσ(f(x) = h(x)) as the measure of the quality of the estimation.",
                "Demand functions are real vector functions and we therefore do not expect f and h to agree with high probability.",
                "Rather we are content with having small mean square errors on all coordinates.",
                "Thus, our measure of estimation error is given by: erσ(f, h) = Z (||f − h||∞)2 dσ.",
                "For given observations S = {(p1, x1), . . . , (pn, xn)} we measure the agreement by the sample error erS(S, h) = X j (||xj − h(pj)||∞)2 .",
                "A sample error minimization (SEM) algorithm is an algorithm that finds a hypothesis minimizing erS(S, h).",
                "In the case of revealed preference, there is a function that takes the sample error to zero.",
                "Nevertheless, the upper bounds theorem we use does not require the sample error to be zero.",
                "Definition 1.",
                "A set of demand functions C is probably approximately correct (PAC) learnable by hypotheses set H if for any ε, δ > 0, f ∈ C and distribution σ on the prices 39 there exists an algorithm L that for a set of observations of length mL = mL(ε, δ) = Poly(1 δ , 1 ε ) finds a function h from H such that erσ(f, h) < ε with probability 1 − δ.",
                "There may be several learning algorithms for C with different sample complexities.",
                "The minimal mL is called the sample complexity of C. Note that in the definition there is no mention of the time complexity to find h in H and evaluating h(p).",
                "A set C is efficiently PAC-learnable if there is a Poly(1 δ , 1 ε ) time algorithm for choosing h and evaluating h(p).",
                "For discrete function sets, sample complexity bounds may be derived from the VC-dimension of the set (see [19, 8]).",
                "An analog to this notion of dimension for real functions is the <br>fat shatter</br>ing dimension.",
                "We use an adaptation of this notion to real vector valued function sets.",
                "Let Γ ⊂ Rd + and let C be a set of real functions from Γ to Rd +.",
                "Definition 2.",
                "For γ > 0, a set of points p1, . . . , pn ∈ Γ is γ-shattered by a class of real functions C if there exists x1, . . . , xn ∈ Rd + and parallel affine hyperplanes H0, H1 ⊂ Rd such that 0 ∈ H− 0 ∩ H+ 1 , dist(H0, H1) > γ and for each b = (b1, . . . , bn) ∈ {0, 1}n there exists a function fb ∈ C such that fb(pi) ∈ xi + H+ 0 if bi = 0 and f(pi) ∈ xi + H− 1 if bi = 1.",
                "We define the γ-<br>fat shatter</br>ing dimension of C, denoted fatC(γ) as the maximal size of a γ-shattered set in Γ.",
                "If this size is unbounded then the dimension is infinite.",
                "To demonstrate the usefulness of the this notion we use it to derive a lower bound on the sample complexity.",
                "Lemma 2.",
                "Suppose the functions {fb : b ∈ {0, 1}n } witness the shattering of {p1, . . . , pn}.",
                "Then, for any x ∈ Rd + and labels b, b ∈ {0, 1}n such that bi = bi either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d .",
                "Proof : Since the max exceeds the mean, it follows that if fb and fb correspond to labels such that bi = bi then ||fb(pi) − fb (pi)||∞ ≥ 1 d ||fb(pi) − fb (pi)||2 > γ d .",
                "This implies that for any x ∈ Rd + either ||fb(pi) − x||∞ > γ 2d or ||fb (pi) − x||∞ > γ 2d ✷ Theorem 3.",
                "Suppose that C is a class of functions mapping from Γ to Rd +.",
                "Then any learning algorithm L for C has sample complexity satisfying mL(ε, δ) ≥ 1 2 fatC(4dε) An analog of this theorem for real valued functions with a tighter bound can be found in [2], this version will suffice for our needs.",
                "Proof : Suppose n = 1 2 fatC(4dε) then there exists a set ΓS = {p1, . . . , p2n} that is shattered by C. It suffices to show that at least one distribution requires large sample.",
                "We construct such a distribution.",
                "Let σ be the uniform distribution on ΓS and CS = {fb : b ∈ {0, 1}2n } be the set of functions that witness the shattering of {p1. . . . , pn}.",
                "Let fb be a function chosen uniformly at random from CS.",
                "It follows from lemma 2 (with γ = 2d ) that for any fixed function h the probability that ||fb(p) − h(p)||∞ > 2ε for p ∈ ΓS is at least as high as getting heads on a fair coin toss.",
                "Therefore Eb(||fb(p) − h(p)||∞) > 2ε.",
                "Suppose for a sequence of observations z = ((pi1 , x1), . . . , (pin , xn)) a learning algorithm L finds a function h. The observation above and Fubini imply Eb(erσ(h, fb)) > ε. Randomizing on the sample space we get Eb,z(erσ(h, fb)) > ε.",
                "This shows Eh,z(erσ(h, fb0 )) > ε for some fb0 .",
                "W.l.g we may assume the error is bounded (since we are looking at what is essentially a finite set) therefore the probability that erσ(h, fb0 ) > ε cannot be too small, hence fb0 is not PAClearnable with a sample of size n ✷ The following theorem gives an upper bound on the sample complexity required for learning a set of functions with finite <br>fat shatter</br>ing dimension.",
                "The theorem is proved in [2] for real valued functions, the proof for the real vector case is analogous and so omitted.",
                "Theorem 4.",
                "Let C be a set of real-valued functions from X to [0, 1] with fatC(γ) < ∞.",
                "Let A be approximate-SEM algorithm for C and define L(z) = A(z, ε0 6 ) for z ∈ Zm and ε0 = 16√ m .",
                "Then L is a learning algorithm for C with sample complexity given by: mL(ε, δ) = O „ 1 ε2 (ln2 ( 1 ε )fatC(ε) + ln( 1 δ )) « for any ε, δ > 0. 5.",
                "LEARNING FROM REVEALED PREFERENCE Algorithm 1 is an efficient learning algorithm in the sense that it finds a hypothesis with sample error zero in time polynomial in the number of observations.",
                "As we have seen in section 4 the number of observations required to PAC learn the demand depends on the <br>fat shatter</br>ing dimension of the class of demand functions which in turn depends on the class of utility functions they are derived from.",
                "We compute the <br>fat shatter</br>ing dimension for two classes of demands.",
                "The first is the class of all demand functions, we show that this class has infinite shattering dimension (we give two proofs) and is therefore not PAC learnable.",
                "The second class we consider is the class of demand functions derived from utilities with bounded support and income-Lipschitz.",
                "We show that the class has a finite <br>fat shatter</br>ing dimension that depends on the support and the income-Lipschitz constant.",
                "Theorem 5.",
                "Let C be a set of demand functions from Rd + to Rd + then fatC(γ) = ∞ Proof 1: For ε > 0 let pi = 2−i p for i = 1, . . . , n be a set of price vectors inducing parallel budget sets Bi and let x1, . . . , xn be the intersection of these hyperplanes with an orthogonal line passing through the center.",
                "Let H0 and H1 be hyperplanes that are not parallel to p and let xi ∈ Bi ∩ (xi + H+ 0 ) and xi ∈ Bi ∩ (xi + H− 1 ) for i = 1 . . . n (see figure 1).",
                "For any labeling b = (b1, . . . , bn) ∈ {0, 1}n let y = y(b) = (y1, . . . , yn) be a set of demands such that yi = xi if bi = 0 and yi = xi if bi = 1 (we omit an additional index b in y for notational convenience).",
                "To show that p1, . . . , pn is shattered it suffices to find for every b a demand function fb supported by concave utility such that fb(pi) = yb i .",
                "To show that such a function exists it suffices to show that Afriats conditions are satisfied.",
                "Since yi are in the budget 40 set yi · 2−i p = 1, therefore pi · (yj − yi) = 2j−i − 1.",
                "This shows that pi · (yj − yi) ≤ 0 iff j < i hence there can be no negative cycles and the condition is met. ✷ Proof 2: The utility functions satisfying Afriats condition in the first proof could be trivial assigning the same utility to xi as to xi .",
                "In fact, pick a utility function whose level sets are parallel to the budget constraint.",
                "Therefore the shattering of the prices p1, . . . , pn is the result of indifference rather than genuine preference.",
                "To avoid this problem we reprove the theorem by constructing utility functions u such that u(xi) = u(xi ) for all i and therefore a distinct utility function is associated with each labeling.",
                "For i = 1, . . . n let pi1, . . . , pid be price vectors satisfying the following conditions: 1. the budget sets Bs i are supporting hyperplanes of a convex polytope Λi 2. yi is a vertex of Λi 3. ||yj ||1 · ||pis − pi||∞ = o(1) for s = 1, . . . d and j = 1, . . . , n Finally let yi1, . . . , yid be points on the facets of Λi that intersect yi, such that ||pjr||1 · ||yi − yis||∞ = o(1) for all j, s and r. We call the set of points yi, yi1, . . . , yid the level i demand and pi, pi1, . . . , pid level i prices.",
                "Applying H¨olders inequality we get |pir · yjs − pi · yj | ≤ |(pir − pi) · yj| + |pir · (yjs − yj)| ||pir − pi||∞ · ||yj ||1 + ||yjs − yj||∞ · ||pir||1. = o(1) This shows that pir · (yjs − yir) = pi · (ys − yi) + o(1) = 2j−i − 1 + o(1) therefore pir · (yjs − yir) ≤ 0 iff j < i or i = j.",
                "This implies that if there is a negative cycle then all the points in the cycle must belong to the same level.",
                "The points of any one level lie on the facets of a polytope Λi and the prices pis are supporting hyperplanes of the polytope.",
                "Thus, the polytope defines a utility function for which these demands are utility maximizing.",
                "The other direction of Afriats theorem therefore implies there can be no negative cycles within points on the same level.",
                "It follows that there are no negative cycles for the union of observations from all levels hence the sequence of observations (y1, p1), (y11, p11), (y12, p12), . . . , (ynd, pnd) is consistent with monotone concave utility function maximization and again by Afriats theorem there exists u supporting a demand function fb ✷ The proof above relies on the fact that an agent have high utility and marginal utility for very large bundles.",
                "In many cases it is reasonable to assume that the marginal for very large bundles is very small, or even that the utility or the marginal utility have compact support.",
                "Unfortunately, rescaling the previous example shows that even a compact set may contain a large shattered set.",
                "We notice however, that in this case we obtain a utility function that yield demand functions that are very sensitive to small price changes.",
                "We show that the class of utility functions that have marginal utilities with compact support and for which the relevant demand functions are income-Lipschitzian has finite <br>fat shatter</br>ing dimension. ✲ ✻ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ ❅ (0,0)               H0               H1r x1 r x1 ❈ ❈ ❜ ❜❜ r x2 r x2 ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❚ ❜ ❜❜ Figure 1: Utility function shattering x1 and x2 Theorem 6.",
                "Let C be a set of L-income-Lipschitz demand functions from ∆d to Rd + for some global constant L ∈ R. Then fatC(γ) ≤ ( L γ )d Proof : Let p1, . . . , pn ∈ ∆d be a shattered set with witnesses x1, . . . , xn ∈ Rd +.",
                "W.l.g. xi+H+ 0 ∩xj +H− 0 = ∅ implying xi + H− 1 ∩ xj + H+ 1 = ∅, for a labeling b = (b1, . . . , bn) ∈ {0, 1}n such that bi = 0 and bj = 1, ||fb(pi) − fb(pj)||∞ > γ hence ||pi − pj||∞ > γ L .",
                "A standard packing argument implies n ≤ (L γ )d ✷ 6.",
                "ACKNOWLEDGMENTS The authors would like to thank Eli Shamir, Ehud Kalai, Julio Gonz´alez D´ıaz, Rosa Matzkin, Gad Allon and Adam Galambos for helpful discussions and suggestions. 7.",
                "REFERENCES [1] Afriat S. N. (1967) The Construction of a Utility Function from Expenditure Data International Economic Review 8, 67-77. [2] Anthony M. and Bartlett P. L. (1999) Neural Network Learning: Theoretical Foundations Cambridge University Press. [3] Blundell R., Browning M. and Crawford I. (2003) Nonparametric Engel curves and revealed preference.",
                "Econometrica, 71(1):205-240. [4] Blundell R. (2005 ) How revealing is revealed preference?",
                "European Economic Journal 3, 211 - 235. [5] Diewert E. (1973) Afriat and Revealed Preference Theory Review of Economic Studies 40, 419 - 426. [6] Farkas J. (1902) ¨Uber die Theorie der Einfachen Ungleichungen Journal f¨ur die Reine und Angewandte Mathematik 124 1-27 [7] Houthakker H. (1950) Revealed Preference and the Utility Function Economica 17, 159 - 174. [8] Kearns M. and Vazirani U. (1994) An Introduction to Computational Learning Theory The MIT Press Cambridge MA. 41 [9] Knoblauch V. (1992) A Tight Upper Bound on the Money Metric Utility Function.",
                "The American Economic Review, 82(3):660-663. [10] Mas-Colell A. (1977) The Recoverability of Consumers Preferences from Market Demand.",
                "Econometrica, 45(6):1409-1430. [11] Mas-Colell A. (1978) On Revealed Preference Analysis.",
                "The Review of Economic Studies, 45(1):121-131. [12] Mas-Colell A., Whinston M. and Green J. R. (1995) Microeconomic Theory Oxford University Press. [13] Matzkin R. and Richter M. (1991) Testing Strictly Concave Rationality.",
                "Journal of Economic Theory, 53:287-303. [14] Papadimitriou C. H. and Steiglitz K. (1982) Combinatorial Optimization Dover Publications inc. [15] Richter M. (1966) Revealed Preference Theory.",
                "Econometrica, 34(3):635-645. [16] Uzawa H. (1960 ) Preference and rational choice in the theory of consumption.",
                "In K. J. Arrow, S. Karlin, and P. Suppes, editors, Mathematical Models in Social Science Stanford University Press, Stanford, CA. [17] Teo C. P. and Vohra R. V. (2003) Afriats Theorem and Negative Cycles Working Paper [18] Samuelson P. A. (1948) Consumption Theory in Terms of Revealed Preference Economica 15, 243 - 253. [19] Vapnik V. N. (1998) Statistical Learning Theory John Wiley & Sons Inc. [20] Varian H. R. (1982) The Non-Parametric Approach to Demand Analysis Econometrica 50, 945 - 974. [21] Varian H. R. (2005) Revealed Preference, In Michael Szenberg editor, Samuelson Economics and the 21st Century. [22] Ziegler G. M. (1994) Lectures on Polytopes Springer. 42"
            ],
            "original_annotated_samples": [
                "We show, by computing the <br>fat shatter</br>ing dimension, that without any prior assumptions, the set of all demand functions induced by monotone concave utility functions is too rich to be efficiently PAC-learnable.",
                "However, under some prior assumptions on the set of demand functions we show that the <br>fat shatter</br>ing dimension is finite and therefore the corresponding sets are PAC-learnable.",
                "We introduce the notion of <br>fat shatter</br>ing dimension and use it to devise a lower bound on the sample complexity.",
                "In section 5 we study the learnability of demand functions and directly compute the <br>fat shatter</br>ing dimension of the class of all demand functions and a class of income-Lipschitzian demand functions with a bounded global income-Lipschitz constant. 2.",
                "An upper bound on the sample complexity can also be proved for our definition of <br>fat shatter</br>ing, but we do not bring it here as the proof is much more tedious and analogous to the proof of theorem 4."
            ],
            "translated_annotated_samples": [
                "Mostramos, al calcular la <br>dimensión de fragmentación de grasa</br>, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC.",
                "Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la <br>dimensión de fragmentación de grasa</br> es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC.",
                "Introducimos la noción de <br>dimensión de fragmentación de conjuntos gordos</br> y la utilizamos para diseñar un límite inferior en la complejidad de la muestra.",
                "En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la <br>dimensión de fat shattering</br> de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2.",
                "Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de <br>fat shattering</br>, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4."
            ],
            "translated_text": "Aprendiendo de la Preferencia Revelada [Resumen Extendido] Eyal Beigman CMS-EMS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 e-beigman@northwestern.edu Rakesh Vohra MEDS Escuela de Administración Kellogg de la Universidad Northwestern Evanston IL 60208 r-vohra@northwestern.edu RESUMEN Una secuencia de precios y demandas es racionalizable si existe una función de utilidad cóncava, continua y monótona tal que las demandas son los maximizadores de la función de utilidad sobre el conjunto de presupuesto correspondiente al precio. Afriat presentó condiciones necesarias y suficientes para que una secuencia finita sea racionalizable. Varian [20] y posteriormente Blundell et al. [3, 4] continuaron esta línea de trabajo estudiando métodos no paramétricos para pronosticar la demanda. Sus resultados caracterizan esencialmente la capacidad de aprendizaje de clases degeneradas de funciones de demanda y, por lo tanto, no logran proporcionar un grado general de confianza en la predicción. El presente artículo complementa esta línea de investigación al introducir un modelo estadístico y una medida de complejidad a través de la cual podemos estudiar la capacidad de aprendizaje de clases de funciones de demanda y derivar un grado de confianza en las previsiones. Nuestros resultados muestran que la clase de todas las funciones de demanda tiene una complejidad ilimitada y, por lo tanto, no es aprendible, pero que existen clases interesantes y potencialmente útiles que son aprendibles a partir de muestras finitas. También presentamos un algoritmo de aprendizaje que es una adaptación de una nueva demostración del teorema de Afriat debido a Teo y Vohra [17]. Categorías y Descriptores de Asignaturas F.2 [Teoría de la Computación]: Análisis de Algoritmos y Complejidad de Problemas; J.4 [Aplicaciones Informáticas]: Ciencias Sociales y del Comportamiento-Economía; I.2.6 [Aprendizaje]: Aprendizaje de Parámetros Términos Generales Economía, Algoritmos, Teoría 1. INTRODUCCIÓN Un mercado es una institución mediante la cual los agentes económicos se encuentran y realizan transacciones. La teoría económica clásica explica los incentivos de los agentes para participar en este comportamiento a través de la preferencia de los agentes sobre el conjunto de paquetes disponibles, indicando que los agentes intentan reemplazar su paquete actual con paquetes que sean tanto más preferidos como alcanzables si existen tales paquetes. La relación de preferencia es, por lo tanto, el factor clave para entender el comportamiento del consumidor. Una de las suposiciones comunes en esta teoría es que la relación de preferencia está representada por una función de utilidad y que los agentes se esfuerzan por maximizar su utilidad dada una restricción presupuestaria. Este patrón de comportamiento es la esencia de la oferta y la demanda, los equilibrios generales y otros aspectos de la teoría del consumidor. Además, como detallamos en la sección 2, las observaciones básicas sobre el comportamiento de la demanda del mercado sugieren que las funciones de utilidad son monótonas y cóncavas. Esto nos lleva a la pregunta, planteada por primera vez por Samuelson [18], ¿hasta qué punto es refutable esta teoría? ¿Bajo qué circunstancias podemos concluir, dadas las observaciones de precio y demanda, que los datos son consistentes con el comportamiento de un agente maximizador de utilidad equipado con una función de utilidad monótona cóncava y sujeto a una restricción presupuestaria? Samuelson dio una condición necesaria pero insuficiente sobre la preferencia subyacente conocida como el axioma débil de la preferencia revelada. Uzawa [16] y Mas-Colell [10, 11] introdujeron una noción de Lipschitz de ingreso y demostraron que las funciones de demanda con esta propiedad son racionalizables. Estas propiedades no requieren ninguna suposición paramétrica y son técnicamente refutables, pero sí asumen el conocimiento de toda la función de demanda y dependen en gran medida de las propiedades diferenciales de las funciones de demanda. Por lo tanto, se necesita una cantidad infinita de información para refutar la teoría. A menudo sucede que, además de las observaciones de la demanda, hay información adicional sobre el sistema y es sensato hacer suposiciones paramétricas, es decir, estipular alguna forma funcional de utilidad. La consistencia con la maximización de la utilidad dependería entonces de fijar los parámetros de la función de utilidad de manera consistente con las observaciones y con un conjunto de ecuaciones llamadas las ecuaciones de Slutski. Si existen tales parámetros, concluimos que la forma de utilidad estipulada es consistente con las observaciones. Este enfoque es útil cuando hay razón para hacer estas estipulaciones, proporciona una función de utilidad explícita que se puede utilizar para hacer pronósticos precisos sobre la demanda de precios no atendidos. El inconveniente de este enfoque es que los datos de la vida real a menudo son inconsistentes con formas funcionales convenientes. Además, si las observaciones son inconsistentes, no está claro si esto es una refutación de la forma funcional estipulada o de la maximización de la utilidad. Abordando estos problemas, Houthakker [7] señaló que un observador solo puede ver cantidades finitas de datos. ¿Él pregunta cuándo se puede determinar que un conjunto finito de observaciones es consistente con la maximización de la utilidad sin hacer suposiciones paramétricas? Él demuestra que la racionalización de un conjunto finito de observaciones es equivalente al fuerte axioma de la preferencia revelada. Richter [15] muestra que el axioma fuerte de preferencia revelada es equivalente a la racionalizabilidad por una función de utilidad estrictamente cóncava y monótona. Afriat [1] propone otro conjunto de condiciones de racionalidad que las observaciones deben cumplir. Varian [20] introduce el axioma generalizado de preferencia revelada (GARP), una forma equivalente de la condición de consistencia de Afriat que es más fácil de verificar computacionalmente. Es interesante notar que estas condiciones necesarias y suficientes para la racionalización son esencialmente versiones del conocido lema de Farkas [6] (ver también [22]). Afriat demostró su teorema mediante la construcción explícita de una función de utilidad que evidencia consistencia. Varian [20] llevó esto un paso más allá al avanzar de la consistencia a la predicción. El algoritmo de pronóstico de Varian básicamente descarta los paquetes que se revelan inferiores a los paquetes observados y encuentra un paquete del conjunto restante que, junto con las observaciones, es consistente con GARP. Además, introduce la métrica monetaria de Samuelson como una función de utilidad canónica y proporciona funciones de utilidad de sobre y subenvoltura para la métrica monetaria. Knoblauch [9] muestra que estos sobres se pueden calcular de manera eficiente. Varian [21] proporciona una encuesta actualizada sobre esta línea de investigación. Un enfoque diferente es presentado por Blundell et al. [3, 4]. Estos documentos presentan un modelo en el que un agente observa los precios y las curvas de Engel para estos precios. Esto supone una mejora de los límites originales de Varian, aunque la idea básica sigue siendo descartar las demandas que se revelan como inferiores. Este modelo es en cierto sentido un híbrido entre los enfoques de Mas-Colell y Afriats. El primero requiere información completa para todos los precios, el segundo para un número finito de precios. Por otro lado, el enfoque adoptado por Blundell et al. requiere información completa solo sobre un número finito de trayectorias de precios. La motivación de este cruce es utilizar la segmentación de ingresos en la población para reestructurar la información econométrica. Diferentes segmentos de la población se enfrentan a los mismos precios con presupuestos diferentes, y tanto como los datos agregados pueden testificar sobre las preferencias individuales, muestran cómo varía la demanda con el presupuesto. Aplicando métodos estadísticos no paramétricos, reconstruyen una trayectoria a partir de las demandas observadas de diferentes segmentos y la utilizan para obtener límites más ajustados. Ambos métodos probablemente proporcionarían un buen pronóstico para una función de demanda fija después de un número suficiente de observaciones, siempre y cuando estuvieran distribuidos de manera razonable. Sin embargo, estos métodos no consideran la complejidad de las funciones de demanda y no utilizan ningún modelo probabilístico de las observaciones. Por lo tanto, no pueden proporcionar ninguna estimación del número de observaciones que serían suficientes para un buen pronóstico o el grado de confianza en dicho pronóstico. En este documento examinamos la viabilidad de pronosticar la demanda con un alto grado de confianza utilizando las condiciones de Afriat. Formulamos la pregunta en términos de si la clase de funciones de demanda derivadas de utilidades monótonas cóncavas es eficientemente PAC-aprendible. Nuestro primer resultado es negativo. Mostramos, al calcular la <br>dimensión de fragmentación de grasa</br>, que sin ninguna suposición previa, el conjunto de todas las funciones de demanda inducidas por funciones de utilidad cóncavas y monótonas es demasiado rico para ser aprendido eficientemente de manera PAC. Sin embargo, bajo algunas suposiciones previas sobre el conjunto de funciones de demanda, demostramos que la <br>dimensión de fragmentación de grasa</br> es finita y, por lo tanto, los conjuntos correspondientes son aprendibles de forma PAC. En estos casos, asumiendo que la distribución de probabilidad mediante la cual se generan los pares observados de precio-demanda está fija, estamos en condiciones de ofrecer un pronóstico y una estimación probabilística sobre su precisión. En la sección 2 discutimos brevemente las suposiciones básicas de la teoría de la demanda y sus implicaciones. En la sección 3 presentamos una nueva demostración del teorema de Afriat que incorpora un algoritmo para generar eficientemente una función de pronóstico desarrollada por Teo y Vohra [17]. Mostramos que este algoritmo es eficiente computacionalmente y puede ser utilizado como algoritmo de aprendizaje. En la sección 4 ofrecemos una breve introducción al aprendizaje PAC, incluyendo varias modificaciones para aprender funciones de valores vectoriales reales. Introducimos la noción de <br>dimensión de fragmentación de conjuntos gordos</br> y la utilizamos para diseñar un límite inferior en la complejidad de la muestra. También esbozamos resultados sobre límites superiores. En la sección 5 estudiamos la capacidad de aprendizaje de las funciones de demanda y calculamos directamente la <br>dimensión de fat shattering</br> de la clase de todas las funciones de demanda y una clase de funciones de demanda Lipschitzianas de ingreso con una constante global de Lipschitz acotada. 2. La función de utilidad y demanda u : Rn + → R es una función que relaciona los conjuntos de bienes con un número cardinal de una manera que refleja las preferencias sobre los conjuntos. Un agente racional con un presupuesto que, sin pérdida de generalidad, es igual a 1 y que se enfrenta a un vector de precios p ∈ Rn + elegirá de su conjunto de presupuesto B(p) = {x ∈ Rn + : p · x ≤ 1} un conjunto x ∈ Rn + que maximice su utilidad privada. La primera suposición que hacemos es que la función es monótona creciente, es decir, si x ≥ y, en el sentido de que la desigualdad se cumple coordenada por coordenada, entonces u(x) ≥ u(y). Esto refleja la suposición de que los agentes siempre preferirán más de cualquier bien. Esto, por supuesto, no necesariamente se cumple en la práctica, ya que en muchos casos el exceso de oferta puede llevar a gastos de almacenamiento u otras externalidades. Sin embargo, en tales casos la demanda será un punto interior del conjunto de presupuesto y los paquetes menos preferidos no serán observados. La segunda suposición que hacemos sobre la utilidad es que todas las marginales (derivadas parciales) son monótonas decrecientes. Esta es la ley de la utilidad marginal decreciente, la cual asume que mientras mayor sea el exceso de un bien sobre otro, menos valoramos cada bien adicional de un tipo sobre el otro. Estas suposiciones implican que la función de utilidad es cóncava y monótona en las observaciones. La función de demanda del agente es la correspondencia fu: Rn + → Rn + que satisface f(p) = argmax{u(x) : p · x ≤ I}. En general, esta correspondencia no es necesariamente univaluada, pero es implícito en la prueba del teorema de Afriat que cualquier conjunto de observaciones puede ser racionalizado por una función de demanda que es univaluada para precios no observados. Dado que grandes cantidades de cualquier bien probablemente creen externalidades que disminuyan la utilidad, asumimos que los precios están limitados a un conjunto compacto. Con la pérdida de generalidad, asumimos que u tiene utilidad marginal cero fuera de [0, 1]d. Cualquier conjunto de presupuesto que no sea un subconjunto del soporte se maximiza en cualquier punto fuera del soporte y, por lo tanto, es difícil prever estos precios. Estamos interesados en pronósticos para precios por debajo del simplex ∆d = conv{(0, . . . , 1, . . . , 0)}. Para estos precios tomamos la métrica dP (p, p ) = max{| 1 pi − 1 pi | : i = 1, . . . , d} para p, p ∈ ∆d. Ten en cuenta que con esta métrica ∆d es compacto. Una función de demanda es L-ingreso-Lipschitz, para L ∈ R+, si ||f(p) − f(p )||∞ dP (p, p ) ≤ L para cualquier p, p ∈ ∆d. Esta propiedad refleja la suposición de que las preferencias y demandas tienen cierto grado de estabilidad. Descarta diferentes demandas por precios similares. Por lo tanto, podemos asumir a partir de aquí que las funciones de demanda son de un solo valor. 3. Una secuencia de precios y demandas (p1, x1), . . . , (pn, xn) es racionalizable si existe una función de utilidad u tal que xi = fu(pi) para i = 1, . . . , n. Comenzamos con una observación trivial, si pi · xj ≤ pi · xi y xi = f(pi) entonces xi es preferido sobre xj ya que este último está en el conjunto de presupuesto cuando se eligió el primero. Por lo tanto, se revela que u(xj) ≤ u(xi), lo que implica que pj · xj ≤ pj · xi. Supongamos que existe una secuencia (pi1 , xi1 ), . . . , (pik , xik ) tal que pij · (xij − xij+1 ) ≤ 0 para j = 1 . . . k − 1 y pik · (xik − xi1 ) ≤ 0. Entonces, el mismo razonamiento muestra que u(xi1) = u(xi2) = . . . = u(xik), lo que implica que pi1 · (xi1 − xi2) = pi2 · (xi2 − xi3) = . . . = pik−1 · (xik−1 − xik) = 0. Llamamos a esta última condición la condición de Afriat (AC). Este argumento muestra que la AC es necesaria para la racionalización; el resultado sorprendente en el teorema de Afriat es que esta condición también es suficiente. Sea A una matriz n × n con entradas aij = pi · (xj − xi) (aij y aji son independientes), aii = 0 y sea D(A) el digrafo ponderado asociado con A. La matriz satisface AC si cada ciclo con peso total negativo incluye al menos una arista con peso positivo. Teorema 1. Existe y = (y1, . . . , yn) ∈ Rn y s = (s1, . . . , sn) ∈ Rn + que satisfacen el conjunto de desigualdades L(A), yj ≤ yi + siaij i = j 1 ≤ i, j ≤ n si y solo si D(A) satisface AC. Prueba: Si L(A) es factible, entonces es fácil ver que u(x) = min i {yi + sipi(x − xi)} es una función de utilidad cóncava que es consistente con las observaciones, y de nuestro comentario anterior se sigue que D(A) satisface AC. En la otra dirección se muestra mediante una construcción explícita que la condición de Afriat para D(A) implica que L(A) es factible. La construcción proporciona una función de utilidad que es consistente con las observaciones. Teo y Vohra [17] presentan un algoritmo de tiempo polinómico fuertemente para esta construcción que será el corazón de nuestro algoritmo de aprendizaje. La construcción se ejecuta en dos pasos. Primero, el algoritmo encuentra s ∈ Rn + tal que el digrafo ponderado D(A, s) definido por la matriz ˜aij = siaij no tiene ciclos con peso total negativo si D(A) satisface AC y devuelve un ciclo negativo en caso contrario. El dual de un problema de camino más corto está dado por las restricciones: yj − yi ≤ siaij i = j. Es un resultado estándar (ver [14] p. 109) que el sistema es factible si y solo si D(A, s) no tiene ciclos negativos. Por lo tanto, en el segundo paso, si D(A) satisface AC, el algoritmo llama a un algoritmo de CAMINO MÁS CORTO para encontrar y ∈ Rn que satisfaga las restricciones. Ahora describimos cómo elegir el sis. Define S = {(i, j) : aij < 0}, E = {(i, j) : aij = 0} y T = {(i, j) : aij > 0} y sea G = ([n], S ∪ E) un digrafo con pesos wij = −1 si (i, j) ∈ S y wij = 0 en otro caso. D(A) no tiene ciclos negativos, por lo tanto G es acíclico y la búsqueda en anchura puede asignar potenciales φi de tal manera que φj ≤ φi + wij para (i, j) ∈ S ∪ E. Relabelamos los vértices de modo que φ1 ≥ φ2 ≥ . . . ≥ φn. Sea δi = (n − 1) max(i,j)∈S(−aij) min(i,j)∈T aij si φi < φi−1 y δi = 1 en otro caso, y defina si = iY j=2 δj = δi · si−1. Mostramos que para esta elección de s, D(A, s) no contiene ningún ciclo de peso negativo. Supongamos que C = (i1, . . . , ik) es un ciclo en D(A, s). Si φ es constante en C, entonces aij ij+1 = 0 para j = 1, . . . , k y hemos terminado. De lo contrario, sea iv ∈ C el vértice con el menor potencial que cumple, sin pérdida de generalidad, φ(iv) < φ(iv+1). Para cualquier ciclo C en el digrafo D(A, s), sea (v, u) una arista en C tal que (i) v tiene el potencial más pequeño entre todos los vértices en C, y (ii) φu > φv. Tal borde existe, de lo contrario φi es idéntico para todos los vértices i en C. En este caso, todos los bordes en C tienen peso de borde no negativo en D(A, s). Si (iv, iv+1) ∈ S ∪ E, entonces tenemos que φ(iv+1) ≤ φ(iv) + wiv,iv+1 ≤ φ(iv) una contradicción. Por lo tanto, (iv, iv+1) ∈ T. Ahora, observe que todos los vértices q en C con el mismo potencial que iv deben estar incidentes a una arista (q, t) en C tal que φ(t) ≥ φ(q). Por lo tanto, el borde (q, t) debe tener un peso no negativo, es decir, aq,t ≥ 0. Que p denote un vértice en C con el segundo menor potencial. Ahora, C tiene peso svavu+ X (k,l)∈C\\(v,u) skak,l ≥ svav,u+sp(n−1) max (i,j)∈S {aij } ≥ 0, es decir, C tiene peso no negativo ✷ El Algoritmo 1 devuelve en tiempo polinómico una hipótesis que es una función lineal por partes y coincide con la etiqueta de la observación, es decir, error de muestra cero. Para utilizar esta función para predecir la demanda de precios no observados, necesitamos el algoritmo 2 que maximiza la función en un conjunto de presupuesto dado. Dado que u(x) = mini{yi + sipi(x − xi)} este es un programa lineal y puede resolverse en tiempo polinómico en d, n, así como en el tamaño del número más grande en la entrada. 38 Algoritmo 1 Algoritmo de Utilidad Entrada (x1, p1), . . . , (xn, pn) S ← {(i, j) : aij < 0} E ← {(i, j) : aij = 0} para todo (i, j) ∈ S hacer wij ← −1 fin para para todo (i, j) ∈ E hacer wij ← 0 fin para mientras existan vértices no visitados hacer visitar nuevo vértice j asignar potencial a φj fin mientras reordenar índices de modo que φ1 ≤ φ2 . . . ≤ φn para todo 1 ≤ i ≤ n hacer δi ← (n − 1) max(i,j)∈S (−aij ) min(i,j)∈T aij si ← Qi j=2 δj end for CAMINO MÁS CORTO(yj − yi ≤ siaij) Devolver y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ Algoritmo 2 Evaluación Entrada y1, . . . , yn ∈ Rd y s1, . . . , sn ∈ R+ max z z ≤ yi + sipi(x − xi) para i = 1, . . . , n px ≤ 1 Devolver x para el cual z está maximizado 4. APRENDIZAJE SUPERVISADO En un problema de aprendizaje supervisado, se le proporciona a un algoritmo de aprendizaje una muestra finita de observaciones etiquetadas como entrada y se le pide que devuelva un modelo de la relación funcional subyacente a las etiquetas. Este modelo, conocido como hipótesis, suele ser una función computable que se utiliza para predecir las etiquetas de observaciones futuras. Las etiquetas suelen ser valores binarios que indican la pertenencia de los puntos observados en el conjunto que se está aprendiendo. Sin embargo, no estamos limitados a valores binarios y, de hecho, en las funciones de demanda que estamos estudiando, las etiquetas son vectores reales. El problema de aprendizaje tiene tres componentes principales: estimación, aproximación y complejidad. El problema de estimación se preocupa por el equilibrio entre el tamaño de la muestra proporcionada al algoritmo y el grado de confianza que tenemos en la predicción que produce. El problema de la aproximación se refiere a la capacidad de las hipótesis de una cierta clase para aproximar funciones objetivo de una clase posiblemente diferente. El problema de la complejidad se refiere a la complejidad computacional de encontrar una hipótesis que aproxime la función objetivo. Un paradigma paramétrico asume que la relación funcional subyacente proviene de una familia bien definida, como las funciones de producción Cobb-Douglas; el sistema debe aprender los parámetros que caracterizan esta familia. Supongamos que un algoritmo de aprendizaje observa un conjunto finito de datos de producción que asume provienen de una función de producción Cobb-Douglas y devuelve una hipótesis que es un polinomio de grado acotado. El problema de estimación en este caso sería determinar el tamaño de la muestra necesario para obtener una buena estimación de los coeficientes. El problema de aproximación consistiría en evaluar el error sufrido al aproximar una función racional por un polinomio. El problema de complejidad sería la evaluación del tiempo requerido para calcular los coeficientes del polinomio. En el paradigma probablemente aproximadamente correcto (PAC), el aprendizaje de una función objetivo se realiza mediante una clase de funciones hipotéticas, que incluye o no la función objetivo en sí misma; no requiere de ninguna suposición paramétrica sobre esta clase. También se asume que las observaciones son generadas de forma independiente por alguna distribución en el dominio de la relación y que esta distribución está fija. Si la clase de funciones objetivo tiene dimensionalidad finita, entonces una función en la clase se caracteriza por sus valores en un número finito de puntos. La idea básica es observar el etiquetado de un número finito de puntos y encontrar una función de una clase de hipótesis que tienda a estar de acuerdo con este etiquetado. La teoría nos dice que si la muestra es lo suficientemente grande, entonces cualquier función que tienda a estar de acuerdo con la etiquetación, con alta probabilidad, será una buena aproximación de la función objetivo para observaciones futuras. El objetivo principal de la teoría PAC es desarrollar la noción relevante de dimensionalidad y formalizar el equilibrio entre la dimensionalidad, el tamaño de la muestra y el nivel de confianza en la predicción. En el contexto de preferencias reveladas, nuestro objetivo es utilizar un conjunto de observaciones de precios y demanda para predecir la demanda para precios no observados. Por lo tanto, la función objetivo es una asignación de precios a conjuntos, es decir, f: Rd + → Rd +. La teoría del aprendizaje PAC para funciones de valores reales se preocupa principalmente por funciones de Rd a R. En esta sección introducimos modificaciones a las nociones clásicas del aprendizaje PAC para funciones de valores vectoriales y las utilizamos para demostrar un límite inferior para la complejidad de la muestra. Un límite superior en la complejidad de la muestra también se puede demostrar para nuestra definición de <br>fat shattering</br>, pero no lo presentamos aquí ya que la prueba es mucho más tediosa y análoga a la prueba del teorema 4. ",
            "candidates": [],
            "error": [
                [
                    "dimensión de fragmentación de grasa",
                    "dimensión de fragmentación de grasa",
                    "dimensión de fragmentación de conjuntos gordos",
                    "dimensión de fat shattering",
                    "fat shattering"
                ]
            ]
        }
    }
}