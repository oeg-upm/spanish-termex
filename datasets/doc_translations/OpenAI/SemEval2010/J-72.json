{
    "id": "J-72",
    "original_text": "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory. We show that learning algorithms can be used as a basis for preference elicitation algorithms. The resulting elicitation algorithms perform a polynomial number of queries. We also give conditions under which the resulting algorithms have polynomial communication. Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions. In particular, we obtain an algorithm that elicits XOR bids with polynomial communication. Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1. INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone. Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic. Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large. Furthermore, it might even be hard for agents to determine their valuations for single bundles [14]. It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible. Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors. These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods. There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19]. In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs? In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation. Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other. We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries. The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries. Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme. Preference elicitation schemes have not traditionally considered this last parameter. We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter. Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone. Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions. Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query. The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations. There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing. We expect this to be an important consideration in practice. Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms. Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation. Related work. Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF. Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF. Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway). Their work only makes use of value queries, which are quite limited in power. Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions. Blum et al. [5] provide results relating the complexities of query learning and preference elicitation. They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation. They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa. In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning. We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem. Nisan and Segal [12] study the communication complexity of preference elicitation. They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential. Their results apply to the black-box model of computational complexity. In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations. This is in fact the basic framework of learning theory. Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results. Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2. THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2]. In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle. The target function is drawn from a function class C that is known to the algorithm. Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê. As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function. Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X. It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise. This function may simply be represented as a list of 2m values. Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct. The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm. Let size(f) be the size of the encoding of f with respect to the given representation class. Most representation classes have a natural measure of encoding size. The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example. We will usually only refer to representation classes; the corresponding function classes will be implied. For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions. Two types of queries are commonly used for exact learning: membership and equivalence queries. On a membership query, the learner presents some x ∈ X and the oracle replies with f(x). On an equivalence query, the learner presents its manifest hypothesis ˜f. The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x). An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented. We are interested in efficient learning algorithms. The following definitions are adapted from Kearns and Vazirani [9]: Definition 1. The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x. Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·). Here m is the dimension of the domain. Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations. Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency. We let n = |N| and m = |M|. An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations. Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles. Each valuation vi is drawn from a known class of valuations Vi. The valuation classes do not need to coincide. We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her). Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components. If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values. Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11]. A classic example which we will refer to again later is the XOR bidding language. In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value. To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ). As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied. For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B). We let size(v1, . . . , vn) = Èn i=1 size(vi). That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages). To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation. More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries. She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made. They may also simply be default or random values if no information has been acquired about certain bundles. The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations. Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting. In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids. Two typical queries used in preference elicitation are value and demand queries. On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8]. On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative. Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle. There may be more succinct ways of communicating this vector, as we show in section 5. We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2. The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·). There are some key differences here with the query learning definition. We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation. Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time. This reflects the fact that communication rather than runtime is the bottleneck in elicitation. Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes. It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm. We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods. In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle. This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice. These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting. Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case. We address this in the next section. 3. PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities. Value and membership queries are clear analogs. Slightly less obvious is the fact that equivalence and demand queries are also analogs. To see this, we need the concept of Lindahl prices. Lindahl prices are nonlinear and non-anonymous prices over the bundles. They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods. They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods. Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries. When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices. Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices. The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium. We say that the Lindahl prices support the optimal allocation. It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation. Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved. The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4]. The dual variables to this linear program are supporting Lindahl prices for the resulting allocation. The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller. There is usually a range of possible Lindahl prices supporting a given optimal allocation. The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices. Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare. Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices. Any Lindahl prices will do for our results, but some may have better elicitation properties than others. Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent. We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation. Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices. These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1). Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4). In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries. Lemma 1. Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation). Then either ˜v(S) = v(S) or ˜v(S ) = v(S ). Proof. We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation. Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query. If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction. Thus at least one of S and S is a counterexample to the agents manifest valuation. Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems. Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation. Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes). Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4. FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found. Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned. Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query. Theorem 1. The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries. Proof. Consider the elicitation algorithm in Figure 1. Each membership query in step 1 is simulated with a value query since these are in fact identical. Consider step 4. If all agents reply YES, condition (1) holds. Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations. Thus an optimal allocation has been found. Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1. We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query. This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents. The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms. Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm. That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation. Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries. It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned. The use of demand queries to simulate equivalence queries enables this early halting. We would not obtain this property with equivalence queries based on manifest valuations. 5. COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation. Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication. Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn). Theorem 2. The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries. Proof. The size of any value query is O(m): the message consists solely of the queried bundle. To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4). Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency. Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm. Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size. We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m). Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m). Thus the value and demand queries, and the responses to these queries, are always of polynomial size. An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters. There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation. These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm. We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2. We are likely to be able to do much better than this in practice. Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made. If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm. Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems. They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm. These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages. We consider these issues below. 6. APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations. We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively. Loop until there is a signal to halt: 1. Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2. Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3. Present the allocation and prices to the agents in the form of a demand query. 4. If they all reply YES, output the allocation and halt. Otherwise there is some agent i that has replied with some preferred bundle Si. Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai. Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately. This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly. We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way. We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively. We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18]. In interpreting the methods we emphasize the expressiveness and succinctness of each representation class. The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol. The equivalence queries made by this algorithm are all proper. Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1. A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4. A polynomial over the real numbers has coefficients drawn from the real numbers. Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17]. To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11]. In the additive valuation, the value of a bundle is the number of goods the bundle contains. In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item). It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation. Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients. The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17]. We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature. Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B). The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal. However, XOR is as expressive as required in most economic settings. Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation. Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use. Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature. A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5. Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions. These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2. An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries. Proof. The algorithm will identify each atomic bid in the target XOR bid in turn. Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids). Present ˜v as an equivalence query. If the response is YES, we are done. Otherwise we obtain a bundle S for which v(S) = ˜v(S). Create a bundle T as follows. First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}). If so set T = T − {i}. Otherwise leave T as is and proceed to the next item. We claim that (T, v(T)) is an atomic bid of the target XOR bid. For each item i in T, we have v(T) = v(T − {i}). To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T. Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items. Now assume v(T) = v(T − {i}). Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}. Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction. We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction. Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)). This assumption holds vacuously when the manifest valuation is initialized. Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function. We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption. Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T). Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation. From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF. Recall that Toolbox DNF are polynomials with non-negative coefficients. For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S). Then again from equation (9) it follows that v(S) < ˜v(S). This contradicts (8), so we in fact have v(T) = ˜v(T). Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis. We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified. After each equivalence query, an atomic bid is identified with at most m membership queries. Each counterexample leads to the discovery of a new atomic bid. Thus we make at most tm membership queries and exactly t + 1 equivalence queries. The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient. Applying Theorem 2, we therefore obtain the following corollary: Theorem 3. The representation class of XOR bids can be efficiently elicited from value and demand queries. This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11]. In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise. More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise. The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value. Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions. These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise. Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10]. To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown. The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values). Note that r-of-k threshold functions can always be succinctly represented in O(m) space. Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7. CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries. At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation. Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation. A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types. If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme. The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient. We do not require that agent valuations can be learned with value and demand queries. Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed. This is the preference elicitation problem. Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity. It would be interesting to find examples of valuation classes for which elicitation is easier than learning. Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4). In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms. In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility. We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15]. An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation? We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries. Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes. Acknowledgements We would like to thank Debasis Mishra for helpful discussions. This work is supported in part by NSF grant IIS0238147. 8. REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge. Integer programming for combinatorial auction winner determination. In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin. Learning regular sets from queries and counterexamples. Information and Computation, 75:87-106, November 1987. [3] D. Angluin. Queries and concept learning. Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy. The Package Assignment Model. Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich. Preference elicitation and query learning. In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm. Partial-revelation VCG mechanism for combinatorial auctions. In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham. Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches. In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm. Using value queries in combinatorial auctions. In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani. An Introduction to Computational Learning Theory. MIT Press, 1994. [10] N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. Machine Learning, 2:285-318, 1988. [11] N. Nisan. Bidding and allocation in combinatorial auctions. In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal. The communication requirements of efficient allocations and supporting Lindahl prices. Working Paper, Hebrew University, 2003. [13] D. C. Parkes. Price-based information certificates for minimal-revelation combinatorial auctions. In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. Auction design with costly preference elicitation. In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar. Iterative combinatorial auctions: Theory and practice. In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine. CABOB: A fast optimal algorithm for combinatorial auctions. In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie. Learning sparse multivariate polynomials over a field with queries and counterexamples. In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26. ACM Press, 1993. 187 [18] L. Valiant. A theory of the learnable. Commun. ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm. On polynomial-time preference elicitation with value-queries. In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188",
    "original_translation": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188",
    "original_sentences": [
        "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
        "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
        "The resulting elicitation algorithms perform a polynomial number of queries.",
        "We also give conditions under which the resulting algorithms have polynomial communication.",
        "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
        "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
        "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
        "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
        "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
        "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
        "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
        "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
        "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
        "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
        "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
        "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
        "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
        "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
        "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
        "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
        "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
        "Preference elicitation schemes have not traditionally considered this last parameter.",
        "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
        "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
        "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
        "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
        "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
        "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
        "We expect this to be an important consideration in practice.",
        "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
        "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
        "Related work.",
        "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
        "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
        "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
        "Their work only makes use of value queries, which are quite limited in power.",
        "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
        "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
        "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
        "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
        "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
        "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
        "Nisan and Segal [12] study the communication complexity of preference elicitation.",
        "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
        "Their results apply to the black-box model of computational complexity.",
        "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
        "This is in fact the basic framework of learning theory.",
        "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
        "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
        "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
        "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
        "The target function is drawn from a function class C that is known to the algorithm.",
        "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
        "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
        "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
        "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
        "This function may simply be represented as a list of 2m values.",
        "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
        "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
        "Let size(f) be the size of the encoding of f with respect to the given representation class.",
        "Most representation classes have a natural measure of encoding size.",
        "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
        "We will usually only refer to representation classes; the corresponding function classes will be implied.",
        "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
        "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
        "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
        "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
        "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
        "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
        "We are interested in efficient learning algorithms.",
        "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
        "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
        "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
        "Here m is the dimension of the domain.",
        "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
        "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
        "We let n = |N| and m = |M|.",
        "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
        "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
        "Each valuation vi is drawn from a known class of valuations Vi.",
        "The valuation classes do not need to coincide.",
        "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
        "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
        "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
        "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
        "A classic example which we will refer to again later is the XOR bidding language.",
        "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
        "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
        "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
        "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
        "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
        "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
        "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
        "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
        "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
        "They may also simply be default or random values if no information has been acquired about certain bundles.",
        "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
        "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
        "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
        "Two typical queries used in preference elicitation are value and demand queries.",
        "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
        "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
        "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
        "There may be more succinct ways of communicating this vector, as we show in section 5.",
        "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
        "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
        "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
        "There are some key differences here with the query learning definition.",
        "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
        "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
        "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
        "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
        "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
        "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
        "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
        "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
        "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
        "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
        "We address this in the next section. 3.",
        "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
        "Value and membership queries are clear analogs.",
        "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
        "To see this, we need the concept of Lindahl prices.",
        "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
        "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
        "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
        "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
        "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
        "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
        "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
        "We say that the Lindahl prices support the optimal allocation.",
        "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
        "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
        "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
        "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
        "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
        "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
        "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
        "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
        "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
        "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
        "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
        "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
        "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
        "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
        "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
        "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
        "Lemma 1.",
        "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
        "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
        "Proof.",
        "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
        "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
        "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
        "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
        "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
        "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
        "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
        "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
        "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
        "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
        "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
        "Theorem 1.",
        "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
        "Proof.",
        "Consider the elicitation algorithm in Figure 1.",
        "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
        "Consider step 4.",
        "If all agents reply YES, condition (1) holds.",
        "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
        "Thus an optimal allocation has been found.",
        "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
        "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
        "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
        "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
        "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
        "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
        "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
        "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
        "The use of demand queries to simulate equivalence queries enables this early halting.",
        "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
        "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
        "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
        "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
        "Theorem 2.",
        "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
        "Proof.",
        "The size of any value query is O(m): the message consists solely of the queried bundle.",
        "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
        "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
        "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
        "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
        "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
        "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
        "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
        "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
        "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
        "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
        "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
        "We are likely to be able to do much better than this in practice.",
        "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
        "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
        "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
        "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
        "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
        "We consider these issues below. 6.",
        "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
        "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
        "Loop until there is a signal to halt: 1.",
        "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
        "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
        "Present the allocation and prices to the agents in the form of a demand query. 4.",
        "If they all reply YES, output the allocation and halt.",
        "Otherwise there is some agent i that has replied with some preferred bundle Si.",
        "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
        "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
        "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
        "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
        "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
        "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
        "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
        "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
        "The equivalence queries made by this algorithm are all proper.",
        "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
        "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
        "A polynomial over the real numbers has coefficients drawn from the real numbers.",
        "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
        "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
        "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
        "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
        "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
        "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
        "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
        "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
        "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
        "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
        "However, XOR is as expressive as required in most economic settings.",
        "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
        "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
        "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
        "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
        "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
        "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
        "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
        "Proof.",
        "The algorithm will identify each atomic bid in the target XOR bid in turn.",
        "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
        "Present ˜v as an equivalence query.",
        "If the response is YES, we are done.",
        "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
        "Create a bundle T as follows.",
        "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
        "If so set T = T − {i}.",
        "Otherwise leave T as is and proceed to the next item.",
        "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
        "For each item i in T, we have v(T) = v(T − {i}).",
        "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
        "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
        "Now assume v(T) = v(T − {i}).",
        "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
        "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
        "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
        "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
        "This assumption holds vacuously when the manifest valuation is initialized.",
        "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
        "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
        "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
        "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
        "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
        "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
        "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
        "Then again from equation (9) it follows that v(S) < ˜v(S).",
        "This contradicts (8), so we in fact have v(T) = ˜v(T).",
        "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
        "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
        "After each equivalence query, an atomic bid is identified with at most m membership queries.",
        "Each counterexample leads to the discovery of a new atomic bid.",
        "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
        "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
        "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
        "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
        "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
        "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
        "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
        "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
        "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
        "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
        "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
        "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
        "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
        "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
        "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
        "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
        "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
        "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
        "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
        "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
        "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
        "We do not require that agent valuations can be learned with value and demand queries.",
        "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
        "This is the preference elicitation problem.",
        "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
        "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
        "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
        "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
        "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
        "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
        "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
        "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
        "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
        "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
        "This work is supported in part by NSF grant IIS0238147. 8.",
        "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
        "Integer programming for combinatorial auction winner determination.",
        "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
        "Learning regular sets from queries and counterexamples.",
        "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
        "Queries and concept learning.",
        "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
        "The Package Assignment Model.",
        "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
        "Preference elicitation and query learning.",
        "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
        "Partial-revelation VCG mechanism for combinatorial auctions.",
        "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
        "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
        "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
        "Using value queries in combinatorial auctions.",
        "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
        "An Introduction to Computational Learning Theory.",
        "MIT Press, 1994. [10] N. Littlestone.",
        "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
        "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
        "Bidding and allocation in combinatorial auctions.",
        "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
        "The communication requirements of efficient allocations and supporting Lindahl prices.",
        "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
        "Price-based information certificates for minimal-revelation combinatorial auctions.",
        "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
        "Springer-Verlag, 2002. [14] D. C. Parkes.",
        "Auction design with costly preference elicitation.",
        "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
        "Iterative combinatorial auctions: Theory and practice.",
        "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
        "CABOB: A fast optimal algorithm for combinatorial auctions.",
        "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
        "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
        "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
        "ACM Press, 1993. 187 [18] L. Valiant.",
        "A theory of the learnable.",
        "Commun.",
        "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
        "On polynomial-time preference elicitation with value-queries.",
        "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
    ],
    "translated_text_sentences": [
        "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje.",
        "Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias.",
        "Los algoritmos de elicitación resultantes realizan un número polinómico de consultas.",
        "También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica.",
        "Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal.",
        "En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica.",
        "Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1.",
        "En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente.",
        "Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático.",
        "Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande.",
        "Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14].",
        "Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible.",
        "Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores.",
        "Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes.",
        "Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19].",
        "En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas?",
        "En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima.",
        "Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro.",
        "Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda.",
        "El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda.",
        "Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado.",
        "Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro.",
        "Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro.",
        "La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes.",
        "Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales.",
        "Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta.",
        "La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones.",
        "No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores.",
        "Esperamos que esto sea una consideración importante en la práctica.",
        "Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información.",
        "Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias.",
        "Trabajo relacionado.",
        "Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF.",
        "Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF.",
        "Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos).",
        "Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder.",
        "Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales.",
        "Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias.",
        "Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias.",
        "Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa.",
        "Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje.",
        "Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información.",
        "Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias.",
        "Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial.",
        "Sus resultados se aplican al modelo de caja negra de complejidad computacional.",
        "En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones.",
        "Este es de hecho el marco básico de la teoría del aprendizaje.",
        "Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal.",
        "Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2.",
        "El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2].",
        "En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo.",
        "La función objetivo se extrae de una clase de funciones C que el algoritmo conoce.",
        "Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê.",
        "A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo.",
        "Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X.",
        "Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario.",
        "Esta función puede ser representada simplemente como una lista de 2m valores.",
        "O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso.",
        "La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje.",
        "Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada.",
        "La mayoría de las clases de representación tienen una medida natural del tamaño de codificación.",
        "El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo.",
        "Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas.",
        "Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas.",
        "Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia.",
        "En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x).",
        "En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f.",
        "El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x).",
        "Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta.",
        "Estamos interesados en algoritmos de aprendizaje eficientes.",
        "Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1.",
        "La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x.",
        "De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·).",
        "Aquí m es la dimensión del dominio.",
        "Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes.",
        "Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional.",
        "Dejamos n = |N| y m = |M|.",
        "Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles.",
        "Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes.",
        "Cada valoración vi se extrae de una clase conocida de valoraciones Vi.",
        "Las clases de valoración no necesitan coincidir.",
        "Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella).",
        "Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios.",
        "Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos.",
        "Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11].",
        "Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR.",
        "En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor.",
        "Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S).",
        "Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas.",
        "Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B).",
        "Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi).",
        "Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta).",
        "Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación.",
        "De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas.",
        "Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas.",
        "También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes.",
        "El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales.",
        "Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje.",
        "En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas.",
        "Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda.",
        "En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8].",
        "En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa.",
        "También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete.",
        "Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5.",
        "Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2.",
        "Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
        "Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·).",
        "Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta.",
        "Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima.",
        "Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico.",
        "Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información.",
        "Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración.",
        "Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias.",
        "Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes.",
        "En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete.",
        "Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica.",
        "Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto.",
        "De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos.",
        "Abordaremos esto en la siguiente sección. 3.",
        "Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes.",
        "Las consultas de valor y de membresía son claros análogos.",
        "Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas.",
        "Para ver esto, necesitamos el concepto de precios de Lindahl.",
        "Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes.",
        "Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes.",
        "No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes.",
        "Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda.",
        "Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados.",
        "La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados.",
        "El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo.",
        "Decimos que los precios de Lindahl respaldan la asignación óptima.",
        "Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima.",
        "Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto.",
        "El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4].",
        "Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante.",
        "La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor.",
        "Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada.",
        "Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos.",
        "De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social.",
        "Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl.",
        "Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros.",
        "Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente.",
        "Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias.",
        "Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos.",
        "Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1).",
        "Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4).",
        "En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda.",
        "Lema 1.",
        "Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes).",
        "Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S).",
        "Prueba.",
        "Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta.",
        "La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda.",
        "Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción.",
        "Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes.",
        "Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información.",
        "Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima.",
        "Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes).",
        "Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4.",
        "DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima.",
        "Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente.",
        "De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda.",
        "Teorema 1.",
        "Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales.",
        "Prueba.",
        "Considera el algoritmo de obtención en la Figura 1.",
        "Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas.",
        "Considera el paso 4.",
        "Si todos los agentes responden SÍ, se cumple la condición (1).",
        "La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes.",
        "Por lo tanto, se ha encontrado una asignación óptima.",
        "De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1.",
        "Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia.",
        "Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes.",
        "El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas.",
        "Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje.",
        "Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima.",
        "Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda.",
        "Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente.",
        "El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana.",
        "No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5.",
        "COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información.",
        "Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua.",
        "Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn).",
        "Teorema 2.",
        "Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia.",
        "Prueba.",
        "El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado.",
        "Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4).",
        "Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia.",
        "Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente.",
        "Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico.",
        "También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m).",
        "Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m).",
        "Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico.",
        "Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes.",
        "A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O.",
        "Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante.",
        "Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2.",
        "Es probable que podamos hacer mucho mejor que esto en la práctica.",
        "Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta.",
        "Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante.",
        "El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente.",
        "Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo.",
        "Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos.",
        "Consideramos estos temas a continuación. 6.",
        "En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias.",
        "Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente.",
        "Bucle hasta que haya una señal para detenerse: 1.",
        "Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2.",
        "Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3.",
        "Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4.",
        "Si todos responden SÍ, mostrar la asignación y detenerse.",
        "De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si.",
        "Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai.",
        "Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado.",
        "Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias.",
        "Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo.",
        "Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente.",
        "Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18].",
        "Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación.",
        "La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria.",
        "Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas.",
        "Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1.",
        "Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4.",
        "Un polinomio sobre los números reales tiene coeficientes tomados de los números reales.",
        "Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17].",
        "Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11].",
        "En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete.",
        "En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo).",
        "No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva.",
        "Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes.",
        "El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17].",
        "Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias.",
        "Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B).",
        "El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre.",
        "Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos.",
        "Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva.",
        "Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico.",
        "Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje.",
        "Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5.",
        "Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales.",
        "Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2.",
        "Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía.",
        "Prueba.",
        "El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una.",
        "Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas).",
        "Presenta ˜v como una consulta de equivalencia.",
        "Si la respuesta es SÍ, hemos terminado.",
        "De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S).",
        "Crear un paquete T de la siguiente manera.",
        "Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}).",
        "Si es así, establezca T = T - {i}.",
        "De lo contrario, deja T como está y continúa con el siguiente elemento.",
        "Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo.",
        "Para cada elemento i en T, tenemos que v(T) = v(T − {i}).",
        "Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T.",
        "Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos.",
        "Ahora suponga que v(T) = v(T − {i}).",
        "Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}.",
        "Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción.",
        "Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción.",
        "Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)).",
        "Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta.",
        "Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo.",
        "Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición.",
        "Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T).",
        "Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta.",
        "A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF.",
        "Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos.",
        "Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S).",
        "Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S).",
        "Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T).",
        "Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción.",
        "Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas.",
        "Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía.",
        "Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica.",
        "Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia.",
        "El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente.",
        "Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3.",
        "La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda.",
        "Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11].",
        "En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario.",
        "Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario.",
        "La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor.",
        "Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k.",
        "Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario.",
        "Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10].",
        "Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos.",
        "El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores).",
        "Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m).",
        "Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7.",
        "CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda.",
        "En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias.",
        "Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias.",
        "Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes.",
        "Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información.",
        "El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes.",
        "No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda.",
        "Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima.",
        "Este es el problema de la obtención de preferencias.",
        "El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje.",
        "Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje.",
        "Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4).",
        "En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información.",
        "En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad.",
        "También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15].",
        "Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información?",
        "Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia.",
        "Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración.",
        "Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones.",
        "Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147.",
        "REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge.",
        "Programación entera para la determinación del ganador en subastas combinatorias.",
        "En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin.",
        "Aprendiendo conjuntos regulares a partir de consultas y contraejemplos.",
        "Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin.",
        "Consultas y aprendizaje de conceptos.",
        "Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy.",
        "El Modelo de Asignación de Paquetes.",
        "Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich.",
        "Elicitación de preferencias y aprendizaje de consultas.",
        "En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm.",
        "Mecanismo VCG de revelación parcial para subastas combinatorias.",
        "En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham.",
        "Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados.",
        "En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm.",
        "Utilizando consultas de valor en subastas combinatorias.",
        "En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani.",
        "Una introducción a la teoría computacional del aprendizaje.",
        "MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone.",
        "Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal.",
        "Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan.",
        "Subasta y asignación en subastas combinatorias.",
        "En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal.",
        "Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo.",
        "Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes.",
        "Certificados de información basados en precios para subastas combinatorias de revelación mínima.",
        "En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122.",
        "Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes.",
        "Diseño de subasta con elicitación costosa de preferencias.",
        "En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar.",
        "Subastas combinatorias iterativas: Teoría y práctica.",
        "En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine.",
        "CABOB: Un algoritmo rápido y óptimo para subastas combinatorias.",
        "En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie.",
        "Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos.",
        "En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26.",
        "ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant.",
        "Una teoría de lo aprendible.",
        "Comunicación.",
        "ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm.",
        "En la obtención de preferencias en tiempo polinómico con consultas de valor.",
        "En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188"
    ],
    "error_count": 11,
    "keys": {
        "parallel": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to <br>parallel</br> the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to <br>parallel</br> the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in <br>parallel</br> on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to <br>parallel</br> the learning setting.",
                "We make the following definitions to <br>parallel</br> the query learning setting and to simplify the statements of later results: Definition 2.",
                "Run A1, . . . , An in <br>parallel</br> on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2."
            ],
            "translated_annotated_samples": [
                "Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser <br>paralela</br> al entorno de aprendizaje.",
                "Hacemos las siguientes definiciones para <br>paralelizar</br> el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2.",
                "Ejecutar A1, . . . , An <br>en paralelo</br> en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser <br>paralela</br> al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para <br>paralelizar</br> el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An <br>en paralelo</br> en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "candidates": [],
            "error": [
                [
                    "paralela",
                    "paralelizar",
                    "en paralelo"
                ]
            ]
        },
        "preference elicitation problem": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the <br>preference elicitation problem</br> in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the <br>preference elicitation problem</br> in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the <br>preference elicitation problem</br> is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the <br>preference elicitation problem</br> for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the <br>preference elicitation problem</br> directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the <br>preference elicitation problem</br>.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the <br>preference elicitation problem</br> in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "There has been recent work exploring the links between the <br>preference elicitation problem</br> in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "The goal in the <br>preference elicitation problem</br> is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "We have shown that the <br>preference elicitation problem</br> for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the <br>preference elicitation problem</br> directly."
            ],
            "translated_annotated_samples": [
                "Aplicando algoritmos de aprendizaje a la <br>obtención de preferencias</br> Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de <br>obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje.",
                "Ha habido trabajos recientes explorando los vínculos entre el <br>problema de la obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19].",
                "El objetivo en el problema de la <br>obtención de preferencias</br> es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales.",
                "Hemos demostrado que el <br>problema de la obtención de preferencias</br> para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente.",
                "Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el <br>problema de la obtención de preferencias</br>."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la <br>obtención de preferencias</br> Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de <br>obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el <br>problema de la obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la <br>obtención de preferencias</br> es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el <br>problema de la obtención de preferencias</br> para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el <br>problema de la obtención de preferencias</br>. ",
            "candidates": [],
            "error": [
                [
                    "obtención de preferencias",
                    "obtención de preferencias",
                    "problema de la obtención de preferencias",
                    "obtención de preferencias",
                    "problema de la obtención de preferencias",
                    "problema de la obtención de preferencias"
                ]
            ]
        },
        "combinatorial auction": {
            "translated_key": "subasta combinatoria",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate <br>combinatorial auction</br> protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a <br>combinatorial auction</br>, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate <br>combinatorial auction</br> protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot <br>combinatorial auction</br> where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a <br>combinatorial auction</br>, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in <br>combinatorial auction</br> terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a <br>combinatorial auction</br> protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established <br>combinatorial auction</br> protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for <br>combinatorial auction</br> winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Our conversion procedure allows us to generate <br>combinatorial auction</br> protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "INTRODUCTION In a <br>combinatorial auction</br>, agents may bid on bundles of goods rather than individual goods alone.",
                "Finally, we use our conversion procedure to generate <br>combinatorial auction</br> protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot <br>combinatorial auction</br> where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a <br>combinatorial auction</br>, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations."
            ],
            "translated_annotated_samples": [
                "Nuestro procedimiento de conversión nos permite generar protocolos de <br>subasta combinatoria</br> a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal.",
                "En una <br>subasta combinatoria</br>, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente.",
                "Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de <br>subasta combinatoria</br> a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales.",
                "Por supuesto, una <br>subasta combinatoria</br> de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta.",
                "Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una <br>subasta combinatoria</br>, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de <br>subasta combinatoria</br> a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una <br>subasta combinatoria</br>, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de <br>subasta combinatoria</br> a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una <br>subasta combinatoria</br> de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una <br>subasta combinatoria</br>, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "learning": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying <br>learning</br> Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of <br>learning</br> an unknown function from learning theory.",
                "We show that <br>learning</br> algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from <br>learning</br> algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: <br>learning</br> General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of <br>learning</br> an unknown function from computational <br>learning</br> theory [5, 19].",
                "In <br>learning</br> theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of <br>learning</br> and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact <br>learning</br> algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from <br>learning</br> algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of <br>learning</br> and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of <br>learning</br> restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in <br>learning</br> theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query <br>learning</br> and preference elicitation.",
                "They consider models with membership and equivalence queries in query <br>learning</br>, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of <br>learning</br>.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of <br>learning</br> theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query <br>learning</br> The query <br>learning</br> model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the <br>learning</br> algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct <br>learning</br> algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the <br>learning</br> algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact <br>learning</br>: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient <br>learning</br> algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the <br>learning</br> theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational <br>learning</br> theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in <br>learning</br> theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the <br>learning</br> setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query <br>learning</br> setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query <br>learning</br> definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query <br>learning</br> and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM <br>learning</br> TO PREFERENCE ELICITATION The key to converting a <br>learning</br> algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query <br>learning</br> algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a <br>learning</br> algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient <br>learning</br> algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient <br>learning</br> algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient <br>learning</br> algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient <br>learning</br> algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a <br>learning</br> algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the <br>learning</br> algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the <br>learning</br> algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact <br>learning</br> algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting <br>learning</br> algorithms to an elicitation algorithm. to the problem of finding an efficient <br>learning</br> algorithm for each of these classes separately.",
                "This is significant because there already exist <br>learning</br> algorithms for a wealth of function classes, and because it may often be simpler to solve each <br>learning</br> subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying <br>learning</br> algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing <br>learning</br> algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational <br>learning</br> theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a <br>learning</br> algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The <br>learning</br> algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the <br>learning</br> theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic <br>learning</br> algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a <br>learning</br> algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact <br>learning</br> algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available <br>learning</br> algorithms to the problem of preference elicitation.",
                "A <br>learning</br> approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design <br>learning</br> algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original <br>learning</br> algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than <br>learning</br> with membership and equivalence queries, but it does not provide any asymptotic improvements over the <br>learning</br> algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than <br>learning</br>.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting <br>learning</br> algorithms to elicitation algorithms.",
                "In the <br>learning</br> setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for <br>learning</br> polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "<br>learning</br> regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept <br>learning</br>.",
                "Machine <br>learning</br>, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query <br>learning</br>.",
                "In Proc. 16th Annual Conference on Computational <br>learning</br> Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational <br>learning</br> Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "<br>learning</br> quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine <br>learning</br>, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "<br>learning</br> sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational <br>learning</br> Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Applying <br>learning</br> Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of <br>learning</br> an unknown function from learning theory.",
                "We show that <br>learning</br> algorithms can be used as a basis for preference elicitation algorithms.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from <br>learning</br> algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: <br>learning</br> General Terms Algorithms, Economics, Theory 1.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of <br>learning</br> an unknown function from computational <br>learning</br> theory [5, 19]."
            ],
            "translated_annotated_samples": [
                "Aplicando algoritmos de <br>aprendizaje</br> a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del <br>aprendizaje</br>.",
                "Mostramos que los <br>algoritmos de aprendizaje</br> pueden ser utilizados como base para algoritmos de obtención de preferencias.",
                "Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de <br>aprendizaje</br> para polinomios, DNF monótono y funciones de umbral lineal.",
                "Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1.",
                "Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del <br>aprendizaje</br> [5, 19]."
            ],
            "translated_text": "Aplicando algoritmos de <br>aprendizaje</br> a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del <br>aprendizaje</br>. Mostramos que los <br>algoritmos de aprendizaje</br> pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de <br>aprendizaje</br> para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del <br>aprendizaje</br> [5, 19]. ",
            "candidates": [],
            "error": [
                [
                    "aprendizaje",
                    "aprendizaje",
                    "algoritmos de aprendizaje",
                    "aprendizaje",
                    "aprendizaje"
                ]
            ]
        },
        "learning theory": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from <br>learning theory</br>.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational <br>learning theory</br> [5, 19].",
                "In <br>learning theory</br>, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in <br>learning theory</br>, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of <br>learning theory</br>.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the <br>learning theory</br> setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational <br>learning theory</br>, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in <br>learning theory</br> that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational <br>learning theory</br> literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the <br>learning theory</br> literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational <br>learning theory</br> (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational <br>learning theory</br>.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational <br>learning theory</br>, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from <br>learning theory</br>.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational <br>learning theory</br> [5, 19].",
                "In <br>learning theory</br>, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "Since their work is also grounded in <br>learning theory</br>, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "This is in fact the basic framework of <br>learning theory</br>."
            ],
            "translated_annotated_samples": [
                "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la <br>teoría del aprendizaje</br>.",
                "Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la <br>teoría computacional del aprendizaje</br> [5, 19].",
                "En la <br>teoría del aprendizaje</br>, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas?",
                "Dado que su trabajo también se basa en la <br>teoría del aprendizaje</br>, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos).",
                "Este es de hecho el marco básico de la <br>teoría del aprendizaje</br>."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la <br>teoría del aprendizaje</br>. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la <br>teoría computacional del aprendizaje</br> [5, 19]. En la <br>teoría del aprendizaje</br>, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la <br>teoría del aprendizaje</br>, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la <br>teoría del aprendizaje</br>. ",
            "candidates": [],
            "error": [
                [
                    "teoría del aprendizaje",
                    "teoría computacional del aprendizaje",
                    "teoría del aprendizaje",
                    "teoría del aprendizaje",
                    "teoría del aprendizaje"
                ]
            ]
        },
        "learning algorithm": {
            "translated_key": "algoritmo de aprendizaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact <br>learning algorithm</br> with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct <br>learning algorithm</br> satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the <br>learning algorithm</br>.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a <br>learning algorithm</br> to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a <br>learning algorithm</br>.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient <br>learning algorithm</br> never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient <br>learning algorithm</br>.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient <br>learning algorithm</br> performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a <br>learning algorithm</br>, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the <br>learning algorithm</br> in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient <br>learning algorithm</br> for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a <br>learning algorithm</br> for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The <br>learning algorithm</br> for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic <br>learning algorithm</br> for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a <br>learning algorithm</br> for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "We show that any exact <br>learning algorithm</br> with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "Upon termination, the manifest hypothesis of a correct <br>learning algorithm</br> satisfies ˜f(x) = f(x) for all x ∈ X.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the <br>learning algorithm</br>.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a <br>learning algorithm</br> to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a <br>learning algorithm</br>."
            ],
            "translated_annotated_samples": [
                "Mostramos que cualquier <br>algoritmo de aprendizaje</br> exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda.",
                "Al finalizar, la hipótesis manifiesta de un <br>algoritmo de aprendizaje</br> correcto satisface ˜f(x) = f(x) para todo x ∈ X.",
                "La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del <br>algoritmo de aprendizaje</br>.",
                "DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un <br>algoritmo de aprendizaje</br> en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima.",
                "Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un <br>algoritmo de aprendizaje</br>."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier <br>algoritmo de aprendizaje</br> exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un <br>algoritmo de aprendizaje</br> correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del <br>algoritmo de aprendizaje</br>. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un <br>algoritmo de aprendizaje</br> en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un <br>algoritmo de aprendizaje</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "preference elicitation algorithm": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a <br>preference elicitation algorithm</br> with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient <br>preference elicitation algorithm</br>.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a <br>preference elicitation algorithm</br>, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a <br>preference elicitation algorithm</br> with value and demand queries.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient <br>preference elicitation algorithm</br>.",
                "Note that the conversion procedure results in a <br>preference elicitation algorithm</br>, not a learning algorithm."
            ],
            "translated_annotated_samples": [
                "Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un <br>algoritmo de obtención de preferencias</br> con consultas de valor y demanda.",
                "Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un <br>algoritmo eficiente de elicitación de preferencias</br>.",
                "Ten en cuenta que el procedimiento de conversión resulta en un <br>algoritmo de elicitación de preferencias</br>, no en un algoritmo de aprendizaje."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un <br>algoritmo de obtención de preferencias</br> con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un <br>algoritmo eficiente de elicitación de preferencias</br>. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un <br>algoritmo de elicitación de preferencias</br>, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "candidates": [],
            "error": [
                [
                    "algoritmo de obtención de preferencias",
                    "algoritmo eficiente de elicitación de preferencias",
                    "algoritmo de elicitación de preferencias"
                ]
            ]
        },
        "elicitation algorithm": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference <br>elicitation algorithm</br> with value and demand queries.",
                "The resulting <br>elicitation algorithm</br> guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient <br>elicitation algorithm</br> is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference <br>elicitation algorithm</br>.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an <br>elicitation algorithm</br> is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the <br>elicitation algorithm</br> in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference <br>elicitation algorithm</br>, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an <br>elicitation algorithm</br> produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting <br>elicitation algorithm</br> is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting <br>elicitation algorithm</br>.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting <br>elicitation algorithm</br>.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an <br>elicitation algorithm</br>. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an <br>elicitation algorithm</br> that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] <br>elicitation algorithm</br> for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The <br>elicitation algorithm</br> that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting <br>elicitation algorithm</br> makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference <br>elicitation algorithm</br> with value and demand queries.",
                "The resulting <br>elicitation algorithm</br> guarantees elicitation in a polynomial number of value and demand queries.",
                "Also, an efficient <br>elicitation algorithm</br> is polynomial communication, rather than polynomial time.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference <br>elicitation algorithm</br>.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an <br>elicitation algorithm</br> is to simulate equivalence queries with demand and value queries until an optimal allocation is found."
            ],
            "translated_annotated_samples": [
                "Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un <br>algoritmo de obtención de preferencias</br> con consultas de valor y demanda.",
                "El <br>algoritmo de elicitación</br> resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda.",
                "Además, un <br>algoritmo de obtención</br> eficiente es de comunicación polinómica, en lugar de tiempo polinómico.",
                "Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un <br>algoritmo eficiente de elicitación</br> de preferencias.",
                "DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un <br>algoritmo de elicitation</br> es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un <br>algoritmo de obtención de preferencias</br> con consultas de valor y demanda. El <br>algoritmo de elicitación</br> resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un <br>algoritmo de obtención</br> eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un <br>algoritmo eficiente de elicitación</br> de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un <br>algoritmo de elicitation</br> es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. ",
            "candidates": [],
            "error": [
                [
                    "algoritmo de obtención de preferencias",
                    "algoritmo de elicitación",
                    "algoritmo de obtención",
                    "algoritmo eficiente de elicitación",
                    "algoritmo de elicitation"
                ]
            ]
        },
        "polynomial number of queries": {
            "translated_key": "número polinómico de consultas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a <br>polynomial number of queries</br>.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a <br>polynomial number of queries</br>, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a <br>polynomial number of queries</br>, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a <br>polynomial number of queries</br> and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a <br>polynomial number of queries</br> and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a <br>polynomial number of queries</br>, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "The resulting elicitation algorithms perform a <br>polynomial number of queries</br>.",
                "The procedure performs a <br>polynomial number of queries</br>, since A1, . . . , An are all polynomial-query learning algorithms.",
                "An efficient learning algorithm performs a <br>polynomial number of queries</br>, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "We therefore obtain an algorithm that elicits general valuations with a <br>polynomial number of queries</br> and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Thus we obtain an algorithm that can elicit such functions with a <br>polynomial number of queries</br> and polynomial communication, in the parameters n and m alone. 186 7."
            ],
            "translated_annotated_samples": [
                "Los algoritmos de elicitación resultantes realizan un <br>número polinómico de consultas</br>.",
                "El procedimiento realiza un <br>número polinómico de consultas</br>, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas.",
                "Un algoritmo de aprendizaje eficiente realiza un <br>número polinómico de consultas</br>, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes.",
                "Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un <br>número polinómico de consultas</br> y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias.",
                "Así obtenemos un algoritmo que puede obtener dichas funciones con un <br>número polinómico de consultas</br> y comunicación polinómica, solo en los parámetros n y m. 186 7."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un <br>número polinómico de consultas</br>. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un <br>número polinómico de consultas</br>, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un <br>número polinómico de consultas</br>, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un <br>número polinómico de consultas</br> y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un <br>número polinómico de consultas</br> y comunicación polinómica, solo en los parámetros n y m. 186 7. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "query polynomial number": {
            "translated_key": "polinomio de consulta",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "polynomial communication": {
            "translated_key": "comunicación polinómica",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have <br>polynomial communication</br>.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with <br>polynomial communication</br>.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have <br>polynomial communication</br> in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is <br>polynomial communication</br>, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and <br>polynomial communication</br>6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and <br>polynomial communication</br>, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes <br>polynomial communication</br> if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "We also give conditions under which the resulting algorithms have <br>polynomial communication</br>.",
                "In particular, we obtain an algorithm that elicits XOR bids with <br>polynomial communication</br>.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have <br>polynomial communication</br> in the size of the agents valuations, and only require one query.",
                "Also, an efficient elicitation algorithm is <br>polynomial communication</br>, rather than polynomial time.",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and <br>polynomial communication</br>6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature."
            ],
            "translated_annotated_samples": [
                "También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen <br>comunicación polinómica</br>.",
                "En particular, obtenemos un algoritmo que obtiene ofertas XOR con <br>comunicación polinómica</br>.",
                "Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una <br>comunicación polinómica</br> en el tamaño de las valoraciones de los agentes y solo requeriría una consulta.",
                "Además, un algoritmo de obtención eficiente es de <br>comunicación polinómica</br>, en lugar de tiempo polinómico.",
                "Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y <br>comunicación polinómica</br>. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen <br>comunicación polinómica</br>. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con <br>comunicación polinómica</br>. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una <br>comunicación polinómica</br> en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de <br>comunicación polinómica</br>, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y <br>comunicación polinómica</br>. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "resulting algorithm": {
            "translated_key": "algoritmo resultante",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the <br>resulting algorithm</br> does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "That is, the <br>resulting algorithm</br> does not simply learn the valuations exactly, then compute an optimal allocation."
            ],
            "translated_annotated_samples": [
                "Es decir, el <br>algoritmo resultante</br> no solo aprende las valoraciones exactamente, luego calcula una asignación óptima."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el <br>algoritmo resultante</br> no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "conversion procedure": {
            "translated_key": "procedimiento de conversión",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our <br>conversion procedure</br> allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our <br>conversion procedure</br> to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the <br>conversion procedure</br> results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Our <br>conversion procedure</br> allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Finally, we use our <br>conversion procedure</br> to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Note that the <br>conversion procedure</br> results in a preference elicitation algorithm, not a learning algorithm."
            ],
            "translated_annotated_samples": [
                "Nuestro <br>procedimiento de conversión</br> nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal.",
                "Finalmente, utilizamos nuestro <br>procedimiento de conversión</br> para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales.",
                "Ten en cuenta que el <br>procedimiento de conversión</br> resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro <br>procedimiento de conversión</br> nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro <br>procedimiento de conversión</br> para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el <br>procedimiento de conversión</br> resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "combinatorial auction protocol": {
            "translated_key": "protocolo de subasta combinatoria",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a <br>combinatorial auction protocol</br>.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a <br>combinatorial auction protocol</br>."
            ],
            "translated_annotated_samples": [
                "La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un <br>protocolo de subasta combinatoria</br>."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un <br>protocolo de subasta combinatoria</br>. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "polynomial": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a <br>polynomial</br> number of queries.",
                "We also give conditions under which the resulting algorithms have <br>polynomial</br> communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with <br>polynomial</br> communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a <br>polynomial</br> number of value and demand queries.",
                "Here we mean <br>polynomial</br> in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee <br>polynomial</br> worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have <br>polynomial</br> communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the <br>polynomial</br> 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a <br>polynomial</br> can be defined as the number of non-zero coefficients in the <br>polynomial</br>, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed <br>polynomial</br> p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed <br>polynomial</br> p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow <br>polynomial</br> dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in <br>polynomial</br> time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed <br>polynomial</br> q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be <br>polynomial</br>-query elicited from value and demand queries if there is a fixed <br>polynomial</br> p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed <br>polynomial</br> p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is <br>polynomial</br> communication, rather than <br>polynomial</br> time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require <br>polynomial</br> time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the <br>polynomial</br> dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be <br>polynomial</br>-query elicited from value and demand queries if they can each be <br>polynomial</br>-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a <br>polynomial</br> number of queries, since A1, . . . , An are all <br>polynomial</br>-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes <br>polynomial</br> in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some <br>polynomial</br> p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed <br>polynomial</br> q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of <br>polynomial</br> size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of <br>polynomial</br> size.",
                "An efficient learning algorithm performs a <br>polynomial</br> number of queries, so the total communication of the resulting elicitation algorithm is <br>polynomial</br> in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 <br>polynomial</br> Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse <br>polynomial</br> has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A <br>polynomial</br> over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a <br>polynomial</br> [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the <br>polynomial</br> representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a <br>polynomial</br> number of queries and <br>polynomial</br> communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a <br>polynomial</br> number of queries and <br>polynomial</br> communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a <br>polynomial</br> number of queries, and makes <br>polynomial</br> communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On <br>polynomial</br>-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "The resulting elicitation algorithms perform a <br>polynomial</br> number of queries.",
                "We also give conditions under which the resulting algorithms have <br>polynomial</br> communication.",
                "In particular, we obtain an algorithm that elicits XOR bids with <br>polynomial</br> communication.",
                "The resulting elicitation algorithm guarantees elicitation in a <br>polynomial</br> number of value and demand queries.",
                "Here we mean <br>polynomial</br> in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme."
            ],
            "translated_annotated_samples": [
                "Los algoritmos de elicitación resultantes realizan un número <br>polinómico</br> de consultas.",
                "También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen <br>comunicación polinómica</br>.",
                "En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación <br>polinómica</br>.",
                "El algoritmo de elicitación resultante garantiza la elicitación en un número <br>polinomial</br> de consultas de valor y demanda.",
                "Aquí nos referimos a un <br>polinomio</br> en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número <br>polinómico</br> de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen <br>comunicación polinómica</br>. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación <br>polinómica</br>. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número <br>polinomial</br> de consultas de valor y demanda. Aquí nos referimos a un <br>polinomio</br> en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. ",
            "candidates": [],
            "error": [
                [
                    "polinómico",
                    "comunicación polinómica",
                    "polinómica",
                    "polinomial",
                    "polinomio"
                ]
            ]
        },
        "monotone dnf": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, <br>monotone dnf</br>, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, <br>monotone dnf</br>, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of <br>monotone dnf</br> formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, <br>monotone dnf</br> formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that <br>monotone dnf</br> formulae are the analogs of XOR bids in the learning theory literature.",
                "A <br>monotone dnf</br> formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize <br>monotone dnf</br> formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for <br>monotone dnf</br> ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that <br>monotone dnf</br> (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, <br>monotone dnf</br>, and linear-threshold functions.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, <br>monotone dnf</br>, and linear-threshold functions.",
                "For example, the representation class of <br>monotone dnf</br> formulae implies the function class of monotone Boolean functions.",
                "We show that existing learning algorithms for polynomials, <br>monotone dnf</br> formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "Blum et al. [5] note that <br>monotone dnf</br> formulae are the analogs of XOR bids in the learning theory literature."
            ],
            "translated_annotated_samples": [
                "Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, <br>DNF monótono</br> y funciones de umbral lineal.",
                "Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, <br>DNF monótono</br> y funciones de umbral lineales.",
                "Por ejemplo, la clase de representación de <br>fórmulas DNF monótonas</br> implica la clase de funciones Booleanas monótonas.",
                "Mostramos que los algoritmos de aprendizaje existentes para polinomios, <br>fórmulas DNF monótonas</br> y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente.",
                "Blum et al. [5] señalan que las <br>fórmulas DNF monótonas</br> son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, <br>DNF monótono</br> y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, <br>DNF monótono</br> y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de <br>fórmulas DNF monótonas</br> implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, <br>fórmulas DNF monótonas</br> y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las <br>fórmulas DNF monótonas</br> son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. ",
            "candidates": [],
            "error": [
                [
                    "DNF monótono",
                    "DNF monótono",
                    "fórmulas DNF monótonas",
                    "fórmulas DNF monótonas",
                    "fórmulas DNF monótonas"
                ]
            ]
        },
        "linear-threshold function": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and <br>linear-threshold function</br>s.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and <br>linear-threshold function</br>s.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and <br>linear-threshold function</br>s can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and <br>linear-threshold function</br>s.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and <br>linear-threshold function</br>s.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and <br>linear-threshold function</br>s can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively."
            ],
            "translated_annotated_samples": [
                "Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y <br>funciones de umbral lineal</br>.",
                "Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y <br>funciones de umbral lineales</br>.",
                "Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y <br>funciones de umbral lineal</br> pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y <br>funciones de umbral lineal</br>. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y <br>funciones de umbral lineales</br>. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y <br>funciones de umbral lineal</br> pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede aprender tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "candidates": [],
            "error": [
                [
                    "funciones de umbral lineal",
                    "funciones de umbral lineales",
                    "funciones de umbral lineal"
                ]
            ]
        },
        "xor bid": {
            "translated_key": "oferta XOR",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an <br>xor bid</br> is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An <br>xor bid</br> containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target <br>xor bid</br> in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an <br>xor bid</br> containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target <br>xor bid</br>.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an <br>xor bid</br>, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Recall that an <br>xor bid</br> is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "An <br>xor bid</br> containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "The algorithm will identify each atomic bid in the target <br>xor bid</br> in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an <br>xor bid</br> containing 0 atomic bids).",
                "We claim that (T, v(T)) is an atomic bid of the target <br>xor bid</br>."
            ],
            "translated_annotated_samples": [
                "Recuerde que una <br>oferta XOR</br> se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B).",
                "Una <br>oferta XOR</br> que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía.",
                "El algoritmo identificará cada oferta atómica en la <br>oferta XOR</br> objetivo, una por una.",
                "Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una <br>oferta XOR</br> que contiene 0 ofertas atómicas).",
                "Sostenemos que (T, v(T)) es una oferta atómica de la <br>oferta XOR</br> objetivo."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos aprender valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo aprende las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una <br>oferta XOR</br> se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una <br>oferta XOR</br> que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la <br>oferta XOR</br> objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una <br>oferta XOR</br> que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la <br>oferta XOR</br> objetivo. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "preference elicitation": {
            "translated_key": "obtención de preferencias",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to <br>preference elicitation</br> Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the <br>preference elicitation</br> problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for <br>preference elicitation</br> algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the <br>preference elicitation</br> problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to learn a function via various types of queries, such as What is the functions value on these inputs?",
                "In <br>preference elicitation</br>, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and <br>preference elicitation</br> differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a <br>preference elicitation</br> algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "<br>preference elicitation</br> schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of <br>preference elicitation</br> regardless of incentive constraints, and on the relationship between the complexities of learning and <br>preference elicitation</br>.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and <br>preference elicitation</br>.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in <br>preference elicitation</br>.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of <br>preference elicitation</br> is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of <br>preference elicitation</br>.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 <br>preference elicitation</br> In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the <br>preference elicitation</br> problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in <br>preference elicitation</br> are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient <br>preference elicitation</br> algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must learn valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and <br>preference elicitation</br> settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize <br>preference elicitation</br>.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any <br>preference elicitation</br> protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO <br>preference elicitation</br> The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a <br>preference elicitation</br> algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply learn the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the <br>preference elicitation</br> problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the <br>preference elicitation</br> problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into <br>preference elicitation</br> algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can learn such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for <br>preference elicitation</br> algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of <br>preference elicitation</br>.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of <br>preference elicitation</br>.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the <br>preference elicitation</br> problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "<br>preference elicitation</br> and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly <br>preference elicitation</br>.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time <br>preference elicitation</br> with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "Applying Learning Algorithms to <br>preference elicitation</br> Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the <br>preference elicitation</br> problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for <br>preference elicitation</br> algorithms.",
                "There has been recent work exploring the links between the <br>preference elicitation</br> problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In <br>preference elicitation</br>, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and <br>preference elicitation</br> differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other."
            ],
            "translated_annotated_samples": [
                "Aplicando algoritmos de aprendizaje a la <br>obtención de preferencias</br> Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de <br>obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje.",
                "Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de <br>obtención de preferencias</br>.",
                "Ha habido trabajos recientes explorando los vínculos entre el problema de la <br>obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19].",
                "En la <br>obtención de preferencias</br>, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima.",
                "Aunque los objetivos del aprendizaje y la <br>obtención de preferencias</br> difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la <br>obtención de preferencias</br> Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de <br>obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de <br>obtención de preferencias</br>. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la <br>obtención de preferencias</br> en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es aprender una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la <br>obtención de preferencias</br>, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la <br>obtención de preferencias</br> difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "learn": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Applying Learning Algorithms to Preference Elicitation Sebastien M. Lahaie Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes Division of Engineering and Applied Sciences Harvard University Cambridge, MA 02138 parkes@eecs.harvard.edu ABSTRACT We consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory.",
                "We show that learning algorithms can be used as a basis for preference elicitation algorithms.",
                "The resulting elicitation algorithms perform a polynomial number of queries.",
                "We also give conditions under which the resulting algorithms have polynomial communication.",
                "Our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "In particular, we obtain an algorithm that elicits XOR bids with polynomial communication.",
                "Categories and Subject Descriptors F.2.0 [Analysis of Algorithms and Problem Complexity]: General; J.4 [Social and Behavioral Sciences]: Economics; I.2.6 [Artificial Intelligence]: Learning General Terms Algorithms, Economics, Theory 1.",
                "INTRODUCTION In a combinatorial auction, agents may bid on bundles of goods rather than individual goods alone.",
                "Since there are an exponential number of bundles (in the number of goods), communicating values over these bundles can be problematic.",
                "Communicating valuations in a one-shot fashion can be prohibitively expensive if the number of goods is only moderately large.",
                "Furthermore, it might even be hard for agents to determine their valuations for single bundles [14].",
                "It is in the interest of such agents to have auction protocols which require them to bid on as few bundles as possible.",
                "Even if agents can efficiently compute their valuations, they might still be reluctant to reveal them entirely in the course of an auction, because such information may be valuable to their competitors.",
                "These considerations motivate the need for auction protocols that minimize the communication and information revelation required to determine an optimal allocation of goods.",
                "There has been recent work exploring the links between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from computational learning theory [5, 19].",
                "In learning theory, the goal is to <br>learn</br> a function via various types of queries, such as What is the functions value on these inputs?",
                "In preference elicitation, the goal is to elicit enough partial information about preferences to be able to compute an optimal allocation.",
                "Though the goals of learning and preference elicitation differ somewhat, it is clear that these problems share similar structure, and it should come as no surprise that techniques from one field should be relevant to the other.",
                "We show that any exact learning algorithm with membership and equivalence queries can be converted into a preference elicitation algorithm with value and demand queries.",
                "The resulting elicitation algorithm guarantees elicitation in a polynomial number of value and demand queries.",
                "Here we mean polynomial in the number of goods, agents, and the sizes of the agents valuation functions in a given encoding scheme.",
                "Preference elicitation schemes have not traditionally considered this last parameter.",
                "We argue that complexity guarantees for elicitation schemes should allow dependence on this parameter.",
                "Introducing this parameter also allows us to guarantee polynomial worst-case communication, which usually cannot be achieved in the number of goods and agents alone.",
                "Finally, we use our conversion procedure to generate combinatorial auction protocols from learning algorithms for polynomials, monotone DNF, and linear-threshold functions.",
                "Of course, a one-shot combinatorial auction where agents provide their entire valuation functions at once would also have polynomial communication in the size of the agents valuations, and only require one query.",
                "The advantage of our scheme is that agents can be viewed as black-boxes that provide incremental information about their valuations.",
                "There is no burden on the agents to formulate their valuations in an encoding scheme of the auctioneers choosing.",
                "We expect this to be an important consideration in practice.",
                "Also, with our scheme entire revelation only happens in the worst-case. 180 For now, we leave the issue of incentives aside when deriving elicitation algorithms.",
                "Our focus is on the time and communication complexity of preference elicitation regardless of incentive constraints, and on the relationship between the complexities of learning and preference elicitation.",
                "Related work.",
                "Zinkevich et al. [19] consider the problem of learning restricted classes of valuation functions which can be represented using read-once formulas and Toolbox DNF.",
                "Read-once formulas can represent certain substitutabilities, but no complementarities, whereas the opposite holds for Toolbox DNF.",
                "Since their work is also grounded in learning theory, they allow dependence on the size of the target valuation as we do (though read-once valuations can always be succinctly represented anyway).",
                "Their work only makes use of value queries, which are quite limited in power.",
                "Because we allow ourselves demand queries, we are able to derive an elicitation scheme for general valuation functions.",
                "Blum et al. [5] provide results relating the complexities of query learning and preference elicitation.",
                "They consider models with membership and equivalence queries in query learning, and value and demand queries in preference elicitation.",
                "They show that certain classes of functions can be efficiently learned yet not efficiently elicited, and vice-versa.",
                "In contrast, our work shows that given a more general (yet still quite standard) version of demand query than the type they consider, the complexity of preference elicitation is no greater than the complexity of learning.",
                "We will show that demand queries can simulate equivalence queries until we have enough information about valuations to imply a solution to the elicitation problem.",
                "Nisan and Segal [12] study the communication complexity of preference elicitation.",
                "They show that for many rich classes of valuations, the worst-case communication complexity of computing an optimal allocation is exponential.",
                "Their results apply to the black-box model of computational complexity.",
                "In this model algorithms are allowed to ask questions about agent valuations and receive honest responses, without any insight into how the agents internally compute their valuations.",
                "This is in fact the basic framework of learning theory.",
                "Our work also addresses the issue of communication complexity, and we are able to derive algorithms that provide significant communication guarantees despite Nisan and Segals negative results.",
                "Their work motivates the need to rely on the sizes of agents valuation functions in stating worst-case results. 2.",
                "THE MODELS 2.1 Query Learning The query learning model we consider here is called exact learning from membership and equivalence queries, introduced by Angluin [2].",
                "In this model the learning algorithms objective is to exactly identify an unknown target function f : X → Y via queries to an oracle.",
                "The target function is drawn from a function class C that is known to the algorithm.",
                "Typically the domain X is some subset of {0, 1}m , and the range Y is either {0, 1} or some subset of the real numbers Ê.",
                "As the algorithm progresses, it constructs a manifest hypothesis ˜f which is its current estimate of the target function.",
                "Upon termination, the manifest hypothesis of a correct learning algorithm satisfies ˜f(x) = f(x) for all x ∈ X.",
                "It is important to specify the representation that will be used to encode functions from C. For example, consider the following function from {0, 1}m to Ê: f(x) = 2 if x consists of m 1s, and f(x) = 0 otherwise.",
                "This function may simply be represented as a list of 2m values.",
                "Or it may be encoded as the polynomial 2x1 · · · xm, which is much more succinct.",
                "The choice of encoding may thus have a significant impact on the time and space requirements of the learning algorithm.",
                "Let size(f) be the size of the encoding of f with respect to the given representation class.",
                "Most representation classes have a natural measure of encoding size.",
                "The size of a polynomial can be defined as the number of non-zero coefficients in the polynomial, for example.",
                "We will usually only refer to representation classes; the corresponding function classes will be implied.",
                "For example, the representation class of monotone DNF formulae implies the function class of monotone Boolean functions.",
                "Two types of queries are commonly used for exact learning: membership and equivalence queries.",
                "On a membership query, the learner presents some x ∈ X and the oracle replies with f(x).",
                "On an equivalence query, the learner presents its manifest hypothesis ˜f.",
                "The oracle either replies YES if ˜f = f, or returns a counterexample x such that ˜f(x) = f(x).",
                "An equivalence query is proper if size( ˜f) ≤ size(f) at the time the manifest hypothesis is presented.",
                "We are interested in efficient learning algorithms.",
                "The following definitions are adapted from Kearns and Vazirani [9]: Definition 1.",
                "The representation class C is polynomialquery exactly learnable from membership and equivalence queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to membership and equivalence queries of an oracle such that for any target function f ∈ C, L outputs after at most p(size(f), m) queries a function ˜f ∈ C such that ˜f(x) = f(x) for all instances x.",
                "Similarly, the representation class C is efficiently exactly learnable from membership and equivalence queries if the algorithm L outputs a correct hypothesis in time p(size(f), m), for some fixed polynomial p(·, ·).",
                "Here m is the dimension of the domain.",
                "Since the target function must be reconstructed, we also necessarily allow polynomial dependence on size(f). 2.2 Preference Elicitation In a combinatorial auction, a set of goods M is to be allocated among a set of agents N so as to maximize the sum of the agents valuations.",
                "Such an allocation is called efficient in the economics literature, but we will refer to it as optimal and reserve the term efficient to refer to computational efficiency.",
                "We let n = |N| and m = |M|.",
                "An allocation is a partition of the objects into bundles (S1, . . . , Sn), such that Si ∩ Sj = ∅ for all distinct i, j ∈ N. Let Γ be the set of possible allocations.",
                "Each agent i ∈ N has a valuation function vi : 2M → Ê over the space of possible bundles.",
                "Each valuation vi is drawn from a known class of valuations Vi.",
                "The valuation classes do not need to coincide.",
                "We will assume that all the valuations considered are normalized, meaning v(∅) = 0, and that there are no externalities, meaning vi(S1, ..., Sn) = vi(Si), for all agents i ∈ N, for any allocation (S1, ..., Sn) ∈ Γ (that is, an agent cares only about the bundle allocated to her).",
                "Valuations satisfying these conditions are called general valuations.1 We 1 Often general valuations are made to satisfy the additional 181 also assume that agents have quasi-linear utility functions, meaning that agents utilities can be divided into monetary and non-monetary components.",
                "If an agent i is allocated bundle S at price p, it derives utility ui(S, p) = vi(S) − p. A valuation function may be viewed as a vector of 2m − 1 non-negative real-values.",
                "Of course there may also be more succinct representations for certain valuation classes, and there has been much research into concise bidding languages for various types of valuations [11].",
                "A classic example which we will refer to again later is the XOR bidding language.",
                "In this language, the agent provides a list of atomic bids, which consist of a bundle together with its value.",
                "To determine the value of a bundle S given these bids, one searches for the bundle S of highest value listed in the atomic bids such that S ⊆ S. It is then the case that v(S) = v(S ).",
                "As in the learning theory setting, we will usually only refer to bidding languages rather than valuation classes, because the corresponding valuation classes will then be implied.",
                "For example, the XOR bidding language implies the class of valuations satisfying free-disposal, which is the condition that A ⊆ B ⇒ v(A) ≤ v(B).",
                "We let size(v1, . . . , vn) = Èn i=1 size(vi).",
                "That is, the size of a vector of valuations is the size of the concatenation of the valuations representations in their respective encoding schemes (bidding languages).",
                "To make an analogy to computational learning theory, we assume that all representation classes considered are polynomially interpretable [11], meaning that the value of a bundle may be computed in polynomial time given the valuation functions representation.",
                "More formally, a representation class (bidding language) C is polynomially interpretable if there exists an algorithm that given as input some v ∈ C and an instance x ∈ X computes the value v(x) in time q(size(v), m), for some fixed polynomial q(·, ·).2 In the intermediate rounds of an (iterative) auction, the auctioneer will have elicited information about the agents valuation functions via various types of queries.",
                "She will thus have constructed a set of manifest valuations, denoted ˜v1, . . . , ˜vn.3 The values of these functions may correspond exactly to the true agent values, or they may for example be upper or lower bounds on the true values, depending on the types of queries made.",
                "They may also simply be default or random values if no information has been acquired about certain bundles.",
                "The goal in the preference elicitation problem is to construct a set of manifest valuations such that: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) That is, the manifest valuations provide enough information to compute an allocation that is optimal with respect to the true valuations.",
                "Note that we only require one such optimal allocation. condition of free-disposal (monotonicity), but we do not need it at this point. 2 This excludes OR∗ , assuming P = NP, because interpreting bids from this language is NP-hard by reduction from weighted set-packing, and there is no well-studied representation class in learning theory that is clearly analogous to OR∗ . 3 This view of iterative auctions is meant to parallel the learning setting.",
                "In many combinatorial auctions, manifest valuations are not explicitly maintained but rather simply implied by the history of bids.",
                "Two typical queries used in preference elicitation are value and demand queries.",
                "On a value query, the auctioneer presents a bundle S ⊆ M and the agent responds with her (exact) value for the bundle v(S) [8].",
                "On a demand query, the auctioneer presents a vector of non-negative prices p ∈ Ê(2m ) over the bundles together with a bundle S. The agent responds YES if it is the case that S ∈ arg max S ⊆M   v(S ) − p(S ) ¡ or otherwise presents a bundle S such that v(S ) − p(S ) > v(S) − p(S) That is, the agent either confirms that the presented bundle is most preferred at the quoted prices, or indicates a better one [15].4 Note that we include ∅ as a bundle, so the agent will only respond YES if its utility for the proposed bundle is non-negative.",
                "Note also that communicating nonlinear prices does not necessarily entail quoting a price for every possible bundle.",
                "There may be more succinct ways of communicating this vector, as we show in section 5.",
                "We make the following definitions to parallel the query learning setting and to simplify the statements of later results: Definition 2.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if there is a fixed polynomial p(·, ·) and an algorithm L with access to value and demand queries of the agents such that for any (v1, . . . , vn) ∈ V1 × . . . × Vn, L outputs after at most p(size(v1, . . . , vn), m) queries an allocation (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si).",
                "Similarly, the representation class C can be efficiently elicited from value and demand queries if the algorithm L outputs an optimal allocation with communication p(size(v1, . . . , vn), m), for some fixed polynomial p(·, ·).",
                "There are some key differences here with the query learning definition.",
                "We have dropped the term exactly since the valuation functions need not be determined exactly in order to compute an optimal allocation.",
                "Also, an efficient elicitation algorithm is polynomial communication, rather than polynomial time.",
                "This reflects the fact that communication rather than runtime is the bottleneck in elicitation.",
                "Computing an optimal allocation of goods even when given the true valuations is NP-hard for a wide range of valuation classes.",
                "It is thus unreasonable to require polynomial time in the definition of an efficient preference elicitation algorithm.",
                "We are happy to focus on the communication complexity of elicitation because this problem is widely believed to be more significant in practice than that of winner determination [11].5 4 This differs slightly from the definition provided by Blum et al. [5] Their demand queries are restricted to linear prices over the goods, where the price of a bundle is the sum of the prices of its underlying goods.",
                "In contrast our demand queries allow for nonlinear prices, i.e. a distinct price for every possible bundle.",
                "This is why the lower bound in their Theorem 2 does not contradict our result that follows. 5 Though the winner determination problem is NP-hard for general valuations, there exist many algorithms that solve it efficiently in practice.",
                "These range from special purpose algorithms [7, 16] to approaches using off-the-shelf IP solvers [1]. 182 Since the valuations need not be elicited exactly it is initially less clear whether the polynomial dependence on size(v1, . . . , vn) is justified in this setting.",
                "Intuitively, this parameter is justified because we must <br>learn</br> valuations exactly when performing elicitation, in the worst-case.",
                "We address this in the next section. 3.",
                "PARALLELSBETWEEN EQUIVALENCE AND DEMAND QUERIES We have described the query learning and preference elicitation settings in a manner that highlights their similarities.",
                "Value and membership queries are clear analogs.",
                "Slightly less obvious is the fact that equivalence and demand queries are also analogs.",
                "To see this, we need the concept of Lindahl prices.",
                "Lindahl prices are nonlinear and non-anonymous prices over the bundles.",
                "They are nonlinear in the sense that each bundle is assigned a price, and this price is not necessarily the sum of prices over its underlying goods.",
                "They are non-anonymous in the sense that two agents may face different prices for the same bundle of goods.",
                "Thus Lindahl prices are of the form pi(S), for all S ⊆ M, for all i ∈ N. Lindahl prices are presented to the agents in demand queries.",
                "When agents have normalized quasi-linear utility functions, Bikhchandani and Ostroy [4] show that there always exist Lindahl prices such that (S1, . . . , Sn) is an optimal allocation if and only if Si ∈ arg max Si   vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) Condition (1) states that each agent is allocated a bundle that maximizes its utility at the given prices.",
                "Condition (2) states that the allocation maximizes the auctioneers revenue at the given prices.",
                "The scenario in which these conditions hold is called a Lindahl equilibrium, or often a competitive equilibrium.",
                "We say that the Lindahl prices support the optimal allocation.",
                "It is therefore sufficient to announce supporting Lindahl prices to verify an optimal allocation.",
                "Once we have found an allocation with supporting Lindahl prices, the elicitation problem is solved.",
                "The problem of finding an optimal allocation (with respect to the manifest valuations) can be formulated as a linear program whose solutions are guaranteed to be integral [4].",
                "The dual variables to this linear program are supporting Lindahl prices for the resulting allocation.",
                "The objective function to the dual program is: min pi(S) πs + i∈N πi (3) with πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) The optimal values of πi and πs correspond to the maximal utility to agent i with respect to its manifest valuation and the maximal revenue to the seller.",
                "There is usually a range of possible Lindahl prices supporting a given optimal allocation.",
                "The agents manifest valuations are in fact valid Lindahl prices, and we refer to them as maximal Lindahl prices.",
                "Out of all possible vectors of Lindahl prices, maximal Lindahl prices maximize the utility of the auctioneer, in fact giving her the entire social welfare.",
                "Conversely, prices that maximize the È i∈N πi component of the objective (the sum of the agents utilities) are minimal Lindahl prices.",
                "Any Lindahl prices will do for our results, but some may have better elicitation properties than others.",
                "Note that a demand query with maximal Lindahl prices is almost identical to an equivalence query, since in both cases we communicate the manifest valuation to the agent.",
                "We leave for future work the question of which Lindahl prices to choose to minimize preference elicitation.",
                "Considering now why demand and equivalence queries are direct analogs, first note that given the πi in some Lindahl equilibrium, setting pi(S) = max{0, ˜vi(S) − πi} (4) for all i ∈ N and S ⊆ M yields valid Lindahl prices.",
                "These prices leave every agent indifferent across all bundles with positive price, and satisfy condition (1).",
                "Thus demand queries can also implicitly communicate manifest valuations, since Lindahl prices will typically be an additive constant away from these by equality (4).",
                "In the following lemma we show how to obtain counterexamples to equivalence queries through demand queries.",
                "Lemma 1.",
                "Suppose an agent replies with a preferred bundle S when proposed a bundle S and supporting Lindahl prices p(S) (supporting with respect to the the agents manifest valuation).",
                "Then either ˜v(S) = v(S) or ˜v(S ) = v(S ).",
                "Proof.",
                "We have the following inequalities: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) Inequality (5) holds because the prices support the proposed allocation with respect to the manifest valuation.",
                "Inequality (6) holds because the agent in fact prefers S to S given the prices, according to its response to the demand query.",
                "If it were the case that ˜v(S) = v(S) and ˜v(S ) = v(S ), these inequalities would represent a contradiction.",
                "Thus at least one of S and S is a counterexample to the agents manifest valuation.",
                "Finally, we justify dependence on size(v1, . . . , vn) in elicitation problems.",
                "Nisan and Segal (Proposition 1, [12]) and Parkes (Theorem 1, [13]) show that supporting Lindahl prices must necessarily be revealed in the course of any preference elicitation protocol which terminates with an optimal allocation.",
                "Furthermore, Nisan and Segal (Lemma 1, [12]) state that in the worst-case agents prices must coincide with their valuations (up to a constant), when the valuation class is rich enough to contain dual valuations (as will be the case with most interesting classes).",
                "Since revealing Lindahl prices is a necessary condition for establishing an optimal allocation, and since Lindahl prices contain the same information as valuation functions (in the worst-case), allowing for dependence on size(v1, . . . , vn) in elicitation problems is entirely natural. 183 4.",
                "FROM LEARNING TO PREFERENCE ELICITATION The key to converting a learning algorithm to an elicitation algorithm is to simulate equivalence queries with demand and value queries until an optimal allocation is found.",
                "Because of our Lindahl price construction, when all agents reply YES to a demand query, we have found an optimal allocation, analogous to the case where an agent replies YES to an equivalence query when the target function has been exactly learned.",
                "Otherwise, we can obtain a counterexample to an equivalence query given an agents response to a demand query.",
                "Theorem 1.",
                "The representation classes V1, . . . , Vn can be polynomial-query elicited from value and demand queries if they can each be polynomial-query exactly learned from membership and equivalence queries.",
                "Proof.",
                "Consider the elicitation algorithm in Figure 1.",
                "Each membership query in step 1 is simulated with a value query since these are in fact identical.",
                "Consider step 4.",
                "If all agents reply YES, condition (1) holds.",
                "Condition (2) holds because the computed allocation is revenue-maximizing for the auctioneer, regardless of the agents true valuations.",
                "Thus an optimal allocation has been found.",
                "Otherwise, at least one of Si or Si is a counterexample to ˜vi, by Lemma 1.",
                "We identify a counterexample by performing value queries on both these bundles, and provide it to Ai as a response to its equivalence query.",
                "This procedure will halt, since in the worst-case all agent valuations will be learned exactly, in which case the optimal allocation and Lindahl prices will be accepted by all agents.",
                "The procedure performs a polynomial number of queries, since A1, . . . , An are all polynomial-query learning algorithms.",
                "Note that the conversion procedure results in a preference elicitation algorithm, not a learning algorithm.",
                "That is, the resulting algorithm does not simply <br>learn</br> the valuations exactly, then compute an optimal allocation.",
                "Rather, it elicits partial information about the valuations through value queries, and periodically tests whether enough information has been gathered by proposing an allocation to the agents through demand queries.",
                "It is possible to generate a Lindahl equilibrium for valuations v1, . . . , vn using an allocation and prices derived using manifest valuations ˜v1, . . . , ˜vn, and finding an optimal allocation does not imply that the agents valuations have been exactly learned.",
                "The use of demand queries to simulate equivalence queries enables this early halting.",
                "We would not obtain this property with equivalence queries based on manifest valuations. 5.",
                "COMMUNICATION COMPLEXITY In this section, we turn to the issue of the communication complexity of elicitation.",
                "Nisan and Segal [12] show that for a variety of rich valuation spaces (such as general and submodular valuations), the worst-case communication burden of determining Lindahl prices is exponential in the number of goods, m. The communication burden is measured in terms of the number of bits transmitted between agents and auctioneer in the case of discrete communication, or in terms of the number of real numbers transmitted in the case of continuous communication.",
                "Converting efficient learning algorithms to an elicitation algorithm produces an algorithm whose queries have sizes polynomial in the parameters m and size(v1, . . . , vn).",
                "Theorem 2.",
                "The representation classes V1, . . . , Vn can be efficiently elicited from value and demand queries if they can each be efficiently exactly learned from membership and equivalence queries.",
                "Proof.",
                "The size of any value query is O(m): the message consists solely of the queried bundle.",
                "To communicate Lindahl prices to agent i, it is sufficient to communicate the agents manifest valuation function and the value πi, by equality (4).",
                "Note that an efficient learning algorithm never builds up a manifest hypothesis of superpolynomial size, because the algorithms runtime would then also be superpolynomial, contradicting efficiency.",
                "Thus communicating the manifest valuation requires size at most p(size(vi), m), for some polynomial p that upper-bounds the runtime of the efficient learning algorithm.",
                "Representing the surplus πi to agent i cannot require space greater than q(size(˜vi), m) for some fixed polynomial q, because we assume that the chosen representation is polynomially interpretable, and thus any value generated will be of polynomial size.",
                "We must also communicate to i its allocated bundle, so the total message size for a demand query is at most p(size(vi), m) + q(p(size(vi), m), m)+O(m).",
                "Clearly, an agents response to a value or demand query has size at most q(size(vi), m) + O(m).",
                "Thus the value and demand queries, and the responses to these queries, are always of polynomial size.",
                "An efficient learning algorithm performs a polynomial number of queries, so the total communication of the resulting elicitation algorithm is polynomial in the relevant parameters.",
                "There will often be explicit bounds on the number of membership and equivalence queries performed by a learning algorithm, with constants that are not masked by big-O notation.",
                "These bounds can be translated to explicit bounds on the number of value and demand queries made by the resulting elicitation algorithm.",
                "We upper-bounded the size of the manifest hypothesis with the runtime of the learning algorithm in Theorem 2.",
                "We are likely to be able to do much better than this in practice.",
                "Recall that an equivalence query is proper if size( ˜f) ≤ size(f) at the time the query is made.",
                "If the learning algorithms equivalence queries are all proper, it may then also be possible to provide tight bounds on the communication requirements of the resulting elicitation algorithm.",
                "Theorem 2 show that elicitation algorithms that depend on the size(v1, . . . , vn) parameter sidestep Nisan and Segals [12] negative results on the worst-case communication complexity of efficient allocation problems.",
                "They provide guarantees with respect to the sizes of the instances of valuation functions faced at any run of the algorithm.",
                "These algorithms will fare well if the chosen representation class provides succinct representations for the simplest and most common of valuations, and thus the focus moves back to one of compact yet expressive bidding languages.",
                "We consider these issues below. 6.",
                "APPLICATIONS In this section, we demonstrate the application of our methods to particular representation classes for combinatorial valuations.",
                "We have shown that the preference elicitation problem for valuation classes V1, . . . , Vn can be reduced 184 Given: exact learning algorithms A1, . . . , An for valuations classes V1, . . . , Vn respectively.",
                "Loop until there is a signal to halt: 1.",
                "Run A1, . . . , An in parallel on their respective agents until each requires a response to an equivalence query, or has halted with the agents exact valuation. 2.",
                "Compute an optimal allocation (S1, . . . , Sn) and corresponding Lindahl prices with respect to the manifest valuations ˜v1, . . . , ˜vn determined so far. 3.",
                "Present the allocation and prices to the agents in the form of a demand query. 4.",
                "If they all reply YES, output the allocation and halt.",
                "Otherwise there is some agent i that has replied with some preferred bundle Si.",
                "Perform value queries on Si and Si to find a counterexample to ˜vi, and provide it to Ai.",
                "Figure 1: Converting learning algorithms to an elicitation algorithm. to the problem of finding an efficient learning algorithm for each of these classes separately.",
                "This is significant because there already exist learning algorithms for a wealth of function classes, and because it may often be simpler to solve each learning subproblem separately than to attack the preference elicitation problem directly.",
                "We can develop an elicitation algorithm that is tailored to each agents valuation, with the underlying learning algorithms linked together at the demand query stages in an algorithm-independent way.",
                "We show that existing learning algorithms for polynomials, monotone DNF formulae, and linear-threshold functions can be converted into preference elicitation algorithms for general valuations, valuations with free-disposal, and valuations with substitutabilities, respectively.",
                "We focus on representations that are polynomially interpretable, because the computational learning theory literature places a heavy emphasis on computational tractability [18].",
                "In interpreting the methods we emphasize the expressiveness and succinctness of each representation class.",
                "The representation class, which in combinatorial auction terms defines a bidding language, must necessarily be expressive enough to represent all possible valuations of interest, and should also succinctly represent the simplest and most common functions in the class. 6.1 Polynomial Representations Schapire and Sellie [17] give a learning algorithm for sparse multivariate polynomials that can be used as the basis for a combinatorial auction protocol.",
                "The equivalence queries made by this algorithm are all proper.",
                "Specifically, their algorithm learns the representation class of t-sparse multivariate polynomials over the real numbers, where the variables may take on values either 0 or 1.",
                "A t-sparse polynomial has at most t terms, where a term is a product of variables, e.g. x1x3x4.",
                "A polynomial over the real numbers has coefficients drawn from the real numbers.",
                "Polynomials are expressive: every valuation function v : 2M → Ê+ can be uniquely written as a polynomial [17].",
                "To get an idea of the succinctness of polynomials as a bidding language, consider the additive and single-item valuations presented by Nisan [11].",
                "In the additive valuation, the value of a bundle is the number of goods the bundle contains.",
                "In the single-item valuation, all bundles have value 1, except ∅ which has value 0 (i.e. the agent is satisfied as soon as it has acquired a single item).",
                "It is not hard to show that the single-item valuation requires polynomials of size 2m − 1, while polynomials of size m suffice for the additive valuation.",
                "Polynomials are thus appropriate for valuations that are mostly additive, with a few substitutabilities and complementarities that can be introduced by adjusting coefficients.",
                "The learning algorithm for polynomials makes at most mti +2 equivalence queries and at most (mti +1)(t2 i +3ti)/2 membership queries to an agent i, where ti is the sparcity of the polynomial representing vi [17].",
                "We therefore obtain an algorithm that elicits general valuations with a polynomial number of queries and polynomial communication.6 6.2 XOR Representations The XOR bidding language is standard in the combinatorial auctions literature.",
                "Recall that an XOR bid is characterized by a set of bundles B ⊆ 2M and a value function w : B → Ê+ defined on those bundles, which induces the valuation function: v(B) = max {B ∈B | B ⊆B} w(B ) (7) XOR bids can represent valuations that satisfy free-disposal (and only such valuations), which again is the property that A ⊆ B ⇒ v(A) ≤ v(B).",
                "The XOR bidding language is slightly less expressive than polynomials, because polynomials can represent valuations that do not satisfy free-disposal.",
                "However, XOR is as expressive as required in most economic settings.",
                "Nisan [11] notes that XOR bids can represent the single-item valuation with m atomic bids, but 2m − 1 atomic bids are needed to represent the additive valuation.",
                "Since the opposite holds for polynomials, these two languages are incomparable in succinctness, and somewhat complementary for practical use.",
                "Blum et al. [5] note that monotone DNF formulae are the analogs of XOR bids in the learning theory literature.",
                "A monotone DNF formula is a disjunction of conjunctions in which the variables appear unnegated, for example x1x2 ∨ x3 ∨ x2x4x5.",
                "Note that such formulae can be represented as XOR bids where each atomic bid has value 1; thus XOR bids generalize monotone DNF formulae from Boolean to real-valued functions.",
                "These insights allow us to generalize a classic learning algorithm for monotone DNF ([3] Theorem 6 Note that Theorem 1 applies even if valuations do not satisfy free-disposal. 185 1, [18] Theorem B) to a learning algorithm for XOR bids.7 Lemma 2.",
                "An XOR bid containing t atomic bids can be exactly learned with t + 1 equivalence queries and at most tm membership queries.",
                "Proof.",
                "The algorithm will identify each atomic bid in the target XOR bid in turn.",
                "Initialize the manifest valuation ˜v to the bid that is identically zero on all bundles (this is an XOR bid containing 0 atomic bids).",
                "Present ˜v as an equivalence query.",
                "If the response is YES, we are done.",
                "Otherwise we obtain a bundle S for which v(S) = ˜v(S).",
                "Create a bundle T as follows.",
                "First initialize T = S. For each item i in T, check via a membership query whether v(T) = v(T − {i}).",
                "If so set T = T − {i}.",
                "Otherwise leave T as is and proceed to the next item.",
                "We claim that (T, v(T)) is an atomic bid of the target XOR bid.",
                "For each item i in T, we have v(T) = v(T − {i}).",
                "To see this, note that at some point when generating T, we had a ¯T such that T ⊆ ¯T ⊆ S and v( ¯T) > v( ¯T − {i}), so that i was kept in ¯T.",
                "Note that v(S) = v( ¯T) = v(T) because the value of the bundle S is maintained throughout the process of deleting items.",
                "Now assume v(T) = v(T − {i}).",
                "Then v( ¯T) = v(T) = v(T − {i}) > v( ¯T − {i}) which contradicts free-disposal, since T − {i} ⊆ ¯T − {i}.",
                "Thus v(T) > v(T − {i}) for all items i in T. This implies that (T, v(T)) is an atomic bid of v. If this were not the case, T would take on the maximum value of its strict subsets, by the definition of an XOR bid, and we would have v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T) which is a contradiction.",
                "We now show that v(T) = ˜v(T), which will imply that (T, v(T)) is not an atomic bid of our manifest hypothesis by induction.",
                "Assume that every atomic bid (R, ˜v(R)) identified so far is indeed an atomic bid of v (meaning R is indeed listed in an atomic bid of v as having value v(R) = ˜v(R)).",
                "This assumption holds vacuously when the manifest valuation is initialized.",
                "Using the notation from (7), let ( ˜B, ˜w) be our hypothesis, and (B, w) be the target function.",
                "We have ˜B ⊆ B, and ˜w(B) = w(B) for B ∈ ˜B by assumption.",
                "Thus, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Now assume v(T) = ˜v(T).",
                "Then, ˜v(T) = v(T) = v(S) = ˜v(S) (9) The second equality follows from the fact that the value remains constant when we derive T from S. The last inequality holds because S is a counterexample to the manifest valuation.",
                "From equation (9) and free-disposal, we 7 The cited algorithm was also used as the basis for Zinkevich et al.s [19] elicitation algorithm for Toolbox DNF.",
                "Recall that Toolbox DNF are polynomials with non-negative coefficients.",
                "For these representations, an equivalence query can be simulated with a value query on the bundle containing all goods. have ˜v(T) < ˜v(S).",
                "Then again from equation (9) it follows that v(S) < ˜v(S).",
                "This contradicts (8), so we in fact have v(T) = ˜v(T).",
                "Thus (T, v(T)) is not currently in our hypothesis as an atomic bid, or we would correctly have ˜v(T) = v(T) by the induction hypothesis.",
                "We add (T, v(T)) to our hypothesis and repeat the process above, performing additional equivalence queries until all atomic bids have been identified.",
                "After each equivalence query, an atomic bid is identified with at most m membership queries.",
                "Each counterexample leads to the discovery of a new atomic bid.",
                "Thus we make at most tm membership queries and exactly t + 1 equivalence queries.",
                "The number of time steps required by this algorithm is essentially the same as the number of queries performed, so the algorithm is efficient.",
                "Applying Theorem 2, we therefore obtain the following corollary: Theorem 3.",
                "The representation class of XOR bids can be efficiently elicited from value and demand queries.",
                "This contrasts with Blum et al.s negative results ([5], Theorem 2) stating that monotone DNF (and hence XOR bids) cannot be efficiently elicited when the demand queries are restricted to linear and anonymous prices over the goods. 6.3 Linear-Threshold Representations Polynomials, XOR bids, and all languages based on the OR bidding language (such as XOR-of-OR, OR-of-XOR, and OR∗ ) fail to succinctly represent the majority valuation [11].",
                "In this valuation, bundles have value 1 if they contain at least m/2 items, and value 0 otherwise.",
                "More generally, consider the r-of-S family of valuations where bundles have value 1 if they contain at least r items from a specified set of items S ⊆ M, and value 0 otherwise.",
                "The majority valuation is a special case of the r-of-S valuation with r = m/2 and S = M. These valuations are appropriate for representing substitutabilities: once a required set of items has been obtained, no other items can add value.",
                "Letting k = |S|, such valuations are succinctly represented by r-of-k threshold functions.",
                "These functions take the form of linear inequalities: xi1 + . . . + xik ≥ r where the function has value 1 if the inequality holds, and 0 otherwise.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can <br>learn</br> such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10].",
                "To provide this guarantee, r must be known to the algorithm, but S (and k) are unknown.",
                "The elicitation algorithm that results from WINNOW 2 uses demand queries only (value queries are not necessary here because the values of counterexamples are implied when there are only two possible values).",
                "Note that r-of-k threshold functions can always be succinctly represented in O(m) space.",
                "Thus we obtain an algorithm that can elicit such functions with a polynomial number of queries and polynomial communication, in the parameters n and m alone. 186 7.",
                "CONCLUSIONS AND FUTURE WORK We have shown that exact learning algorithms with membership and equivalence queries can be used as a basis for preference elicitation algorithms with value and demand queries.",
                "At the heart of this result is the fact that demand queries may be viewed as modified equivalence queries, specialized to the problem of preference elicitation.",
                "Our result allows us to apply the wealth of available learning algorithms to the problem of preference elicitation.",
                "A learning approach to elicitation also motivates a different approach to designing elicitation algorithms that decomposes neatly across agent types.",
                "If the designer knowns beforehand what types of preferences each agent is likely to exhibit (mostly additive, many substitutes, etc...), she can design learning algorithms tailored to each agents valuations and integrate them into an elicitation scheme.",
                "The resulting elicitation algorithm makes a polynomial number of queries, and makes polynomial communication if the original learning algorithms are efficient.",
                "We do not require that agent valuations can be learned with value and demand queries.",
                "Equivalence queries can only be, and need only be, simulated up to the point where an optimal allocation has been computed.",
                "This is the preference elicitation problem.",
                "Theorem 1 implies that elicitation with value and demand queries is no harder than learning with membership and equivalence queries, but it does not provide any asymptotic improvements over the learning algorithms complexity.",
                "It would be interesting to find examples of valuation classes for which elicitation is easier than learning.",
                "Blum et al. [5] provide such an example when considering membership/value queries only (Theorem 4).",
                "In future work we plan to address the issue of incentives when converting learning algorithms to elicitation algorithms.",
                "In the learning setting, we usually assume that oracles will provide honest responses to queries; in the elicitation setting, agents are usually selfish and will provide possibly dishonest responses so as to maximize their utility.",
                "We also plan to implement the algorithms for learning polynomials and XOR bids as elicitation algorithms, and test their performance against other established combinatorial auction protocols [6, 15].",
                "An interesting question here is: which Lindahl prices in the maximal to minimal range are best to quote in order to minimize information revelation?",
                "We conjecture that information revelation is reduced when moving from maximal to minimal Lindahl prices, namely as we move demand queries further away from equivalence queries.",
                "Finally, it would be useful to determine whether the OR∗ bidding language [11] can be efficiently learned (and hence elicited), given this languages expressiveness and succinctness for a wide variety of valuation classes.",
                "Acknowledgements We would like to thank Debasis Mishra for helpful discussions.",
                "This work is supported in part by NSF grant IIS0238147. 8.",
                "REFERENCES [1] A. Andersson, M. Tenhunen, and F. Ygge.",
                "Integer programming for combinatorial auction winner determination.",
                "In Proceedings of the Fourth International Conference on Multiagent Systems (ICMAS-00), 2000. [2] D. Angluin.",
                "Learning regular sets from queries and counterexamples.",
                "Information and Computation, 75:87-106, November 1987. [3] D. Angluin.",
                "Queries and concept learning.",
                "Machine Learning, 2:319-342, 1987. [4] S. Bikhchandani and J. Ostroy.",
                "The Package Assignment Model.",
                "Journal of Economic Theory, 107(2), December 2002. [5] A. Blum, J. Jackson, T. Sandholm, and M. Zinkevich.",
                "Preference elicitation and query learning.",
                "In Proc. 16th Annual Conference on Computational Learning Theory (COLT), Washington DC, 2003. [6] W. Conen and T. Sandholm.",
                "Partial-revelation VCG mechanism for combinatorial auctions.",
                "In Proc. the 18th National Conference on Artificial Intelligence (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown, and Y. Shoham.",
                "Taming the computational complexity of combinatorial auctions: Optimal and approximate approaches.",
                "In Proc. the 16th International Joint Conference on Artificial Intelligence (IJCAI), pages 548-553, 1999. [8] B. Hudson and T. Sandholm.",
                "Using value queries in combinatorial auctions.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. [9] M. J. Kearns and U. V. Vazirani.",
                "An Introduction to Computational Learning Theory.",
                "MIT Press, 1994. [10] N. Littlestone.",
                "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm.",
                "Machine Learning, 2:285-318, 1988. [11] N. Nisan.",
                "Bidding and allocation in combinatorial auctions.",
                "In Proc. the ACM Conference on Electronic Commerce, pages 1-12, 2000. [12] N. Nisan and I. Segal.",
                "The communication requirements of efficient allocations and supporting Lindahl prices.",
                "Working Paper, Hebrew University, 2003. [13] D. C. Parkes.",
                "Price-based information certificates for minimal-revelation combinatorial auctions.",
                "In Padget et al., editor, Agent-Mediated Electronic Commerce IV,LNAI 2531, pages 103-122.",
                "Springer-Verlag, 2002. [14] D. C. Parkes.",
                "Auction design with costly preference elicitation.",
                "In Special Issues of Annals of Mathematics and AI on the Foundations of Electronic Commerce, Forthcoming (2003). [15] D. C. Parkes and L. H. Ungar.",
                "Iterative combinatorial auctions: Theory and practice.",
                "In Proc. 17th National Conference on Artificial Intelligence (AAAI-00), pages 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin, and D. Levine.",
                "CABOB: A fast optimal algorithm for combinatorial auctions.",
                "In Proc. the 17th International Joint Conference on Artificial Intelligence (IJCAI), pages 1102-1108, 2001. [17] R. Schapire and L. Sellie.",
                "Learning sparse multivariate polynomials over a field with queries and counterexamples.",
                "In Proceedings of the Sixth Annual ACM Workshop on Computational Learning Theory, pages 17-26.",
                "ACM Press, 1993. 187 [18] L. Valiant.",
                "A theory of the learnable.",
                "Commun.",
                "ACM, 27(11):1134-1142, Nov. 1984. [19] M. Zinkevich, A. Blum, and T. Sandholm.",
                "On polynomial-time preference elicitation with value-queries.",
                "In Proc. 4th ACM Conference on Electronic Commerce (ACM-EC), San Diego, CA, June 2003. 188"
            ],
            "original_annotated_samples": [
                "In learning theory, the goal is to <br>learn</br> a function via various types of queries, such as What is the functions value on these inputs?",
                "Intuitively, this parameter is justified because we must <br>learn</br> valuations exactly when performing elicitation, in the worst-case.",
                "That is, the resulting algorithm does not simply <br>learn</br> the valuations exactly, then compute an optimal allocation.",
                "Here i1, . . . , ik are the items in S. Littlestones WINNOW 2 algorithm can <br>learn</br> such functions using equivalence queries only, using at most 8r2 + 5k + 14kr ln m + 1 queries [10]."
            ],
            "translated_annotated_samples": [
                "En la teoría del aprendizaje, el objetivo es <br>aprender</br> una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas?",
                "De manera intuitiva, este parámetro está justificado porque debemos <br>aprender</br> valoraciones exactamente al realizar la solicitud, en el peor de los casos.",
                "Es decir, el algoritmo resultante no solo <br>aprende</br> las valoraciones exactamente, luego calcula una asignación óptima.",
                "Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede <br>aprender</br> tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]."
            ],
            "translated_text": "Aplicando algoritmos de aprendizaje a la obtención de preferencias Sebastien M. Lahaie División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 slahaie@eecs.harvard.edu David C. Parkes División de Ingeniería y Ciencias Aplicadas Universidad de Harvard Cambridge, MA 02138 parkes@eecs.harvard.edu RESUMEN Consideramos los paralelos entre el problema de obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría del aprendizaje. Mostramos que los algoritmos de aprendizaje pueden ser utilizados como base para algoritmos de obtención de preferencias. Los algoritmos de elicitación resultantes realizan un número polinómico de consultas. También proporcionamos condiciones bajo las cuales los algoritmos resultantes tienen comunicación polinómica. Nuestro procedimiento de conversión nos permite generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineal. En particular, obtenemos un algoritmo que obtiene ofertas XOR con comunicación polinómica. Categorías y Descriptores de Asignaturas F.2.0 [Análisis de Algoritmos y Complejidad de Problemas]: General; J.4 [Ciencias Sociales y del Comportamiento]: Economía; I.2.6 [Inteligencia Artificial]: Aprendizaje Términos Generales Algoritmos, Economía, Teoría 1. En una subasta combinatoria, los agentes pueden ofertar por paquetes de bienes en lugar de bienes individuales solamente. Dado que hay un número exponencial de paquetes (en el número de bienes), comunicar valores sobre estos paquetes puede ser problemático. Comunicar valoraciones de una sola vez puede resultar prohibitivamente costoso si el número de bienes es solo moderadamente grande. Además, incluso podría resultar difícil para los agentes determinar sus valoraciones para paquetes individuales [14]. Es del interés de dichos agentes tener protocolos de subasta que les exijan ofertar en la menor cantidad de paquetes posible. Aunque los agentes puedan calcular eficientemente sus valoraciones, aún podrían ser reacios a revelarlas por completo durante una subasta, ya que esa información podría ser valiosa para sus competidores. Estas consideraciones motivan la necesidad de protocolos de subasta que minimicen la comunicación y la revelación de información requerida para determinar una asignación óptima de bienes. Ha habido trabajos recientes explorando los vínculos entre el problema de la obtención de preferencias en subastas combinatorias y el problema de aprender una función desconocida de la teoría computacional del aprendizaje [5, 19]. En la teoría del aprendizaje, el objetivo es <br>aprender</br> una función a través de varios tipos de consultas, como ¿Cuál es el valor de la función en estas entradas? En la obtención de preferencias, el objetivo es obtener suficiente información parcial sobre las preferencias para poder calcular una asignación óptima. Aunque los objetivos del aprendizaje y la obtención de preferencias difieren en cierta medida, está claro que estos problemas comparten una estructura similar, y no debería sorprender que las técnicas de un campo sean relevantes para el otro. Mostramos que cualquier algoritmo de aprendizaje exacto con consultas de membresía y equivalencia puede convertirse en un algoritmo de obtención de preferencias con consultas de valor y demanda. El algoritmo de elicitación resultante garantiza la elicitación en un número polinomial de consultas de valor y demanda. Aquí nos referimos a un polinomio en el número de bienes, agentes y tamaños de las funciones de valoración de los agentes en un esquema de codificación dado. Los esquemas de obtención de preferencias no han considerado tradicionalmente este último parámetro. Sostenemos que las garantías de complejidad para los esquemas de obtención de información deberían permitir la dependencia de este parámetro. La introducción de este parámetro también nos permite garantizar una comunicación en el peor de los casos polinomial, lo cual generalmente no se puede lograr solo con el número de bienes y agentes. Finalmente, utilizamos nuestro procedimiento de conversión para generar protocolos de subasta combinatoria a partir de algoritmos de aprendizaje para polinomios, DNF monótono y funciones de umbral lineales. Por supuesto, una subasta combinatoria de una sola vez en la que los agentes proporcionan sus funciones de valoración completas de una vez también tendría una comunicación polinómica en el tamaño de las valoraciones de los agentes y solo requeriría una consulta. La ventaja de nuestro esquema es que los agentes pueden ser vistos como cajas negras que proporcionan información incremental sobre sus valoraciones. No hay obligación para los agentes de formular sus valoraciones en un esquema de codificación elegido por los subastadores. Esperamos que esto sea una consideración importante en la práctica. Además, con nuestro esquema la revelación completa solo ocurre en el peor de los casos. Por ahora, dejamos de lado el tema de los incentivos al derivar algoritmos de obtención de información. Nuestro enfoque se centra en la complejidad temporal y de comunicación de la obtención de preferencias, independientemente de las restricciones de incentivos, y en la relación entre las complejidades del aprendizaje y la obtención de preferencias. Trabajo relacionado. Zinkevich et al. [19] consideran el problema de aprender clases restringidas de funciones de valoración que pueden ser representadas utilizando fórmulas de lectura única y Toolbox DNF. Las fórmulas de lectura única pueden representar ciertas sustituciones, pero no complementariedades, mientras que lo opuesto es cierto para Toolbox DNF. Dado que su trabajo también se basa en la teoría del aprendizaje, permiten la dependencia del tamaño de la valoración objetivo como lo hacemos nosotros (aunque las valoraciones de una sola lectura siempre pueden representarse de manera sucinta de todos modos). Su trabajo solo hace uso de consultas de valor, las cuales son bastante limitadas en poder. Debido a que nos permitimos realizar consultas de demanda, podemos derivar un esquema de obtención para funciones de valoración generales. Blum et al. [5] proporcionan resultados relacionados con las complejidades del aprendizaje de consultas y la obtención de preferencias. Consideran modelos con consultas de membresía y equivalencia en el aprendizaje por consulta, y consultas de valor y demanda en la obtención de preferencias. Muestran que ciertas clases de funciones pueden ser aprendidas de manera eficiente pero no pueden ser obtenidas de manera eficiente, y viceversa. Por el contrario, nuestro trabajo muestra que, dado una versión más general (aunque aún bastante estándar) de la consulta de demanda que la que consideran, la complejidad de la obtención de preferencias no es mayor que la complejidad del aprendizaje. Mostraremos que las consultas de demanda pueden simular consultas de equivalencia hasta que tengamos suficiente información sobre las valoraciones para implicar una solución al problema de la obtención de información. Nisan y Segal [12] estudian la complejidad de la comunicación en la obtención de preferencias. Muestran que para muchas clases ricas de valoraciones, la complejidad de comunicación en el peor de los casos para calcular una asignación óptima es exponencial. Sus resultados se aplican al modelo de caja negra de complejidad computacional. En este modelo, los algoritmos pueden hacer preguntas sobre las valoraciones de los agentes y recibir respuestas honestas, sin tener ninguna idea de cómo los agentes calculan internamente sus valoraciones. Este es de hecho el marco básico de la teoría del aprendizaje. Nuestro trabajo también aborda el tema de la complejidad de la comunicación, y somos capaces de derivar algoritmos que ofrecen garantías significativas de comunicación a pesar de los resultados negativos de Nisan y Segal. Su trabajo motiva la necesidad de depender de los tamaños de las funciones de valoración de los agentes al declarar resultados en el peor de los casos. 2. El modelo de aprendizaje por consultas 2.1. El modelo de aprendizaje por consultas que consideramos aquí se llama aprendizaje exacto a partir de consultas de membresía y de equivalencia, introducido por Angluin [2]. En este modelo, el objetivo de los algoritmos de aprendizaje es identificar exactamente una función objetivo desconocida f : X → Y a través de consultas a un oráculo. La función objetivo se extrae de una clase de funciones C que el algoritmo conoce. Normalmente, el dominio X es un subconjunto de {0, 1}m, y el rango Y es o bien {0, 1} o algún subconjunto de los números reales Ê. A medida que el algoritmo avanza, construye una hipótesis manifiesta ˜f que es su estimación actual de la función objetivo. Al finalizar, la hipótesis manifiesta de un algoritmo de aprendizaje correcto satisface ˜f(x) = f(x) para todo x ∈ X. Es importante especificar la representación que se utilizará para codificar funciones desde C. Por ejemplo, considera la siguiente función de {0, 1}m a Ê: f(x) = 2 si x consiste en m unos, y f(x) = 0 en caso contrario. Esta función puede ser representada simplemente como una lista de 2m valores. O puede ser codificado como el polinomio 2x1 · · · xm, que es mucho más conciso. La elección de la codificación puede tener un impacto significativo en los requisitos de tiempo y espacio del algoritmo de aprendizaje. Sea size(f) el tamaño de la codificación de f con respecto a la clase de representación dada. La mayoría de las clases de representación tienen una medida natural del tamaño de codificación. El tamaño de un polinomio puede definirse como el número de coeficientes no nulos en el polinomio, por ejemplo. Normalmente solo nos referiremos a las clases de representación; las clases de función correspondientes se darán por implícitas. Por ejemplo, la clase de representación de fórmulas DNF monótonas implica la clase de funciones Booleanas monótonas. Dos tipos de consultas se utilizan comúnmente para el aprendizaje exacto: consultas de membresía y consultas de equivalencia. En una consulta de membresía, el aprendiz presenta un x ∈ X y el oráculo responde con f(x). En una consulta de equivalencia, el aprendiz presenta su hipótesis manifiesta ˜f. El oráculo responde SÍ si ˜f = f, o devuelve un contraejemplo x tal que ˜f(x) = f(x). Una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se presenta la hipótesis manifiesta. Estamos interesados en algoritmos de aprendizaje eficientes. Las siguientes definiciones están adaptadas de Kearns y Vazirani [9]: Definición 1. La clase de representación C es exactamente aprendible mediante consultas polinomiales de membresía y equivalencia si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de membresía y equivalencia de un oráculo tal que para cualquier función objetivo f ∈ C, L produce después de un máximo de p(tamaño(f), m) consultas una función ˜f ∈ C tal que ˜f(x) = f(x) para todas las instancias x. De manera similar, la clase de representación C es eficientemente exactamente aprendible a partir de consultas de membresía y de equivalencia si el algoritmo L produce una hipótesis correcta en tiempo p(tamaño(f), m), para algún polinomio fijo p(·, ·). Aquí m es la dimensión del dominio. Dado que la función objetivo debe ser reconstruida, también permitimos necesariamente una dependencia polinómica del tamaño de (f). 2.2 Elicitación de preferencias En una subasta combinatoria, un conjunto de bienes M debe ser asignado entre un conjunto de agentes N para maximizar la suma de las valoraciones de los agentes. Una asignación así se llama eficiente en la literatura económica, pero nosotros la llamaremos óptima y reservaremos el término eficiente para referirnos a la eficiencia computacional. Dejamos n = |N| y m = |M|. Una asignación es una partición de los objetos en conjuntos (S1, . . . , Sn), tal que Si ∩ Sj = ∅ para todo i, j distintos en N. Sea Γ el conjunto de asignaciones posibles. Cada agente i ∈ N tiene una función de valoración vi : 2M → Ê sobre el espacio de posibles paquetes. Cada valoración vi se extrae de una clase conocida de valoraciones Vi. Las clases de valoración no necesitan coincidir. Supondremos que todas las valoraciones consideradas están normalizadas, lo que significa que v(∅) = 0, y que no hay externalidades, lo que significa que vi(S1, ..., Sn) = vi(Si), para todos los agentes i ∈ N, para cualquier asignación (S1, ..., Sn) ∈ Γ (es decir, un agente solo se preocupa por el conjunto asignado a ella). Las valoraciones que satisfacen estas condiciones se llaman valoraciones generales. A menudo, las valoraciones generales se hacen para satisfacer la condición adicional de asumir que los agentes tienen funciones de utilidad cuasi-lineales, lo que significa que las utilidades de los agentes pueden dividirse en componentes monetarios y no monetarios. Si un agente i recibe el conjunto S a un precio p, obtiene una utilidad ui(S, p) = vi(S) − p. Una función de valoración puede ser vista como un vector de 2m − 1 valores reales no negativos. Por supuesto, también puede haber representaciones más concisas para ciertas clases de valoración, y ha habido mucha investigación sobre lenguajes de oferta concisos para varios tipos de valoraciones [11]. Un ejemplo clásico al que volveremos más adelante es el lenguaje de subasta XOR. En este lenguaje, el agente proporciona una lista de ofertas atómicas, las cuales consisten en un paquete junto con su valor. Para determinar el valor de un paquete S dado estos ofertas, se busca el paquete S de mayor valor enumerado en las ofertas atómicas tal que S ⊆ S. Entonces, se cumple que v(S) = v(S). Como en el contexto de la teoría del aprendizaje, generalmente nos referiremos solo a los lenguajes de oferta en lugar de las clases de valoración, ya que las clases de valoración correspondientes estarán implícitas. Por ejemplo, el lenguaje de subasta XOR implica la clase de valoraciones que satisfacen el libre disposición, que es la condición de que A ⊆ B ⇒ v(A) ≤ v(B). Dejamos que el tamaño(v1, . . . , vn) = Σn i=1 tamaño(vi). Es decir, el tamaño de un vector de valoraciones es el tamaño de la concatenación de las representaciones de las valoraciones en sus respectivos esquemas de codificación (idiomas de oferta). Para hacer una analogía con la teoría computacional del aprendizaje, asumimos que todas las clases de representación consideradas son polinomialmente interpretables [11], lo que significa que el valor de un conjunto puede ser calculado en tiempo polinómico dadas las funciones de valoración de la representación. De manera más formal, una clase de representación (lenguaje de oferta) C es polinómicamente interpretable si existe un algoritmo que, dado como entrada algún v ∈ C y una instancia x ∈ X, calcula el valor v(x) en tiempo q(tamaño(v), m), para algún polinomio fijo q(·, ·). En las rondas intermedias de una subasta (iterativa), el subastador habrá obtenido información sobre las funciones de valoración de los agentes a través de varios tipos de consultas. Así habrá construido un conjunto de valoraciones manifiestas, denotadas ˜v1, . . . , ˜vn. Los valores de estas funciones pueden corresponder exactamente a los valores verdaderos del agente, o pueden ser, por ejemplo, límites superiores o inferiores de los valores verdaderos, dependiendo de los tipos de consultas realizadas. También pueden ser simplemente valores predeterminados o aleatorios si no se ha obtenido información sobre ciertos paquetes. El objetivo en el problema de la obtención de preferencias es construir un conjunto de valoraciones manifiestas de tal manera que: arg max (S1,...,Sn)∈Γ i∈N ˜vi(Si) ⊆ arg max (S1,...,Sn)∈Γ i∈N vi(Si) Es decir, las valoraciones manifiestas proporcionan suficiente información para calcular una asignación que sea óptima con respecto a las valoraciones reales. Ten en cuenta que solo requerimos una asignación óptima de este tipo. La condición de disposición libre (monotonía), pero no la necesitamos en este momento. 2 Esto excluye OR∗ , asumiendo P = NP, porque interpretar ofertas de este lenguaje es NP-duro mediante reducción de empaquetamiento de conjuntos ponderados, y no hay una clase de representación bien estudiada en teoría del aprendizaje que sea claramente análoga a OR∗ . 3 Esta visión de las subastas iterativas está destinada a ser paralela al entorno de aprendizaje. En muchas subastas combinatorias, las valoraciones manifiestas no se mantienen explícitamente, sino que simplemente se deducen de la historia de las ofertas. Dos consultas típicas utilizadas en la obtención de preferencias son las consultas de valor y de demanda. En una consulta de valor, el subastador presenta un conjunto S ⊆ M y el agente responde con su valor (exacto) para el conjunto v(S) [8]. En una consulta de demanda, el subastador presenta un vector de precios no negativos p ∈ Ê(2m) sobre los paquetes junto con un paquete S. El agente responde SÍ si es el caso que S ∈ arg max S ⊆M v(S) − p(S) ¡ o de lo contrario presenta un paquete S tal que v(S) − p(S) > v(S) − p(S). Es decir, el agente confirma que el paquete presentado es el más preferido a los precios cotizados, o indica uno mejor. Nota que incluimos ∅ como un paquete, por lo que el agente solo responderá SÍ si su utilidad para el paquete propuesto es no negativa. También hay que tener en cuenta que comunicar precios no lineales no implica necesariamente citar un precio para cada posible paquete. Puede haber formas más concisas de comunicar este vector, como mostramos en la sección 5. Hacemos las siguientes definiciones para paralelizar el entorno de aprendizaje de consultas y simplificar las afirmaciones de los resultados posteriores: Definición 2. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si existe un polinomio fijo p(·, ·) y un algoritmo L con acceso a consultas de valor y demanda de los agentes, de tal manera que para cualquier (v1, . . . , vn) ∈ V1 × . . . × Vn, L devuelve después de un máximo de p(tamaño(v1, . . . , vn), m) consultas una asignación (S1, . . . , Sn) ∈ arg max(S1,...,Sn)∈Γ È vi(Si). Del mismo modo, la clase de representación C puede ser eficientemente obtenida a partir de consultas de valor y demanda si el algoritmo L produce una asignación óptima con una comunicación p(tamaño(v1, . . . , vn), m), para algún polinomio fijo p(·, ·). Aquí hay algunas diferencias clave con la definición de aprendizaje por consulta. Hemos eliminado el término \"exactamente\" ya que las funciones de valoración no necesitan ser determinadas exactamente para calcular una asignación óptima. Además, un algoritmo de obtención eficiente es de comunicación polinómica, en lugar de tiempo polinómico. Esto refleja el hecho de que la comunicación, en lugar del tiempo de ejecución, es el cuello de botella en la obtención de información. Calcular una asignación óptima de bienes, incluso cuando se conocen las valoraciones reales, es NP-duro para una amplia gama de clases de valoración. Por lo tanto, es irrazonable requerir tiempo polinómico en la definición de un algoritmo eficiente de elicitación de preferencias. Nos complace centrarnos en la complejidad de comunicación de la obtención de información, ya que se cree ampliamente que este problema es más significativo en la práctica que el de la determinación del ganador [11]. Esto difiere ligeramente de la definición proporcionada por Blum et al. [5]. Sus consultas de demanda están restringidas a precios lineales sobre los bienes, donde el precio de un paquete es la suma de los precios de sus bienes subyacentes. En contraste, nuestras consultas de demanda permiten precios no lineales, es decir, un precio distinto para cada posible paquete. Por eso, el límite inferior en su Teorema 2 no contradice nuestro resultado que sigue. Aunque el problema de determinación del ganador es NP-duro para valoraciones generales, existen muchos algoritmos que lo resuelven eficientemente en la práctica. Estos van desde algoritmos de propósito especial [7, 16] hasta enfoques que utilizan solucionadores de IP listos para usar [1]. Dado que las valoraciones no necesitan ser obtenidas exactamente, inicialmente no está claro si la dependencia polinómica del tamaño (v1, . . . , vn) está justificada en este contexto. De manera intuitiva, este parámetro está justificado porque debemos <br>aprender</br> valoraciones exactamente al realizar la solicitud, en el peor de los casos. Abordaremos esto en la siguiente sección. 3. Hemos descrito la configuración de aprendizaje de consultas y de obtención de preferencias de una manera que resalta sus similitudes. Las consultas de valor y de membresía son claros análogos. Un hecho ligeramente menos obvio es que las consultas de equivalencia y de demanda también son análogas. Para ver esto, necesitamos el concepto de precios de Lindahl. Los precios de Lindahl son precios no lineales y no anónimos sobre los paquetes. Son no lineales en el sentido de que a cada paquete se le asigna un precio, y este precio no es necesariamente la suma de los precios de sus bienes subyacentes. No son anónimos en el sentido de que dos agentes pueden enfrentar precios diferentes por el mismo conjunto de bienes. Por lo tanto, los precios de Lindahl son de la forma pi(S), para todo S ⊆ M, para todo i ∈ N. Los precios de Lindahl se presentan a los agentes en consultas de demanda. Cuando los agentes tienen funciones de utilidad cuasi-lineales normalizadas, Bikhchandani y Ostroy [4] muestran que siempre existen precios de Lindahl tales que (S1, . . . , Sn) es una asignación óptima si y solo si Si ∈ arg max Si vi(Si) − pi(Si) ¡ ∀i ∈ N (1) (S1, . . . , Sn) ∈ arg max (S1,...,Sn)∈Γ i∈N pi(Si) (2) La Condición (1) establece que a cada agente se le asigna un paquete que maximiza su utilidad a los precios dados. La condición (2) establece que la asignación maximiza los ingresos del subastador a los precios dados. El escenario en el que se cumplen estas condiciones se llama equilibrio de Lindahl, o a menudo equilibrio competitivo. Decimos que los precios de Lindahl respaldan la asignación óptima. Por lo tanto, es suficiente anunciar el apoyo a los precios de Lindahl para verificar una asignación óptima. Una vez que hayamos encontrado una asignación con precios de Lindahl de apoyo, el problema de la elicitación estará resuelto. El problema de encontrar una asignación óptima (con respecto a las valoraciones manifiestas) puede formularse como un programa lineal cuyas soluciones están garantizadas de ser integrales [4]. Las variables duales de este programa lineal son los precios de Lindahl que respaldan la asignación resultante. La función objetivo del programa dual es: min π(S) πs + i∈N πi (3) con πi = max S⊆M (˜vi(S) − pi(S)) πs = max (S1,...,Sn)∈Γ i∈N pi(Si) Los valores óptimos de πi y πs corresponden a la utilidad máxima para el agente i con respecto a su valoración manifiesta y a los ingresos máximos para el vendedor. Por lo general, hay un rango de posibles precios de Lindahl que respaldan una asignación óptima dada. Las valoraciones manifiestas de los agentes son de hecho precios de Lindahl válidos, y nos referimos a ellos como precios de Lindahl máximos. De entre todos los posibles vectores de precios de Lindahl, los precios de Lindahl máximos maximizan la utilidad del subastador, de hecho dándole todo el bienestar social. Por el contrario, los precios que maximizan el componente È i∈N πi del objetivo (la suma de las utilidades de los agentes) son los precios mínimos de Lindahl. Cualquier precio de Lindahl servirá para nuestros resultados, pero algunos pueden tener mejores propiedades de elicitación que otros. Ten en cuenta que una consulta de demanda con precios de Lindahl máximos es casi idéntica a una consulta de equivalencia, ya que en ambos casos comunicamos la valoración manifiesta al agente. Dejamos para trabajos futuros la pregunta de qué precios de Lindahl elegir para minimizar la elicitación de preferencias. Considerando ahora por qué las consultas de demanda y de equivalencia son análogas directas, primero observe que dada la πi en algún equilibrio de Lindahl, establecer pi(S) = max{0, ˜vi(S) − πi} (4) para todo i ∈ N y S ⊆ M produce precios de Lindahl válidos. Estos precios dejan indiferente a cada agente en todos los paquetes con precio positivo, y cumplen con la condición (1). Por lo tanto, las consultas de demanda también pueden comunicar implícitamente valoraciones manifiestas, ya que los precios de Lindahl suelen estar a una constante aditiva de estos por igualdad (4). En el siguiente lema mostramos cómo obtener contraejemplos a consultas de equivalencia a través de consultas de demanda. Lema 1. Supongamos que un agente responde con un conjunto preferido S cuando se le propone un conjunto S y precios de Lindahl de soporte p(S) (de soporte con respecto a la valoración manifiesta de los agentes). Entonces, o ˜v(S) = v(S) o ˜v(S) = v(S). Prueba. Tenemos las siguientes desigualdades: ˜v(S) − p(S) ≥ ˜v(S ) − p(S ) ⇒ ˜v(S ) − ˜v(S) ≤ p(S ) − p(S) (5) v(S ) − p(S ) > v(S) − p(S) ⇒ v(S ) − v(S) > p(S ) − p(S) (6) La desigualdad (5) se cumple porque los precios respaldan la asignación propuesta con respecto a la valoración manifiesta. La desigualdad (6) se cumple porque el agente de hecho prefiere S a S dadas las precios, de acuerdo a su respuesta a la consulta de demanda. Si fuera el caso de que ˜v(S) = v(S) y ˜v(S ) = v(S ), estas desigualdades representarían una contradicción. Por lo tanto, al menos uno de S y S es un contraejemplo a la valoración manifiesta de los agentes. Finalmente, justificamos la dependencia del tamaño (v1, . . . , vn) en problemas de obtención de información. Nisan y Segal (Proposición 1, [12]) y Parkes (Teorema 1, [13]) muestran que el apoyo a los precios de Lindahl debe necesariamente ser revelado en el transcurso de cualquier protocolo de obtención de preferencias que finalice con una asignación óptima. Además, Nisan y Segal (Lema 1, [12]) afirman que en el peor de los casos, los precios de los agentes deben coincidir con sus valoraciones (hasta una constante), cuando la clase de valoración es lo suficientemente rica como para contener valoraciones duales (como será el caso con la mayoría de las clases interesantes). Dado que revelar los precios de Lindahl es una condición necesaria para establecer una asignación óptima, y dado que los precios de Lindahl contienen la misma información que las funciones de valoración (en el peor de los casos), permitir la dependencia del tamaño (v1, . . . , vn) en problemas de elicitación es completamente natural. 183 4. DE APRENDIZAJE A ELICITACIÓN DE PREFERENCIAS La clave para convertir un algoritmo de aprendizaje en un algoritmo de elicitation es simular consultas de equivalencia con consultas de demanda y valor hasta encontrar una asignación óptima. Debido a nuestra construcción de precios de Lindahl, cuando todos los agentes responden SÍ a una consulta de demanda, hemos encontrado una asignación óptima, análoga al caso en el que un agente responde SÍ a una consulta de equivalencia cuando la función objetivo ha sido aprendida exactamente. De lo contrario, podemos obtener un contraejemplo para una consulta de equivalencia dada la respuesta de un agente a una consulta de demanda. Teorema 1. Las clases de representación V1, . . . , Vn pueden ser solicitadas mediante consultas polinomiales de valor y demanda si cada una puede ser aprendida exactamente mediante consultas de membresía y equivalencia con consultas polinomiales. Prueba. Considera el algoritmo de obtención en la Figura 1. Cada consulta de membresía en el paso 1 se simula con una consulta de valor ya que en realidad son idénticas. Considera el paso 4. Si todos los agentes responden SÍ, se cumple la condición (1). La condición (2) se cumple porque la asignación calculada maximiza los ingresos para el subastador, independientemente de las verdaderas valoraciones de los agentes. Por lo tanto, se ha encontrado una asignación óptima. De lo contrario, al menos uno de Si o Si es un contraejemplo para ˜vi, según el Lema 1. Identificamos un contraejemplo realizando consultas de valor en ambos paquetes, y lo proporcionamos a Ai como respuesta a su consulta de equivalencia. Este procedimiento se detendrá, ya que en el peor de los casos todas las valoraciones de los agentes se aprenderán exactamente, en cuyo caso la asignación óptima y los precios de Lindahl serán aceptados por todos los agentes. El procedimiento realiza un número polinómico de consultas, ya que A1, . . . , An son todos algoritmos de aprendizaje con consultas polinómicas. Ten en cuenta que el procedimiento de conversión resulta en un algoritmo de elicitación de preferencias, no en un algoritmo de aprendizaje. Es decir, el algoritmo resultante no solo <br>aprende</br> las valoraciones exactamente, luego calcula una asignación óptima. Más bien, obtiene información parcial sobre las valoraciones a través de consultas de valor y periódicamente verifica si se ha recopilado suficiente información proponiendo una asignación a los agentes a través de consultas de demanda. Es posible generar un equilibrio de Lindahl para valoraciones v1, . . . , vn utilizando una asignación y precios derivados utilizando valoraciones manifiestas ˜v1, . . . , ˜vn, y encontrar una asignación óptima no implica que las valoraciones de los agentes hayan sido aprendidas exactamente. El uso de consultas de demanda para simular consultas de equivalencia permite esta detención temprana. No obtendríamos esta propiedad con consultas de equivalencia basadas en valoraciones manifiestas. 5. COMPLEJIDAD DE LA COMUNICACIÓN En esta sección, abordamos el tema de la complejidad de la comunicación en la obtención de información. Nisan y Segal [12] muestran que para una variedad de espacios de valoración ricos (como valoraciones generales y submodulares), la carga de comunicación en el peor de los casos para determinar los precios de Lindahl es exponencial en el número de bienes, m. La carga de comunicación se mide en términos del número de bits transmitidos entre los agentes y el subastador en el caso de comunicación discreta, o en términos del número de números reales transmitidos en el caso de comunicación continua. Convertir algoritmos de aprendizaje eficientes en un algoritmo de elicitación produce un algoritmo cuyas consultas tienen tamaños polinomiales en los parámetros m y size(v1, . . . , vn). Teorema 2. Las clases de representación V1, . . . , Vn pueden ser eficientemente obtenidas a partir de consultas de valor y demanda si cada una de ellas puede ser aprendida de manera exacta y eficiente a partir de consultas de membresía y equivalencia. Prueba. El tamaño de cualquier consulta de valor es O(m): el mensaje consiste únicamente en el paquete consultado. Para comunicar los precios de Lindahl al agente i, es suficiente comunicar la función de valoración manifiesta de los agentes y el valor πi, mediante la igualdad (4). Ten en cuenta que un algoritmo de aprendizaje eficiente nunca construye una hipótesis manifiesta de tamaño superpolinómico, ya que el tiempo de ejecución de los algoritmos sería entonces también superpolinómico, contradiciendo la eficiencia. Por lo tanto, comunicar la valoración manifiesta requiere un tamaño de a lo sumo p(tamaño(vi), m), para algún polinomio p que limite superiormente el tiempo de ejecución del algoritmo de aprendizaje eficiente. Representar el excedente πi al agente i no puede requerir un espacio mayor que q(tamaño(˜vi), m) para algún polinomio fijo q, porque asumimos que la representación elegida es polinómicamente interpretable, y por lo tanto cualquier valor generado será de tamaño polinómico. También debemos comunicarle a i su paquete asignado, por lo que el tamaño total del mensaje para una consulta de demanda es a lo sumo p(tamaño(vi), m) + q(p(tamaño(vi), m), m) + O(m). Claramente, la respuesta de un agente a una consulta de valor o demanda tiene un tamaño de a lo sumo q(tamaño(vi), m) + O(m). Por lo tanto, las consultas de valor y demanda, y las respuestas a estas consultas, siempre son de tamaño polinómico. Un algoritmo de aprendizaje eficiente realiza un número polinómico de consultas, por lo que la comunicación total del algoritmo de elicitación resultante es polinómica en los parámetros relevantes. A menudo habrá límites explícitos en el número de consultas de membresía y equivalencia realizadas por un algoritmo de aprendizaje, con constantes que no están enmascaradas por la notación big-O. Estos límites se pueden traducir en límites explícitos sobre el número de consultas de valor y demanda realizadas por el algoritmo de elicitación resultante. Hemos acotado superiormente el tamaño de la hipótesis manifiesta con el tiempo de ejecución del algoritmo de aprendizaje en el Teorema 2. Es probable que podamos hacer mucho mejor que esto en la práctica. Recuerda que una consulta de equivalencia es adecuada si el tamaño de ˜f es menor o igual al tamaño de f en el momento en que se realiza la consulta. Si las consultas de equivalencia de los algoritmos de aprendizaje son todas adecuadas, entonces también puede ser posible proporcionar límites ajustados sobre los requisitos de comunicación del algoritmo de obtención resultante. El Teorema 2 muestra que los algoritmos de elicitación que dependen del parámetro de tamaño (v1, . . . , vn) evitan los resultados negativos de Nisan y Segal [12] sobre la complejidad de comunicación en el peor de los casos de problemas de asignación eficiente. Proporcionan garantías con respecto a los tamaños de las instancias de funciones de valoración enfrentadas en cualquier ejecución del algoritmo. Estos algoritmos funcionarán bien si la clase de representación elegida proporciona representaciones concisas para las valoraciones más simples y comunes, y por lo tanto, el enfoque vuelve a uno de lenguajes de oferta compactos pero expresivos. Consideramos estos temas a continuación. 6. En esta sección, demostramos la aplicación de nuestros métodos a clases de representación particulares para valoraciones combinatorias. Hemos demostrado que el problema de la obtención de preferencias para las clases de valoración V1, ..., Vn se puede reducir 184 Dado: algoritmos de aprendizaje exactos A1, ..., An para las clases de valoración V1, ..., Vn respectivamente. Bucle hasta que haya una señal para detenerse: 1. Ejecutar A1, . . . , An en paralelo en sus respectivos agentes hasta que cada uno requiera una respuesta a una consulta de equivalencia, o se haya detenido con la valuación exacta de los agentes. 2. Calcular una asignación óptima (S1, . . . , Sn) y los precios de Lindahl correspondientes con respecto a las valoraciones manifiestas ˜v1, . . . , ˜vn determinadas hasta ahora. 3. Presentar la asignación y los precios a los agentes en forma de una consulta de demanda. 4. Si todos responden SÍ, mostrar la asignación y detenerse. De lo contrario, hay algún agente i que ha respondido con un conjunto preferido Si. Realice consultas de valor en Si y Si para encontrar un contraejemplo a ˜vi, y proporcióneselo a Ai. Figura 1: Convirtiendo algoritmos de aprendizaje en un algoritmo de obtención para el problema de encontrar un algoritmo de aprendizaje eficiente para cada una de estas clases por separado. Esto es significativo porque ya existen algoritmos de aprendizaje para una gran cantidad de clases de funciones, y porque a menudo puede ser más sencillo resolver cada subproblema de aprendizaje por separado que abordar directamente el problema de la obtención de preferencias. Podemos desarrollar un algoritmo de elicitación que se adapte a la valoración de cada agente, con los algoritmos de aprendizaje subyacentes vinculados en las etapas de consulta de demanda de una manera independiente del algoritmo. Mostramos que los algoritmos de aprendizaje existentes para polinomios, fórmulas DNF monótonas y funciones de umbral lineal pueden convertirse en algoritmos de obtención de preferencias para valoraciones generales, valoraciones con disposición libre y valoraciones con sustituibilidad, respectivamente. Nos enfocamos en representaciones que son polinómicamente interpretables, porque la literatura de la teoría del aprendizaje computacional pone un fuerte énfasis en la tratabilidad computacional [18]. Al interpretar los métodos, enfatizamos la expresividad y la concisión de cada clase de representación. La clase de representación, que en términos de subasta combinatoria define un lenguaje de oferta, debe ser necesariamente lo suficientemente expresiva como para representar todas las valoraciones posibles de interés, y también debería representar de manera sucinta las funciones más simples y comunes de la clase. 6.1 Representaciones Polinomiales Schapire y Sellie [17] presentan un algoritmo de aprendizaje para polinomios multivariados dispersos que puede ser utilizado como base para un protocolo de subasta combinatoria. Las consultas de equivalencia realizadas por este algoritmo son todas adecuadas. Específicamente, su algoritmo aprende la clase de representación de polinomios multivariados t-esparsos sobre los números reales, donde las variables pueden tomar valores de 0 o 1. Un polinomio t-esparso tiene como máximo t términos, donde un término es un producto de variables, por ejemplo, x1x3x4. Un polinomio sobre los números reales tiene coeficientes tomados de los números reales. Los polinomios son expresivos: cada función de valoración v : 2M → Ê+ puede ser escrita de manera única como un polinomio [17]. Para tener una idea de la concisión de los polinomios como lenguaje de subasta, considera las valoraciones aditivas y de un solo artículo presentadas por Nisan [11]. En la valoración aditiva, el valor de un paquete es la cantidad de bienes que contiene el paquete. En la valoración de un solo artículo, todos los paquetes tienen un valor de 1, excepto ∅ que tiene un valor de 0 (es decir, el agente queda satisfecho tan pronto como adquiere un solo artículo). No es difícil demostrar que la valoración de un solo ítem requiere polinomios de tamaño 2m − 1, mientras que los polinomios de tamaño m son suficientes para la valoración aditiva. Los polinomios son apropiados para valoraciones que son principalmente aditivas, con algunas sustituciones y complementariedades que pueden ser introducidas ajustando los coeficientes. El algoritmo de aprendizaje para polinomios realiza como máximo mti + 2 consultas de equivalencia y como máximo (mti + 1)(t2 i + 3ti)/2 consultas de membresía a un agente i, donde ti es la dispersión del polinomio que representa vi [17]. Por lo tanto, obtenemos un algoritmo que obtiene valoraciones generales con un número polinómico de consultas y comunicación polinómica. 6.2 Representaciones XOR El lenguaje de oferta XOR es estándar en la literatura de subastas combinatorias. Recuerde que una oferta XOR se caracteriza por un conjunto de paquetes B ⊆ 2M y una función de valor w : B → Ê+ definida en esos paquetes, que induce la función de valoración: v(B) = max {B ∈B | B ⊆B} w(B ) (7) Las ofertas XOR pueden representar valoraciones que cumplen con la propiedad de disposición libre (y solo tales valoraciones), que nuevamente es la propiedad de que A ⊆ B ⇒ v(A) ≤ v(B). El lenguaje de subasta XOR es ligeramente menos expresivo que los polinomios, ya que los polinomios pueden representar valoraciones que no cumplen con la disposición libre. Sin embargo, XOR es tan expresivo como se requiere en la mayoría de los entornos económicos. Nisan [11] señala que las ofertas XOR pueden representar la valoración de un solo artículo con m ofertas atómicas, pero se necesitan 2m − 1 ofertas atómicas para representar la valoración aditiva. Dado que lo contrario ocurre con los polinomios, estos dos lenguajes son incomparables en concisión y algo complementarios para uso práctico. Blum et al. [5] señalan que las fórmulas DNF monótonas son los análogos de las ofertas XOR en la literatura de teoría del aprendizaje. Una fórmula DNF monótona es una disyunción de conjunciones en las que las variables aparecen sin negar, por ejemplo x1x2 ∨ x3 ∨ x2x4x5. Ten en cuenta que dichas fórmulas pueden representarse como pujas XOR donde cada puja atómica tiene un valor de 1; por lo tanto, las pujas XOR generalizan las fórmulas DNF monótonas de booleano a funciones de valores reales. Estas ideas nos permiten generalizar un algoritmo de aprendizaje clásico para DNF monótono ([3] Teorema 6. Nótese que el Teorema 1 se aplica incluso si las valoraciones no cumplen con la disposición libre. 185 1, [18] Teorema B) a un algoritmo de aprendizaje para ofertas XOR.7 Lema 2. Una oferta XOR que contiene t ofertas atómicas puede ser aprendida exactamente con t + 1 consultas de equivalencia y como máximo tm consultas de membresía. Prueba. El algoritmo identificará cada oferta atómica en la oferta XOR objetivo, una por una. Inicialice la valoración del manifiesto ˜v con la oferta que es idénticamente cero en todos los paquetes (esta es una oferta XOR que contiene 0 ofertas atómicas). Presenta ˜v como una consulta de equivalencia. Si la respuesta es SÍ, hemos terminado. De lo contrario, obtenemos un conjunto S para el cual v(S) = ˜v(S). Crear un paquete T de la siguiente manera. Primero inicializa T = S. Para cada elemento i en T, verifica a través de una consulta de membresía si v(T) = v(T − {i}). Si es así, establezca T = T - {i}. De lo contrario, deja T como está y continúa con el siguiente elemento. Sostenemos que (T, v(T)) es una oferta atómica de la oferta XOR objetivo. Para cada elemento i en T, tenemos que v(T) = v(T − {i}). Para ver esto, observe que en algún momento al generar T, tuvimos un ¯T tal que T ⊆ ¯T ⊆ S y v(¯T) > v(¯T - {i}), de modo que i se mantuvo en ¯T. Ten en cuenta que v(S) = v(¯T) = v(T) porque el valor del conjunto S se mantiene constante durante el proceso de eliminación de elementos. Ahora suponga que v(T) = v(T − {i}). Entonces v(¯T) = v(T) = v(T - {i}) > v(¯T - {i}) lo cual contradice la libre disposición, ya que T - {i} ⊆ ¯T - {i}. Por lo tanto, v(T) > v(T − {i}) para todos los elementos i en T. Esto implica que (T, v(T)) es una oferta atómica de v. Si esto no fuera el caso, T asumiría el valor máximo de sus subconjuntos estrictos, por la definición de una oferta XOR, y tendríamos v(T) = max i∈T { max T ⊆T −{i} v(T )} = max i∈T {v(T − {i})} < v(T), lo cual es una contradicción. Ahora demostramos que v(T) = ˜v(T), lo cual implicará que (T, v(T)) no es una oferta atómica de nuestra hipótesis manifiesta por inducción. Suponga que cada oferta atómica (R, ˜v(R)) identificada hasta ahora es de hecho una oferta atómica de v (lo que significa que R está efectivamente listado en una oferta atómica de v con valor v(R) = ˜v(R)). Esta suposición se cumple vacuamente cuando se inicializa la valoración manifiesta. Utilizando la notación de la ecuación (7), sea ( ˜B, ˜w) nuestra hipótesis, y (B, w) la función objetivo. Tenemos ˜B ⊆ B, y ˜w(B) = w(B) para B ∈ ˜B por suposición. Por lo tanto, ˜v(S) = max {B∈ ˜B | B⊆S} ˜w(B) = max {B∈ ˜B | B⊆S} w(B) ≤ max {B∈B | B⊆S} w(B) = v(S) (8) Ahora asumamos que v(T) = ˜v(T). Entonces, ˜v(T) = v(T) = v(S) = ˜v(S) (9) La segunda igualdad se sigue del hecho de que el valor permanece constante cuando derivamos T de S. La última desigualdad se cumple porque S es un contraejemplo a la valoración manifiesta. A partir de la ecuación (9) y la eliminación libre, el algoritmo citado también se utilizó como base para el algoritmo de elicitación de Zinkevich et al. [19] para Toolbox DNF. Recuerda que las cajas de herramientas DNF son polinomios con coeficientes no negativos. Para estas representaciones, una consulta de equivalencia puede ser simulada con una consulta de valor en el conjunto que contiene todos los bienes. Tener ˜v(T) < ˜v(S). Una vez más, de la ecuación (9) se sigue que v(S) < ˜v(S). Esto contradice (8), por lo que de hecho tenemos v(T) = ˜v(T). Por lo tanto, (T, v(T)) no se encuentra actualmente en nuestra hipótesis como una oferta atómica, de lo contrario tendríamos correctamente ˜v(T) = v(T) según la hipótesis de inducción. Añadimos (T, v(T)) a nuestra hipótesis y repetimos el proceso anterior, realizando consultas de equivalencia adicionales hasta identificar todas las ofertas atómicas. Después de cada consulta de equivalencia, se identifica una oferta atómica con un máximo de m consultas de membresía. Cada contraejemplo lleva al descubrimiento de una nueva oferta atómica. Así, realizamos como máximo tm consultas de membresía y exactamente t + 1 consultas de equivalencia. El número de pasos de tiempo requeridos por este algoritmo es esencialmente el mismo que el número de consultas realizadas, por lo que el algoritmo es eficiente. Aplicando el Teorema 2, obtenemos por lo tanto el siguiente corolario: Teorema 3. La clase de representación de las ofertas XOR puede ser eficientemente obtenida a partir de consultas de valor y demanda. Esto contrasta con los resultados negativos de Blum et al. ([5], Teorema 2) que afirman que las DNF monótonas (y por lo tanto las ofertas XOR) no pueden ser eficientemente obtenidas cuando las consultas de demanda están restringidas a precios lineales y anónimos sobre los bienes. 6.3 Representaciones de Umbral Lineal Polinomios, ofertas XOR y todos los lenguajes basados en el lenguaje de oferta OR (como XOR-de-OR, OR-de-XOR y OR∗) no logran representar de manera sucinta la valoración mayoritaria [11]. En esta valoración, los paquetes tienen un valor de 1 si contienen al menos m/2 artículos, y un valor de 0 en caso contrario. Más generalmente, considera la familia de valoraciones r-de-S donde los paquetes tienen un valor de 1 si contienen al menos r elementos de un conjunto especificado de elementos S ⊆ M, y un valor de 0 en caso contrario. La valoración de la mayoría es un caso especial de la valoración r-de-S con r = m/2 y S = M. Estas valoraciones son apropiadas para representar sustituibilidades: una vez que se ha obtenido un conjunto requerido de elementos, ningún otro elemento puede agregar valor. Dejando k = |S|, tales valoraciones son representadas de manera sucinta por funciones de umbral r-de-k. Estas funciones toman la forma de desigualdades lineales: xi1 + . . . + xik ≥ r donde la función tiene valor 1 si la desigualdad se cumple, y 0 en caso contrario. Aquí i1, . . . , ik son los elementos en S. El algoritmo WINNOW 2 de Littlestone puede <br>aprender</br> tales funciones utilizando solo consultas de equivalencia, utilizando como máximo 8r2 + 5k + 14kr ln m + 1 consultas [10]. Para proporcionar esta garantía, r debe ser conocido por el algoritmo, pero S (y k) son desconocidos. El algoritmo de elicitación que resulta de WINNOW 2 utiliza solo consultas de demanda (las consultas de valor no son necesarias aquí porque los valores de los contraejemplos se sobreentienden cuando solo hay dos posibles valores). Ten en cuenta que las funciones de umbral r-de-k siempre pueden ser representadas de manera sucinta en un espacio de O(m). Así obtenemos un algoritmo que puede obtener dichas funciones con un número polinómico de consultas y comunicación polinómica, solo en los parámetros n y m. 186 7. CONCLUSIONES Y TRABAJO FUTURO Hemos demostrado que los algoritmos de aprendizaje exacto con consultas de membresía y equivalencia pueden ser utilizados como base para algoritmos de obtención de preferencias con consultas de valor y demanda. En el centro de este resultado está el hecho de que las consultas de demanda pueden ser vistas como consultas de equivalencia modificadas, especializadas para el problema de la obtención de preferencias. Nuestro resultado nos permite aplicar la gran cantidad de algoritmos de aprendizaje disponibles al problema de la obtención de preferencias. Un enfoque de aprendizaje para la elicitación también motiva un enfoque diferente para diseñar algoritmos de elicitación que se descomponen de manera ordenada entre los tipos de agentes. Si el diseñador conoce de antemano qué tipos de preferencias es probable que exhiba cada agente (principalmente aditivas, muchos sustitutos, etc...), puede diseñar algoritmos de aprendizaje adaptados a las valoraciones de cada agente e integrarlos en un esquema de obtención de información. El algoritmo de elicitación resultante realiza un número polinómico de consultas y tiene una comunicación polinómica si los algoritmos de aprendizaje originales son eficientes. No requerimos que las valoraciones de los agentes puedan ser aprendidas con consultas de valor y demanda. Las consultas de equivalencia solo pueden ser, y solo necesitan ser, simuladas hasta el punto en que se haya calculado una asignación óptima. Este es el problema de la obtención de preferencias. El Teorema 1 implica que la obtención de información con consultas de valor y demanda no es más difícil que el aprendizaje con consultas de membresía y equivalencia, pero no proporciona ninguna mejora asintótica sobre la complejidad de los algoritmos de aprendizaje. Sería interesante encontrar ejemplos de clases de valoración para las cuales la obtención de información sea más fácil que el aprendizaje. Blum et al. [5] proporcionan un ejemplo de esto al considerar solo consultas de membresía/valor (Teorema 4). En trabajos futuros planeamos abordar el tema de los incentivos al convertir algoritmos de aprendizaje en algoritmos de obtención de información. En el entorno de aprendizaje, generalmente asumimos que los oráculos proporcionarán respuestas honestas a las consultas; en el entorno de obtención, los agentes suelen ser egoístas y proporcionarán posiblemente respuestas deshonestas para maximizar su utilidad. También planeamos implementar los algoritmos para aprender polinomios y ofertas XOR como algoritmos de obtención, y probar su rendimiento frente a otros protocolos establecidos de subasta combinatoria [6, 15]. Una pregunta interesante aquí es: ¿cuáles son los precios de Lindahl en el rango máximo a mínimo que son mejores para citar con el fin de minimizar la revelación de información? Conjeturamos que la revelación de información se reduce al pasar de los precios de Lindahl máximos a mínimos, es decir, a medida que alejamos las consultas de demanda de las consultas de equivalencia. Finalmente, sería útil determinar si el lenguaje de oferta OR∗ [11] se puede aprender eficientemente (y por lo tanto, ser solicitado), dada la expresividad y concisión de este lenguaje para una amplia variedad de clases de valoración. Agradecimientos Nos gustaría agradecer a Debasis Mishra por las útiles discusiones. Este trabajo está apoyado en parte por la subvención de la NSF IIS0238147. REFERENCIAS [1] A. Andersson, M. Tenhunen y F. Ygge. Programación entera para la determinación del ganador en subastas combinatorias. En Actas de la Cuarta Conferencia Internacional sobre Sistemas Multiagentes (ICMAS-00), 2000. [2] D. Angluin. Aprendiendo conjuntos regulares a partir de consultas y contraejemplos. Información y Computación, 75:87-106, noviembre de 1987. [3] D. Angluin. Consultas y aprendizaje de conceptos. Aprendizaje automático, 2:319-342, 1987. [4] S. Bikhchandani y J. Ostroy. El Modelo de Asignación de Paquetes. Revista de Teoría Económica, 107(2), diciembre de 2002. [5] A. Blum, J. Jackson, T. Sandholm y M. Zinkevich. Elicitación de preferencias y aprendizaje de consultas. En Proc. 16ª Conferencia Anual sobre Teoría Computacional del Aprendizaje (COLT), Washington DC, 2003. [6] W. Conen y T. Sandholm. Mecanismo VCG de revelación parcial para subastas combinatorias. En Proc. de la 18ª Conferencia Nacional de Inteligencia Artificial (AAAI), 2002. [7] Y. Fujishima, K. Leyton-Brown y Y. Shoham. Domando la complejidad computacional de las subastas combinatorias: Enfoques óptimos y aproximados. En Proc. de la 16ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 548-553, 1999. [8] B. Hudson y T. Sandholm. Utilizando consultas de valor en subastas combinatorias. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. [9] M. J. Kearns y U. V. Vazirani. Una introducción a la teoría computacional del aprendizaje. MIT Press, 1994. [10] N. Littlestone. \n\nMIT Press, 1994. [10] N. Littlestone. Aprendizaje rápido cuando abundan atributos irrelevantes: Un nuevo algoritmo de umbral lineal. Aprendizaje automático, 2:285-318, 1988. [11] N. Nisan. Subasta y asignación en subastas combinatorias. En Proc. de la Conferencia ACM sobre Comercio Electrónico, páginas 1-12, 2000. [12] N. Nisan e I. Segal. Los requisitos de comunicación de asignaciones eficientes y precios de Lindahl de apoyo. Documento de trabajo, Universidad Hebrea, 2003. [13] D. C. Parkes. Certificados de información basados en precios para subastas combinatorias de revelación mínima. En Padget et al., editor, Comercio Electrónico Mediado por Agentes IV, LNAI 2531, páginas 103-122. Springer-Verlag, 2002. [14] D. C. Parkes. \n\nSpringer-Verlag, 2002. [14] D. C. Parkes. Diseño de subasta con elicitación costosa de preferencias. En Ediciones Especiales de Annals of Mathematics and AI sobre los Fundamentos del Comercio Electrónico, Próximamente (2003). [15] D. C. Parkes y L. H. Ungar. Subastas combinatorias iterativas: Teoría y práctica. En Proc. 17ª Conferencia Nacional de Inteligencia Artificial (AAAI-00), páginas 74-81, 2000. [16] T. Sandholm, S. Suri, A. Gilpin y D. Levine. CABOB: Un algoritmo rápido y óptimo para subastas combinatorias. En Proc. de la 17ª Conferencia Internacional Conjunta sobre Inteligencia Artificial (IJCAI), páginas 1102-1108, 2001. [17] R. Schapire y L. Sellie. Aprendizaje de polinomios multivariados dispersos sobre un campo con consultas y contraejemplos. En Actas del Sexto Taller Anual de la ACM sobre Teoría Computacional del Aprendizaje, páginas 17-26. ACM Press, 1993. 187 [18] L. Valiant.\nACM Press, 1993. 187 [18] L. Valiant. Una teoría de lo aprendible. Comunicación. ACM, 27(11):1134-1142, noviembre de 1984. [19] M. Zinkevich, A. Blum y T. Sandholm. En la obtención de preferencias en tiempo polinómico con consultas de valor. En Proc. 4ta Conferencia ACM sobre Comercio Electrónico (ACM-EC), San Diego, CA, junio de 2003. 188 ",
            "candidates": [],
            "error": [
                [
                    "aprender",
                    "aprender",
                    "aprende",
                    "aprender"
                ]
            ]
        }
    }
}