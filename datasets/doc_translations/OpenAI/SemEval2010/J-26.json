{
    "id": "J-26",
    "original_text": "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal. The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings. This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties. Our model is a combinatorial variant of the classical principalagent problem from economic theory. In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him. Our focus is on cases where complex combinations of the efforts of the agents influence the outcome. The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game. We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open. Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1. INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations. The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants. Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey). A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another. In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants. This paper deals with the complementary lack of knowledge, that of hidden actions. In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly. Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract. An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information. While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort? Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory. How can we ensure that the right combination of allocations is actually made by the different servers? A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system. How can we ensure that the desired level of 18 collective security is obtained? Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal? The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible. This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14. The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort. In this paper we initiate a general study of handling combinations of agents rather than a single agent. While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions. In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal. The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility? In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent. This paper suggest models for and provides some interesting initial results about this combinatorial agency problem. We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research. We believe that this type of analysis may also find applications in regular economic activity. Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms). It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.) When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives. It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems. In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled. This calls for the study of the standard issues in economic theory in new complex settings. The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically. The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions. Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action. The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 . Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project. Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action. Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 . The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment. The main difficulty is that of determining the required Nash equilibrium point. In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure. It seems that this case already captures the main interesting ingredients3 . In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort. This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort. We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented. This subclass will provide many natural types of problem instances. In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort. The whole project succeeds as a deterministic Boolean function of the success of the subtasks. This Boolean function can now be represented in various ways. Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds. A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge. Effort by the edge increases this success probability. The complete project succeeds if there is a complete path of successful edges between a given source and sink. Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium. One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results. We believe that despite the large amount of work that appears here, we have only scratched the surface. In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results. In many cases, simulations reveal structure that we were not able to formally prove. We present here an informal overview of the issues that we studied, what we were able to do, and what we were not. The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper. Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance. Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success. For very low values, no agent will be contracted since even a single agents cost is higher than the principals value. For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment. What happens for intermediate principals values? We first observe that there is a finite number of transitions between different sets, as the principals project value increases. These transitions behave very differently for different functions. For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted. For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one. We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur. However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks. We do have several partial results, including a construction with an exponential number of transitions. During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal? We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity. More general analysis remains an open problem. Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems. In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function. We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model. We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard. The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks. In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one. We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free. Both phenomena can not occur in the non-strategic setting. 2. MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +). The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O). A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn). The principal has a certain value for each possible outcome, given by the function v : O → . As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value. Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome. Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O). Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai). The agents will be assumed to reach Nash equilibrium, if such equilibrium exists. The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium. In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium. A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists. Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12]. We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort). The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0). The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model. We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success). The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0). We assume that the principal can pay the agents but not fine them (known as the limited liability constraint). The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success. If the project fails, the agent gets 0. When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds. At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci. As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone. Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0). Definition 1. The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks. Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function. At this point we can already make some simple observations. The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi. Claim 1. Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.) As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case. This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium. Observation 1. The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1). In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk. The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) . We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A). The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium. Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}). We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A. A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs). In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci. The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability. Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases). Definition 2. The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare). When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c). Note that the POU is at least 1 for any technology. As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c). For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions. This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions. In a structured technology function, each individual succeeds or fails in his own task independently. The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks. Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents). Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort. In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 . Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ. We denote x = (x1, . . . , xn). The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit. An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player. The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 . A few simple examples should be in order here: 1. The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi). Thus the project succeeds only if all agents succeed in their tasks. This is shown graphically as a read-once network in Figure 1(a). If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m . E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2. The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi). Thus the project succeeds if at least one of the agents succeed in their tasks. This is shown graphically as a read-once network in Figure 1(b). If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3. The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions. In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k). Thus the project succeeds if in at least one clause all agents succeed in their tasks. This is shown graphically as a read-once network in Figure 2(a). If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents. Figure 1: Graphical representations of (a) AND and (b) OR technologies. Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4. The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions. In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k). Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks. This is shown graphically as a read-once network in Figure 2(b). If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5. The Majority technology: f(x) is 1 if a majority of the values xi are 1. Thus the project succeeds if most players succeed. The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz. In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3. ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players. I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort). A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents. Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA). As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ. OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1. Example 1. AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8. The principal has 3 possibilities: contracting with 0, 1, or 2 agents. Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3. Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal. The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6. This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally. In this case the principal will make both agents exert effort whenever v ≥ 4. Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3. It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below. Example 2. OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8. Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2. Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3. In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8. It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case. This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]). Lemma 1. For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases. Proof sketch: We look at all transition points in both cases. For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1. Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1. Thus, we can focus on the interval between the first and last transition points. Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment). We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point). As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted. Figure 3 shows the same phenomena for AND and OR technologies with 3 players. Theorem 1. For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents. Thus, the optimal contract corresponds to the maximum over a set of linear functions. Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents. In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}. As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal. This is true for both the agency and the non-strategic cases. As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below. For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case. The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case. Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )). Next we consider the OR technology and show that it exhibits all n transitions. Theorem 2. For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted). For v = vk, the principal is indifferent between contracting with k − 1 or k agents. Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents. We then show that for any k, vk < vk+1. As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case. This characterization is a direct corollary of a more general characterization given in [2]. While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze. Open Question 1. What is the POU for OR with n > 2 agents? Is it bounded by a constant for every n? We are only able to determine the POU of the OR technology for the case of two agents [2]. Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies. Observation 2. While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions? Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases. However, this is not true in general. In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions. We find that the conditions in the agency case are different than the ones in the non-strategic case. We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]). Lemma 2. For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case. Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case. Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively. By Lemma 1 the POU is obtained at a transition point. As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case. The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 . Substituting the transition point of the agency case into the POU expression yields the required expression. POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3). We are unable to characterize the transition behavior of the MAJORITY technology analytically. Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5. The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture. Conjecture 1. For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents. For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents. For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions. Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4. NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents. In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology. Definition 3. For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ). The korbit of t is the collection of sets of size exactly k in the orbit. Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit). Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1. We show that the picture in the agency case is very different. A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma. Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value. Proof. Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively. Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci). The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S). As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2). We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value. Next we show that the success probability is monotonic non-decreasing in the value. S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2). Finally we show that the expected payment is monotonic non-decreasing in the value. As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies. The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together. Theorem 3. Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs. Then for any value v, an optimal contract contracts with the same number of agents in each OR-component. Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section. We conjecture that a similar result holds for the OOA technology. Conjecture 2. In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths. Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted. We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents. If conjecture 2 is true, the same holds for the OOA technology. What can be said about the orbit size of a general non-anonymous technology? In case of identical costs, it is impossible for all subsets of agents to be on the orbit. This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1. Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least). Nevertheless, we next show that the orbit can have exponential size. A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be). Theorem 4. Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive. Let S be some admissible collection of k-size sets. For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj . We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j. For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version). This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S . We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal. This result is obtained by taking the derivative of u(S, v). Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t. S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof. We next show that there exist very large admissible collections. Lemma 4. For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ). Proof sketch: The proof is based on an error correcting code that corrects one bit. Such a code has a distance ≥ 3, thus admissible. It is known that there are such codes with Ω(2n /n) code words. To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible. Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n . Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit. Corollary 1. There exists a technology (t, c) with orbit of size Ω( 2n n √ n ). Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology. Open Question 2. Is there a Read Once network with exponential orbit? Is there a structured technology with exponential orbit? Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1. Open Question 3. How big can the orbit size of a seriesparallel network be? We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes. Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series). The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively. Lemma 5. Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T). Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well. Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R). Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6. The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)). Proof. Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1. By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2). By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2). As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma. For the full proof, see [2]. Lemma 7. Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series). Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1. By induction we get the following corollary. Corollary 2. Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj). Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents). In particular, this holds for AOO technology where each OR-component is anonymous. It would also be interesting to consider a disjunction of two Boolean functions. Open Question 4. Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)? We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well. If this is true, this will show that series-parallel networks have polynomial size orbit. 5. ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract. In this section we state these implications (for the proofs see [2]). We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ . In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that. In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract. Proposition 1. Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c). Proof. We prove the claims for the non-anonymous case, the proof for the anonymous case is similar. We first show how to construct the orbit of the technology (the same procedure apply in both cases). To construct the orbit we find all transition points and the sets that are in the orbit. The empty contract is always optimal for v = 0. Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability. We show how to calculate the next transition point and the next optimal contract. By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit). We calculate the next optimal contract by the following procedure. We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract. Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works. Clearly the above calculation is polynomial in the input size. Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated. We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point. Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time. By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio. A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5. Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof. Consider the following family of technologies. For some small > 0 and k = n/2 we define the success probability for a given set T as follows. If |T| < k, then t(T) = |T| · . If |T| > k, then t(T) = 1 − (n − |T|) · . For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative). If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one). We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function. Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract. Let t(E) denote the probability of success when each edge succeeds with probability δe. We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8]. Just a little effort will reveal that our problem is not easier: Theorem 6. The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions). Proof. We will show that an algorithm for this problem can be used to solve the network reliability problem. Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx. For the other edges, we let δe = ζe and γe = ζe/2. By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract. Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value). Let us denote βx = 1 − 2γx. The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value. Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}. Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E). In conclusion, computing the optimal contract in general is hard. These results suggest two natural research directions. The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time. The second avenue is to explore approximation algorithms for the optimal contract problem. A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial. Open Question 5. Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time? We can only handle the non-trivial level of AOO networks: Lemma 8. Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time. Acknowledgments. This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6. REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan. The Price of Purity and Free-Labor in Combinatorial Agency. In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan. Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker. Hidden-action in multi-hop routing. In EC05, pages 117-126, 2005. [4] B. Holmstrom. Moral Hazard in Teams. Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J. Green. Microeconomic Theory. Oxford University Press, 1995. [6] N. Nisan and A. Ronen. Algorithmic mechanism design. Games and Economic Behaviour, 35:166 - 196, 2001. A preliminary version appeared in STOC 1999. [7] C. Papadimitriou. Algorithms, Games, and the Internet. In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O. Ball. The complexity of counting cuts and of computing the probability that a graph is connected. SIAM J. Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann. Prediction Games. WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz. Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz. Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case. Forthcoming, GEB, 2005. [12] E. Winter. Incentives and Discrimination. American Economic Review, 94:764-773, 2004. 28",
    "original_translation": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28",
    "original_sentences": [
        "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
        "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
        "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
        "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
        "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
        "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
        "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
        "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
        "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
        "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
        "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
        "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
        "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
        "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
        "This paper deals with the complementary lack of knowledge, that of hidden actions.",
        "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
        "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
        "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
        "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
        "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
        "How can we ensure that the right combination of allocations is actually made by the different servers?",
        "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
        "How can we ensure that the desired level of 18 collective security is obtained?",
        "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
        "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
        "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
        "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
        "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
        "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
        "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
        "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
        "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
        "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
        "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
        "We believe that this type of analysis may also find applications in regular economic activity.",
        "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
        "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
        "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
        "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
        "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
        "This calls for the study of the standard issues in economic theory in new complex settings.",
        "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
        "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
        "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
        "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
        "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
        "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
        "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
        "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
        "The main difficulty is that of determining the required Nash equilibrium point.",
        "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
        "It seems that this case already captures the main interesting ingredients3 .",
        "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
        "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
        "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
        "This subclass will provide many natural types of problem instances.",
        "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
        "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
        "This Boolean function can now be represented in various ways.",
        "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
        "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
        "Effort by the edge increases this success probability.",
        "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
        "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
        "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
        "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
        "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
        "In many cases, simulations reveal structure that we were not able to formally prove.",
        "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
        "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
        "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
        "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
        "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
        "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
        "What happens for intermediate principals values?",
        "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
        "These transitions behave very differently for different functions.",
        "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
        "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
        "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
        "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
        "We do have several partial results, including a construction with an exponential number of transitions.",
        "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
        "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
        "More general analysis remains an open problem.",
        "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
        "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
        "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
        "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
        "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
        "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
        "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
        "Both phenomena can not occur in the non-strategic setting. 2.",
        "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
        "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
        "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
        "The principal has a certain value for each possible outcome, given by the function v : O → .",
        "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
        "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
        "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
        "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
        "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
        "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
        "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
        "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
        "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
        "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
        "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
        "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
        "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
        "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
        "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
        "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
        "If the project fails, the agent gets 0.",
        "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
        "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
        "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
        "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
        "Definition 1.",
        "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
        "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
        "At this point we can already make some simple observations.",
        "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
        "Claim 1.",
        "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
        "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
        "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
        "Observation 1.",
        "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
        "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
        "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
        "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
        "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
        "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
        "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
        "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
        "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
        "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
        "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
        "Definition 2.",
        "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
        "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
        "Note that the POU is at least 1 for any technology.",
        "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
        "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
        "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
        "In a structured technology function, each individual succeeds or fails in his own task independently.",
        "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
        "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
        "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
        "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
        "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
        "We denote x = (x1, . . . , xn).",
        "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
        "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
        "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
        "A few simple examples should be in order here: 1.",
        "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
        "Thus the project succeeds only if all agents succeed in their tasks.",
        "This is shown graphically as a read-once network in Figure 1(a).",
        "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
        "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
        "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
        "Thus the project succeeds if at least one of the agents succeed in their tasks.",
        "This is shown graphically as a read-once network in Figure 1(b).",
        "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
        "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
        "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
        "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
        "This is shown graphically as a read-once network in Figure 2(a).",
        "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
        "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
        "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
        "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
        "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
        "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
        "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
        "This is shown graphically as a read-once network in Figure 2(b).",
        "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
        "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
        "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
        "Thus the project succeeds if most players succeed.",
        "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
        "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
        "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
        "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
        "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
        "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
        "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
        "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
        "Example 1.",
        "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
        "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
        "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
        "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
        "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
        "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
        "In this case the principal will make both agents exert effort whenever v ≥ 4.",
        "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
        "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
        "Example 2.",
        "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
        "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
        "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
        "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
        "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
        "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
        "Lemma 1.",
        "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
        "Proof sketch: We look at all transition points in both cases.",
        "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
        "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
        "Thus, we can focus on the interval between the first and last transition points.",
        "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
        "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
        "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
        "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
        "Theorem 1.",
        "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
        "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
        "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
        "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
        "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
        "This is true for both the agency and the non-strategic cases.",
        "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
        "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
        "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
        "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
        "Next we consider the OR technology and show that it exhibits all n transitions.",
        "Theorem 2.",
        "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
        "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
        "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
        "We then show that for any k, vk < vk+1.",
        "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
        "This characterization is a direct corollary of a more general characterization given in [2].",
        "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
        "Open Question 1.",
        "What is the POU for OR with n > 2 agents?",
        "Is it bounded by a constant for every n?",
        "We are only able to determine the POU of the OR technology for the case of two agents [2].",
        "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
        "Observation 2.",
        "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
        "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
        "However, this is not true in general.",
        "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
        "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
        "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
        "Lemma 2.",
        "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
        "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
        "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
        "By Lemma 1 the POU is obtained at a transition point.",
        "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
        "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
        "Substituting the transition point of the agency case into the POU expression yields the required expression.",
        "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
        "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
        "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
        "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
        "Conjecture 1.",
        "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
        "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
        "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
        "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
        "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
        "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
        "Definition 3.",
        "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
        "The korbit of t is the collection of sets of size exactly k in the orbit.",
        "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
        "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
        "We show that the picture in the agency case is very different.",
        "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
        "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
        "Proof.",
        "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
        "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
        "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
        "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
        "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
        "Next we show that the success probability is monotonic non-decreasing in the value.",
        "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
        "Finally we show that the expected payment is monotonic non-decreasing in the value.",
        "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
        "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
        "Theorem 3.",
        "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
        "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
        "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
        "We conjecture that a similar result holds for the OOA technology.",
        "Conjecture 2.",
        "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
        "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
        "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
        "If conjecture 2 is true, the same holds for the OOA technology.",
        "What can be said about the orbit size of a general non-anonymous technology?",
        "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
        "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
        "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
        "Nevertheless, we next show that the orbit can have exponential size.",
        "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
        "Theorem 4.",
        "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
        "Let S be some admissible collection of k-size sets.",
        "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
        "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
        "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
        "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
        "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
        "This result is obtained by taking the derivative of u(S, v).",
        "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
        "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
        "We next show that there exist very large admissible collections.",
        "Lemma 4.",
        "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
        "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
        "Such a code has a distance ≥ 3, thus admissible.",
        "It is known that there are such codes with Ω(2n /n) code words.",
        "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
        "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
        "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
        "Corollary 1.",
        "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
        "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
        "Open Question 2.",
        "Is there a Read Once network with exponential orbit?",
        "Is there a structured technology with exponential orbit?",
        "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
        "Open Question 3.",
        "How big can the orbit size of a seriesparallel network be?",
        "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
        "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
        "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
        "Lemma 5.",
        "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
        "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
        "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
        "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
        "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
        "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
        "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
        "Proof.",
        "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
        "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
        "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
        "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
        "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
        "For the full proof, see [2].",
        "Lemma 7.",
        "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
        "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
        "By induction we get the following corollary.",
        "Corollary 2.",
        "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
        "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
        "In particular, this holds for AOO technology where each OR-component is anonymous.",
        "It would also be interesting to consider a disjunction of two Boolean functions.",
        "Open Question 4.",
        "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
        "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
        "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
        "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
        "In this section we state these implications (for the proofs see [2]).",
        "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
        "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
        "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
        "Proposition 1.",
        "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
        "Proof.",
        "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
        "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
        "To construct the orbit we find all transition points and the sets that are in the orbit.",
        "The empty contract is always optimal for v = 0.",
        "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
        "We show how to calculate the next transition point and the next optimal contract.",
        "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
        "We calculate the next optimal contract by the following procedure.",
        "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
        "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
        "Clearly the above calculation is polynomial in the input size.",
        "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
        "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
        "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
        "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
        "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
        "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
        "Consider the following family of technologies.",
        "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
        "If |T| < k, then t(T) = |T| · .",
        "If |T| > k, then t(T) = 1 − (n − |T|) · .",
        "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
        "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
        "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
        "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
        "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
        "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
        "Just a little effort will reveal that our problem is not easier: Theorem 6.",
        "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
        "Proof.",
        "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
        "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
        "For the other edges, we let δe = ζe and γe = ζe/2.",
        "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
        "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
        "Let us denote βx = 1 − 2γx.",
        "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
        "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
        "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
        "In conclusion, computing the optimal contract in general is hard.",
        "These results suggest two natural research directions.",
        "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
        "The second avenue is to explore approximation algorithms for the optimal contract problem.",
        "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
        "Open Question 5.",
        "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
        "We can only handle the non-trivial level of AOO networks: Lemma 8.",
        "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
        "Acknowledgments.",
        "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
        "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
        "The Price of Purity and Free-Labor in Combinatorial Agency.",
        "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
        "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
        "Hidden-action in multi-hop routing.",
        "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
        "Moral Hazard in Teams.",
        "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
        "Green.",
        "Microeconomic Theory.",
        "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
        "Algorithmic mechanism design.",
        "Games and Economic Behaviour, 35:166 - 196, 2001.",
        "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
        "Algorithms, Games, and the Internet.",
        "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
        "Ball.",
        "The complexity of counting cuts and of computing the probability that a graph is connected.",
        "SIAM J.",
        "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
        "Prediction Games.",
        "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
        "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
        "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
        "Forthcoming, GEB, 2005. [12] E. Winter.",
        "Incentives and Discrimination.",
        "American Economic Review, 94:764-773, 2004. 28"
    ],
    "translated_text_sentences": [
        "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta.",
        "El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales.",
        "Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes.",
        "Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica.",
        "En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él.",
        "Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado.",
        "El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido.",
        "Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas.",
        "Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1.",
        "INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones.",
        "El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes.",
        "De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente).",
        "Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro.",
        "En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes.",
        "Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas.",
        "En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta.",
        "Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal.",
        "Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información.",
        "Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo?",
        "Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física.",
        "¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores?",
        "Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema.",
        "¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva?",
        "Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal?",
        "La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible.",
        "Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5].",
        "La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido.",
        "En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente.",
        "Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes.",
        "En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal.",
        "¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta?",
        "En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente.",
        "Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria.",
        "Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones.",
        "Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular.",
        "Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas).",
        "A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas).",
        "Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados.",
        "También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados.",
        "En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica.",
        "Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos.",
        "El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística.",
        "La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes.",
        "Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente.",
        "El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo.",
        "La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto.",
        "Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción.",
        "Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash.",
        "El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado.",
        "La dificultad principal es la de determinar el punto de equilibrio de Nash requerido.",
        "Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso.",
        "Parece que este caso ya captura los ingredientes principales interesantes.",
        "En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse.",
        "Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo.",
        "Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta.",
        "Esta subclase proporcionará muchos tipos naturales de instancias de problemas.",
        "En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo.",
        "El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas.",
        "Esta función booleana ahora puede ser representada de varias formas.",
        "Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito.",
        "Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde.",
        "El esfuerzo en el límite aumenta la probabilidad de éxito.",
        "El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero.",
        "Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash.",
        "Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados.",
        "Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie.",
        "En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales.",
        "En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente.",
        "Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no.",
        "El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo.",
        "Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada.",
        "Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales.",
        "Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal.",
        "Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado.",
        "¿Qué sucede para valores intermedios de los principios?",
        "Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal.",
        "Estas transiciones se comportan de manera muy diferente para diferentes funciones.",
        "Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados.",
        "Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno.",
        "Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones.",
        "Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples.",
        "Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones.",
        "Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal?",
        "Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito.",
        "El análisis más general sigue siendo un problema abierto.",
        "Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza.",
        "En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad.",
        "Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra.",
        "También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil.",
        "El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo.",
        "En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro.",
        "También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito.",
        "Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2.",
        "MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +).",
        "Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O).",
        "Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn).",
        "El director tiene un valor específico para cada posible resultado, dado por la función v: O → .",
        "Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple.",
        "Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final.",
        "Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O).",
        "Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai).",
        "Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe.",
        "El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash.",
        "En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash.",
        "Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio.",
        "Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12].",
        "Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto).",
        "La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0).",
        "El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario.",
        "Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto).",
        "El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0).",
        "Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada).",
        "El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto.",
        "Si el proyecto falla, el agente recibe 0.",
        "Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación.",
        "En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci.",
        "Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona.",
        "Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0).",
        "Definición 1.",
        "La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea.",
        "Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva.",
        "En este punto ya podemos hacer algunas observaciones simples.",
        "La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi.",
        "Reclamo 1.",
        "Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas).",
        "Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso.",
        "Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado.",
        "Observación 1.",
        "Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1).",
        "En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea.",
        "La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i).",
        "Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A).",
        "El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio.",
        "Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}).",
        "Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A.",
        "Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos).",
        "En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci.",
        "La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad.",
        "Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico).",
        "Definición 2.",
        "El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social).",
        "Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c).",
        "Ten en cuenta que el POU es al menos 1 para cualquier tecnología.",
        "Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c).",
        "Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas.",
        "Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología.",
        "En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente.",
        "El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas.",
        "Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes).",
        "Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo.",
        "Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2.",
        "Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ.",
        "Denotamos x = (x1, . . . , xn).",
        "La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general.",
        "Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente.",
        "El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero.",
        "Unos cuantos ejemplos simples deberían estar en orden aquí: 1.",
        "La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi).",
        "Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas.",
        "Esto se muestra gráficamente como una red de lectura única en la Figura 1(a).",
        "Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m.",
        "Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2.",
        "La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi).",
        "Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas.",
        "Esto se muestra gráficamente como una red de lectura única en la Figura 1(b).",
        "Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2.",
        "La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones.",
        "En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k).",
        "Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas.",
        "Esto se muestra gráficamente como una red de lectura única en la Figura 2(a).",
        "Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
        "Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas.",
        "Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR.",
        "Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4.",
        "La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones.",
        "En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k).",
        "Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas.",
        "Esto se muestra gráficamente como una red de lectura única en la Figura 2(b).",
        "Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
        "Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5.",
        "La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1.",
        "Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito.",
        "La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz.",
        "En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc.",
        "ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores.",
        "Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo).",
        "Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes.",
        "De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA).",
        "En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ.",
        "Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1.",
        "Ejemplo 1.",
        "Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8.",
        "El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes.",
        "Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3.",
        "Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal.",
        "El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6.",
        "Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente.",
        "En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4.",
        "Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3.",
        "Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación.",
        "Ejemplo 2.",
        "Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8.",
        "Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2.",
        "Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3.",
        "En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8.",
        "Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia.",
        "No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]).",
        "Lema 1.",
        "Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos.",
        "Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos.",
        "Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1.",
        "De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1.",
        "Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición.",
        "Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento).",
        "Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición).",
        "Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado.",
        "La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores.",
        "Teorema 1.",
        "Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados.",
        "Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales.",
        "Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes.",
        "En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}.",
        "Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo.",
        "Esto es cierto tanto para los casos de agencia como para los casos no estratégicos.",
        "Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación.",
        "Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial.",
        "La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico.",
        "Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )).",
        "A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones.",
        "Teorema 2.",
        "Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados).",
        "Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes.",
        "Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes.",
        "Luego demostramos que para cualquier k, vk < vk+1.",
        "Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico.",
        "Esta caracterización es un corolario directo de una caracterización más general dada en [2].",
        "Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar.",
        "Pregunta abierta 1.",
        "¿Cuál es el POU para OR con n > 2 agentes?",
        "¿Está acotado por una constante para cada n?",
        "Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2].",
        "Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR.",
        "Observación 2.",
        "Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones?",
        "Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos.",
        "Sin embargo, esto no es cierto en general.",
        "En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones.",
        "Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico.",
        "Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]).",
        "Lema 2.",
        "Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia.",
        "Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico.",
        "Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente.",
        "Según el Lema 1, el POU se obtiene en un punto de transición.",
        "A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia.",
        "El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1.",
        "Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida.",
        "La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3).",
        "No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica.",
        "La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5.",
        "Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura.",
        "Conjetura 1.",
        "Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes.",
        "Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente.",
        "Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes.",
        "Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4.",
        "En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados.",
        "En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología.",
        "Definición 3.",
        "Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico).",
        "El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita.",
        "Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita).",
        "Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1.",
        "Mostramos que la situación en el caso de la agencia es muy diferente.",
        "Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema.",
        "Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor.",
        "Prueba.",
        "Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente.",
        "Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci).",
        "La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S).",
        "Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2).",
        "Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor.",
        "A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor.",
        "S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2).",
        "Finalmente demostramos que el pago esperado es monótono no decreciente en el valor.",
        "Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA).",
        "La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND.",
        "Teorema 3.",
        "Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas.",
        "Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR.",
        "Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección.",
        "Conjeturamos que un resultado similar se aplica a la tecnología OOA.",
        "Conjetura 2.",
        "En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados.",
        "Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen.",
        "No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes.",
        "Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA.",
        "¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima?",
        "En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita.",
        "Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1.",
        "Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague).",
        "Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial.",
        "Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar).",
        "Teorema 4.",
        "Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva.",
        "Sea S una colección admisible de conjuntos de tamaño k.",
        "Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj.",
        "Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j.",
        "Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa).",
        "Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S.",
        "Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal.",
        "Este resultado se obtiene tomando la derivada de u(S, v).",
        "Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t.",
        "S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba.",
        "A continuación mostramos que existen colecciones admisibles muy grandes.",
        "Lema 4.",
        "Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ).",
        "Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit.",
        "Un código con una distancia ≥ 3, por lo tanto es admisible.",
        "Se sabe que existen tales códigos con Ω(2n /n) palabras de código.",
        "Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible.",
        "Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n.",
        "Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial.",
        "Corolario 1.",
        "Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ).",
        "Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada.",
        "Abra la Pregunta 2.",
        "¿Existe una red de lectura única con órbita exponencial?",
        "¿Existe una tecnología estructurada con órbita exponencial?",
        "Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1.",
        "Abra la Pregunta 3.",
        "¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo?",
        "Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes.",
        "Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie).",
        "El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente.",
        "Lema 5.",
        "Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T).",
        "Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología.",
        "Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
        "Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
        "El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R).",
        "Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6.",
        "La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)).",
        "Prueba.",
        "Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1.",
        "Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
        "Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2).",
        "Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2).",
        "Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema.",
        "Para la prueba completa, ver [2].",
        "Lema 7.",
        "Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie).",
        "Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1.",
        "Por inducción obtenemos el siguiente corolario.",
        "Corolario 2.",
        "Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj).",
        "Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes).",
        "En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo.",
        "También sería interesante considerar una disyunción de dos funciones booleanas.",
        "Abre la Pregunta 4.",
        "¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)?",
        "Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción.",
        "Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5.",
        "Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato.",
        "En esta sección mencionamos estas implicaciones (para las pruebas ver [2]).",
        "Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗.",
        "En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso.",
        "En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo.",
        "Proposición 1.",
        "Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c).",
        "Prueba.",
        "Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar.",
        "Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos).",
        "Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita.",
        "El contrato vacío siempre es óptimo para v = 0.",
        "Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito.",
        "Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo.",
        "Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita).",
        "Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento.",
        "Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo.",
        "La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione.",
        "Claramente el cálculo anterior es polinómico en el tamaño de la entrada.",
        "Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v.",
        "Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición.",
        "Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico.",
        "Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima.",
        "Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5.",
        "Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración.",
        "Considera la siguiente familia de tecnologías.",
        "Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera.",
        "Si |T| < k, entonces t(T) = |T| · .",
        "Si |T| > k, entonces t(T) = 1 − (n − |T|) · .",
        "Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa).",
        "Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo).",
        "Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente.",
        "Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo.",
        "Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe.",
        "Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8].",
        "Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6.",
        "El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing).",
        "Prueba.",
        "Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red.",
        "Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx.",
        "Para los otros bordes, dejamos que δe = ζe y γe = ζe/2.",
        "Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo).",
        "Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor.",
        "Denotemos βx = 1 − 2γx.",
        "El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor.",
        "Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}.",
        "Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E).",
        "En conclusión, calcular el contrato óptimo en general es difícil.",
        "Estos resultados sugieren dos direcciones naturales de investigación.",
        "La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico.",
        "La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo.",
        "Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial.",
        "Abre la Pregunta 5.",
        "¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico?",
        "Solo podemos manejar el nivel no trivial de redes AOO: Lema 8.",
        "Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico.",
        "Agradecimientos.",
        "Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659.",
        "REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan.",
        "El precio de la pureza y el trabajo libre en la agencia combinatoria.",
        "En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan.",
        "Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker.",
        "Acción oculta en enrutamiento de múltiples saltos.",
        "En EC05, páginas 117-126, 2005. [4] B. Holmstrom.",
        "Riesgo moral en equipos.",
        "Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J.",
        "Verde.",
        "Teoría microeconómica.",
        "Oxford University Press, 1995. [6] N. Nisan y A. Ronen.",
        "Diseño mecanismos algorítmicos.",
        "Juegos y Comportamiento Económico, 35:166 - 196, 2001.",
        "Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou.",
        "Algoritmos, Juegos y el Internet.",
        "En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O.",
        "Pelota.",
        "La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado.",
        "Revista SIAM.",
        "Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann.",
        "Juegos de predicción.",
        "VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz.",
        "Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz.",
        "Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo.",
        "Próximamente, GEB, 2005. [12] E. Winter.",
        "Incentivos y discriminación.",
        "Revista Económica Americana, 94:764-773, 2004. 28"
    ],
    "error_count": 11,
    "keys": {
        "optimal set of contract": {
            "translated_key": "conjunto óptimo de contratos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an <br>optimal set of contract</br>s: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "The principals problem, our problem in this paper, is of designing an <br>optimal set of contract</br>s: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment."
            ],
            "translated_annotated_samples": [
                "El problema principal, nuestro problema en este documento, consiste en diseñar un <br>conjunto óptimo de contratos</br>: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un <br>conjunto óptimo de contratos</br>: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "contract optimal set": {
            "translated_key": "conjunto óptimo de contratos",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "classical principalagent": {
            "translated_key": "problema principal-agente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the <br>classical principalagent</br> problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "Our model is a combinatorial variant of the <br>classical principalagent</br> problem from economic theory."
            ],
            "translated_annotated_samples": [
                "Nuestro modelo es una variante combinatoria del clásico <br>problema principal-agente</br> de la teoría económica."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico <br>problema principal-agente</br> de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "quality of service": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is <br>quality of service</br> routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "An example that was discussed in [3] is <br>quality of service</br> routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information."
            ],
            "translated_annotated_samples": [
                "Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "service quality": {
            "translated_key": "calidad del servicio",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "combinatorial agency": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>combinatorial agency</br> [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this <br>combinatorial agency</br> problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that <br>combinatorial agency</br> models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in <br>combinatorial agency</br>.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "<br>combinatorial agency</br>, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "<br>combinatorial agency</br> [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "This paper suggest models for and provides some interesting initial results about this <br>combinatorial agency</br> problem.",
                "When the dependencies between the different subtasks are complex, we believe that <br>combinatorial agency</br> models can offer a foundation for the design of contracts with appropriate incentives.",
                "The Price of Purity and Free-Labor in <br>combinatorial agency</br>.",
                "<br>combinatorial agency</br>, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker."
            ],
            "translated_annotated_samples": [
                "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta.",
                "Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este <br>problema de agencia combinatoria</br>.",
                "Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los <br>modelos de agencia combinatoria</br> pueden ofrecer una base para el diseño de contratos con incentivos apropiados.",
                "El precio de la pureza y el trabajo libre en la <br>agencia combinatoria</br>.",
                "Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este <br>problema de agencia combinatoria</br>. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los <br>modelos de agencia combinatoria</br> pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la <br>agencia combinatoria</br>. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. ",
            "candidates": [],
            "error": [
                [
                    "problema de agencia combinatoria",
                    "modelos de agencia combinatoria",
                    "agencia combinatoria"
                ]
            ]
        },
        "nash equilibrium": {
            "translated_key": "equilibrio de Nash",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required <br>nash equilibrium</br> point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a <br>nash equilibrium</br> point to the agents, thus focusing on the best <br>nash equilibrium</br>.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-<br>nash equilibrium</br> between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach <br>nash equilibrium</br>, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best <br>nash equilibrium</br>.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst <br>nash equilibrium</br>, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "The main difficulty is that of determining the required <br>nash equilibrium</br> point.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a <br>nash equilibrium</br> point to the agents, thus focusing on the best <br>nash equilibrium</br>.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-<br>nash equilibrium</br> between the agents rather than a pure one.",
                "The agents will be assumed to reach <br>nash equilibrium</br>, if such equilibrium exists.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best <br>nash equilibrium</br>."
            ],
            "translated_annotated_samples": [
                "La dificultad principal es la de determinar el punto de <br>equilibrio de Nash</br> requerido.",
                "Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de <br>equilibrio de Nash</br> a los agentes, centrándose así en el mejor <br>equilibrio de Nash</br>.",
                "En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un <br>equilibrio de Nash</br> mixto entre los agentes en lugar de uno puro.",
                "Los agentes se asumirán que alcanzan el <br>equilibrio de Nash</br>, si dicho equilibrio existe.",
                "En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor <br>equilibrio de Nash</br>."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de <br>equilibrio de Nash</br> requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de <br>equilibrio de Nash</br> a los agentes, centrándose así en el mejor <br>equilibrio de Nash</br>. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un <br>equilibrio de Nash</br> mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el <br>equilibrio de Nash</br>, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor <br>equilibrio de Nash</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "contractible action": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with <br>contractible action</br>s or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with <br>contractible action</br>s or the principals first-best solution. a read-once network, the problem becomes #P-hard."
            ],
            "translated_annotated_samples": [
                "También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "k-orbit": {
            "translated_key": "k-órbita",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the <br>k-orbit</br> of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "Observe that in the non-strategic case the <br>k-orbit</br> of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit)."
            ],
            "translated_annotated_samples": [
                "Observe que en el caso no estratégico, la <br>k-órbita</br> de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita)."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la <br>k-órbita</br> de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "anonymous technology": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any <br>anonymous technology</br> that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any <br>anonymous technology</br> that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-<br>anonymous technology</br>?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an <br>anonymous technology</br>, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an <br>anonymous technology</br>, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "We are able to determine the POU for any <br>anonymous technology</br> that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "For any <br>anonymous technology</br> that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "What can be said about the orbit size of a general non-<br>anonymous technology</br>?",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an <br>anonymous technology</br>, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Given a Read Once AND-of-OR network such that each OR-component is an <br>anonymous technology</br>, the optimal contract problem can be solved in polynomial time."
            ],
            "translated_annotated_samples": [
                "Somos capaces de determinar el POU para cualquier <br>tecnología anónima</br> que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]).",
                "Para cualquier <br>tecnología anónima</br> que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia.",
                "¿Qué se puede decir sobre el tamaño de la órbita de una <br>tecnología general no anónima</br>?",
                "Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una <br>tecnología anónima</br>, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c).",
                "Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una <br>tecnología anónima</br>, el problema del contrato óptimo puede resolverse en tiempo polinómico."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier <br>tecnología anónima</br> que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier <br>tecnología anónima</br> que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una <br>tecnología general no anónima</br>? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una <br>tecnología anónima</br>, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una <br>tecnología anónima</br>, el problema del contrato óptimo puede resolverse en tiempo polinómico. ",
            "candidates": [],
            "error": [
                [
                    "tecnología anónima",
                    "tecnología anónima",
                    "tecnología general no anónima",
                    "tecnología anónima",
                    "tecnología anónima"
                ]
            ]
        },
        "series-parallel network": {
            "translated_key": "redes en serie-paralelo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that <br>series-parallel network</br>s have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of <br>series-parallel network</br>s, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once <br>series-parallel network</br>s be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "If this is true, this will show that <br>series-parallel network</br>s have polynomial size orbit. 5.",
                "A possible candidate for the first direction is the family of <br>series-parallel network</br>s, for which the network reliability problem (computing the value of t) is polynomial.",
                "Can the optimal contract problem for Read Once <br>series-parallel network</br>s be solved in polynomial time?"
            ],
            "translated_annotated_samples": [
                "Si esto es cierto, esto demostrará que las <br>redes en serie-paralelo</br> tienen un tamaño de órbita polinomial. 5.",
                "Un posible candidato para la primera dirección es la familia de <br>redes en serie-paralelo</br>, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial.",
                "¿Se puede resolver el problema del contrato óptimo para <br>redes en serie-paralelo</br> de Leer una Vez en tiempo polinómico?"
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las <br>redes en serie-paralelo</br> tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de <br>redes en serie-paralelo</br>, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para <br>redes en serie-paralelo</br> de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "price of unaccountability": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the <br>price of unaccountability</br>: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the <br>price of unaccountability</br>.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The <br>price of unaccountability</br> POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the <br>price of unaccountability</br> for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst <br>price of unaccountability</br> in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the <br>price of unaccountability</br> here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the <br>price of unaccountability</br> POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the <br>price of unaccountability</br> is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the <br>price of unaccountability</br> for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The <br>price of unaccountability</br> POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the <br>price of unaccountability</br> in polynomial time.",
                "By Lemma 1 the <br>price of unaccountability</br> POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "During the previous analysis we also study what we term the <br>price of unaccountability</br>: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the <br>price of unaccountability</br>.",
                "The <br>price of unaccountability</br> POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the <br>price of unaccountability</br> for technology (t, c).",
                "It turns out that this is the worst <br>price of unaccountability</br> in this example, and it is obtained exactly at the transition point of the agency case, as we show below."
            ],
            "translated_annotated_samples": [
                "Durante el análisis previo también estudiamos lo que denominamos el <br>precio de la falta de responsabilidad</br>: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal?",
                "La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado <br>el precio de la falta de responsabilidad</br>.",
                "El <br>precio de la falta de responsabilidad</br> POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social).",
                "Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el <br>precio de la falta de responsabilidad</br> de la tecnología (t, c).",
                "Resulta que este es el peor <br>precio de falta de responsabilidad</br> en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza incentivos apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con incentivos apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el <br>precio de la falta de responsabilidad</br>: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado <br>el precio de la falta de responsabilidad</br>. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El <br>precio de la falta de responsabilidad</br> POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el <br>precio de la falta de responsabilidad</br> de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor <br>precio de falta de responsabilidad</br> en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. ",
            "candidates": [],
            "error": [
                [
                    "precio de la falta de responsabilidad",
                    "el precio de la falta de responsabilidad",
                    "precio de la falta de responsabilidad",
                    "precio de la falta de responsabilidad",
                    "precio de falta de responsabilidad"
                ]
            ]
        },
        "unaccountability price": {
            "translated_key": "precio sin responsabilidad",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "agency theory": {
            "translated_key": "teoría de la agencia",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "principal-agent model": {
            "translated_key": "modelo principal-agente",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "incentive": {
            "translated_key": "incentivos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research concerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from economic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of contracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: Economics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, Economics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish economic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate <br>incentive</br>s to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-contractible - meaning that it can not be formally used in a legal contract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples concerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in economic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many contexts in classical economic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed contract, in which the payments are contingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which conditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, conjectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular economic activity.",
                "Consider for example a firm that sub-contracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-contractor (e.g., in cases of public-relations activities, consulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate <br>incentive</br>s.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of economic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in economic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a contract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the contract cannot make the payments directly contingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of contracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of contracts: i.e. contracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be contracted to exert effort.",
                "This model is still pretty abstract, and every problem description contains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then consider a more concrete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example considers a communication network, where each agent controls a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be contracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us consider the set of contracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be contracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be contracted since the marginal contribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be contracted, while for higher values all agents will be contracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of contracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a construction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal contracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal contract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal contract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with contractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal contract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a contractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only consider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome.",
                "Thus the contract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability constraint).",
                "The contract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal contribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his contract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the contracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best contracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal contracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal contract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal contract in the agency case and let S∗ ns(v) denote an optimal contract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are constants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical conjunction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of conjunctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being controlled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical conjunction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal contract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are contracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: contracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal.",
                "The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be contrasted with the non-strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now contracting with one agent is better than contracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the second one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 contracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are contracted or none, while in the second case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to contract with no agent, for v > v∗ it is optimal to contract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal contract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between contracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, contracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we consider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between contracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between contracting with k − 1 agents, and contracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of contracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient condition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a constant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the conditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of contracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal contract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the contracted set of agents and not only about the number of contracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal contract for some v. These sets construct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal contract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal contracts, the success probability of the optimal contracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal contracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We conclude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a conjunction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal contract contracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We conjecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal contract is constructed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are contracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If conjecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is constructive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal contribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal contribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The construction of t(Z) ensures this since the marginal contribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we construct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can construct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to construct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a conjunction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal contract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal contract for f = g V h on v. Then, T is an optimal contract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from contracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal contribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the second term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal contract for h on v · tg(R).",
                "Similarly, we show that R is an optimal contract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal contract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal contract for f on v1, and let S2 = T2 ∪R2 be the optimal contract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in contradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a contradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to consider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We conjecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best contract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first consider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then consider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal contract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal contract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to construct the orbit of the technology (the same procedure apply in both cases).",
                "To construct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty contract is always optimal for v = 0.",
                "Assume that we have calculated the optimal contracts and the transition points up to some transition point v for which S is an optimal contract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal contract.",
                "By Lemma 3 the next contract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal contract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between contracting with T and contracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal contracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal contract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal contract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal contract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal contract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal contract for t ˆT is ˆT (for the contract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal contract (as any of the sets that it has not queried about might be the optimal one).",
                "We conclude that ` n n/2 ´ − 1 queries are needed to determine the optimal contract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be contracted in an optimal contract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal contract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal contract only for very large values of v, after all other agents are contracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal contract of G , can be found using binary search over the algorithm that supposedly finds the optimal contract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal contract we are also able to compute the value of t(E).",
                "In conclusion, computing the optimal contract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal contracts can be computed in polynomial time.",
                "The second avenue is to explore approximation algorithms for the optimal contract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal contract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal contract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of Economics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microeconomic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and Economic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is connected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American Economic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "In particular, the field of algorithmic mechanism design [6] uses appropriate <br>incentive</br>s to extract the private information from the participants.",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of contracts with appropriate <br>incentive</br>s."
            ],
            "translated_annotated_samples": [
                "En particular, el campo del diseño algorítmico de mecanismos utiliza <br>incentivos</br> apropiados para extraer la información privada de los participantes.",
                "Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con <br>incentivos</br> apropiados."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo egoísta. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la teoría económica. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de contratos, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: Economía; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, Economía, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes intereses económicos egoístas de los distintos participantes. De hecho, en los últimos años se ha realizado mucho trabajo abordando este problema utilizando nociones de teoría de juegos (ver [7] para una encuesta influyente). Una parte significativa de la dificultad proviene de asimetrías subyacentes de información: un participante puede no saber todo lo que es conocido o hecho por otro. En particular, el campo del diseño algorítmico de mecanismos utiliza <br>incentivos</br> apropiados para extraer la información privada de los participantes. Este documento trata sobre la falta complementaria de conocimiento, la de las acciones ocultas. En muchos casos, los comportamientos reales - acciones - de los diferentes participantes están ocultos para los demás y solo influyen en el resultado final de manera indirecta. Lo oculto aquí abarca una amplia gama de situaciones que incluyen aspectos no precisamente medibles, costosos de determinar o incluso no contractualizables, lo que significa que no se pueden utilizar formalmente en un contrato legal. Un ejemplo que se discutió en [3] es el enrutamiento de Calidad de Servicio en una red: cada enlace intermedio o enrutador puede ejercer una cantidad diferente de esfuerzo (prioridad, ancho de banda, ...) al intentar reenviar un paquete de información. Si bien el resultado final de si un paquete llegó a su destino es claramente visible, rara vez es factible monitorear la cantidad exacta de esfuerzo ejercido por cada enlace intermedio. ¿Cómo podemos asegurarnos de que realmente ejerzan la cantidad apropiada de esfuerzo? Muchos otros problemas de asignación de recursos complejos presentan acciones ocultas similares, por ejemplo, una tarea que se ejecuta en un conjunto de servidores compartidos puede ser asignada, por cada servidor, un porcentaje desconocido de la potencia de procesamiento de las CPUs o de la memoria física. ¿Cómo podemos asegurarnos de que la combinación correcta de asignaciones sea realizada realmente por los diferentes servidores? Una clase relacionada de ejemplos se refiere a problemas de seguridad: cada enlace en un sistema complejo puede ejercer diferentes niveles de esfuerzo para proteger alguna propiedad de seguridad deseada del sistema. ¿Cómo podemos asegurar que se logre el nivel deseado de seguridad colectiva? Nuestro enfoque a este problema se basa en el bien estudiado problema principal-agente en la teoría económica: ¿Cómo puede un principal motivar a un agente racional a realizar un esfuerzo costoso hacia el bienestar del principal? La clave del modelo es que la acción de los agentes (es decir, si hacen un esfuerzo o no) es invisible para el principal y solo el resultado final, que es probabilístico y también influenciado por otros factores, es visible. Este problema está bien estudiado en muchos contextos en la teoría económica clásica y remitimos a los lectores a textos introductorios sobre teoría económica como el Capítulo 14 de [5]. La solución se basa en la observación de que un contrato adecuadamente diseñado, en el cual los pagos dependen del resultado final, puede influir en un agente racional para que realice el esfuerzo requerido. En este artículo iniciamos un estudio general sobre el manejo de combinaciones de agentes en lugar de un solo agente. Si bien se ha realizado mucho trabajo en motivar equipos de agentes [4], nuestro énfasis está en lidiar con la compleja estructura combinatoria de las dependencias entre las acciones de los agentes. En el caso general, cada combinación de esfuerzos ejercidos por los n diferentes agentes puede resultar en una ganancia esperada diferente para el principal. ¿La pregunta general es qué pagos condicionales debería ofrecer el principal a qué agentes para maximizar su utilidad neta? En nuestro entorno y a diferencia de trabajos anteriores (ver, por ejemplo, [12]), el principal desafío es determinar la cantidad óptima de esfuerzo deseada de cada agente. Este artículo sugiere modelos y proporciona algunos resultados iniciales interesantes sobre este problema de agencia combinatoria. Creemos que apenas hemos arañado la superficie y dejamos muchas preguntas abiertas, conjeturas y direcciones para futuras investigaciones. Creemos que este tipo de análisis también puede encontrar aplicaciones en la actividad económica regular. Consideremos, por ejemplo, una empresa que subcontrata una familia de tareas relacionadas a muchos individuos (o a otras empresas). A menudo no será posible monitorear exactamente el nivel de esfuerzo real de cada subcontratista (por ejemplo, en casos de actividades de relaciones públicas, actividades de consultoría o cualquier actividad que requiera cooperación entre diferentes subcontratistas). Cuando las dependencias entre las diferentes subtareas son complejas, creemos que los modelos de agencia combinatoria pueden ofrecer una base para el diseño de contratos con <br>incentivos</br> apropiados. También puede ser útil ver nuestro trabajo como parte de una agenda de investigación general que surge del hecho de que todos los tipos de actividad económica están siendo manejados cada vez más con la ayuda de sistemas informáticos sofisticados. En general, en entornos computarizados como estos, es natural que ocurran escenarios complejos que involucren múltiples agentes y bienes, los cuales deben ser manejados de forma algorítmica. Esto requiere el estudio de los problemas estándar en la teoría económica en nuevos entornos complejos. El problema principal-agente es un ejemplo primordial donde configuraciones tan complejas introducen nuevos desafíos. 1.2 Nuestros Modelos Comenzamos presentando un modelo general: en este modelo, cada uno de los n agentes tiene un conjunto de posibles acciones, la combinación de acciones de los jugadores resulta en algún resultado, donde esto sucede de manera probabilística. La parte principal de la especificación de un problema en este modelo es una función que especifica esta distribución para cada n-tupla de acciones de agentes. Además, el problema especifica la utilidad del principal para cada resultado posible, y para cada agente, el costo de cada acción posible del agente. El director motiva a los agentes ofreciéndoles a cada uno de ellos un contrato que especifica un pago por cada posible resultado del proyecto completo. La clave aquí es que las acciones de los jugadores no son observables y, por lo tanto, el contrato no puede hacer que los pagos dependan directamente de las acciones de los jugadores, sino solo del resultado de todo el proyecto. Dado un conjunto de contratos, los agentes optimizarán cada uno su propia utilidad: es decir, elegirán la acción que maximice su pago esperado menos el costo de su acción. Dado que el resultado depende de las acciones de todos los jugadores juntos, los agentes se colocan en un juego y se asume que alcanzarán un equilibrio de Nash. El problema principal, nuestro problema en este documento, consiste en diseñar un conjunto óptimo de contratos: es decir, contratos que maximicen su utilidad esperada del resultado, menos su pago total esperado. La dificultad principal es la de determinar el punto de equilibrio de Nash requerido. Para centrarse en los problemas principales, el resto del documento trata el caso binario básico: cada agente tiene solo dos posibles acciones, esforzarse y escaquearse, y solo hay dos posibles resultados, éxito y fracaso. Parece que este caso ya captura los ingredientes principales interesantes. En este caso, el problema de cada agente se reduce a si debe o no esforzarse, y el problema del principal se reduce a qué agentes deben ser contratados para esforzarse. Este modelo sigue siendo bastante abstracto, y cada descripción del problema contiene una tabla completa que especifica la probabilidad de éxito para cada subconjunto de agentes que hacen un esfuerzo. Luego consideramos un modelo más concreto que se refiere a una subclase de instancias de problemas donde esta tabla de tamaño exponencial se representa de manera sucinta. Esta subclase proporcionará muchos tipos naturales de instancias de problemas. En esta subclase, cada agente realiza una subtarea que tiene éxito con una baja probabilidad γ si el agente no hace esfuerzo y con una probabilidad más alta δ > γ si el agente hace esfuerzo. El proyecto completo tiene éxito como una función booleana determinista del éxito de las subtareas. Esta función booleana ahora puede ser representada de varias formas. Dos ejemplos básicos son la función Y en la que el proyecto tiene éxito solo si todas las subtareas tienen éxito, y la función O que tiene éxito si alguna de las subtareas tiene éxito. Un ejemplo más complejo considera una red de comunicación, donde cada agente controla un único borde, y el éxito de la subtarea implica que un mensaje sea reenviado por ese borde. El esfuerzo en el límite aumenta la probabilidad de éxito. El proyecto completo tiene éxito si hay un camino completo de aristas exitosas entre una fuente dada y un sumidero. Las definiciones completas de los modelos aparecen en la Sección 2. 1.3 Nuestros Resultados. Uno podría pensar en un modelo diferente en el que los agentes tengan utilidad intrínseca del resultado y los pagos no sean necesarios, como en [10, 11]. En este artículo, nuestra filosofía es que el principal puede sugerir un punto de equilibrio de Nash a los agentes, centrándose así en el mejor equilibrio de Nash. Uno puede estudiar alternativamente el equilibrio del peor caso como en [12], o intentar modelar algún tipo de juego extensivo entre los agentes, como en [9, 10, 11]. Sin embargo, algunas de las preguntas más avanzadas que planteamos para este caso pueden ser vistas como instancias del modelo general. Abordamos una serie de preguntas y demostramos un gran número de resultados. Creemos que a pesar de la gran cantidad de trabajo que aparece aquí, apenas hemos arañado la superficie. En muchos casos no pudimos lograr los teoremas de caracterización general que deseábamos y tuvimos que conformarnos con analizar casos especiales o demostrar resultados parciales. En muchos casos, las simulaciones revelan estructuras que no pudimos demostrar formalmente. Presentamos aquí un resumen informal de los temas que estudiamos, lo que pudimos hacer y lo que no. El tratamiento completo de la mayoría de nuestros resultados solo aparece en la versión extendida [2], y solo algunos son discutidos, a menudo con resultados de simulación asociados, en el cuerpo del artículo. Nuestro primer objeto de estudio es la estructura de la clase de conjuntos de agentes que pueden ser contratados para una instancia de problema dada. Fijemos una función dada que describe las probabilidades de éxito, fijemos los costos de los agentes y consideremos el conjunto de agentes contratados para diferentes valores del valor asociado de éxito de los principales. Para valores muy bajos, ningún agente será contratado ya que incluso el costo de un solo agente es mayor que el valor del principal. Para valores muy altos, todos los agentes siempre serán contratados ya que la contribución marginal de un agente multiplicada por el valor de los principios superará cualquier pago asociado. ¿Qué sucede para valores intermedios de los principios? Primero observamos que hay un número finito de transiciones entre diferentes conjuntos, a medida que aumenta el valor del proyecto principal. Estas transiciones se comportan de manera muy diferente para diferentes funciones. Por ejemplo, demostramos que para la función AND solo ocurre una transición: para valores lo suficientemente bajos, ningún agente será contratado, mientras que para valores más altos todos los agentes serán contratados; no hay un rango intermedio en el que solo algunos agentes sean contratados. Para la función OR, la situación es opuesta: a medida que el valor de los principales aumenta, el conjunto de agentes contratados aumenta uno por uno. Somos capaces de caracterizar completamente los tipos de funciones para los cuales ocurren estos dos tipos extremos de comportamiento de transiciones. Sin embargo, la estructura de estas transiciones en general parece bastante compleja, y no pudimos analizarlas completamente incluso en casos simples como la función de Mayoría (el proyecto tiene éxito si la mayoría de las subtareas tiene éxito) o redes muy simples. Tenemos varios resultados parciales, incluyendo una construcción con un número exponencial de transiciones. Durante el análisis previo también estudiamos lo que denominamos el precio de la falta de responsabilidad: ¿Cuánto es la utilidad social lograda bajo los contratos óptimos peor que lo que se podría lograr en el caso no estratégico, donde las acciones socialmente óptimas son simplemente dictadas por el principal? Somos capaces de analizar completamente este precio para la función Y, donde se muestra que tiende a infinito a medida que el número de agentes tiende a infinito. El análisis más general sigue siendo un problema abierto. Nuestro análisis de estas preguntas arroja luz sobre la dificultad de los diversos problemas algorítmicos asociados a la naturaleza. En particular, observamos que el contrato óptimo se puede encontrar en tiempo polinómico en la representación explícita de la función de probabilidad. Demostramos un límite inferior que muestra que el contrato óptimo no puede encontrarse en un número de consultas que sea polinomial solo en el número de agentes, en un modelo general de caja negra. También demostramos que cuando la función de probabilidad se representa de manera sucinta como una red de lectura única, el problema se vuelve #P-difícil. El estado de algunas preguntas algorítmicas sigue abierto, en particular la de encontrar el contrato óptimo para tecnologías definidas por redes serie-paralelo. En un artículo de seguimiento [1] nos ocupamos de los equilibrios en estrategias mixtas y demostramos que el principal puede beneficiarse al inducir un equilibrio de Nash mixto entre los agentes en lugar de uno puro. También mostramos casos en los que el principal puede beneficiarse al pedir a los agentes que reduzcan su nivel de esfuerzo, incluso cuando este es gratuito. Ambos fenómenos no pueden ocurrir en un entorno no estratégico. 2. MODELO Y PRELIMINARES 2.1 El Contexto General Un director emplea un conjunto de agentes N de tamaño n. Cada agente i ∈ N tiene un posible conjunto de acciones Ai, y un costo (esfuerzo) ci(ai) ≥ 0 para cada acción posible ai ∈ Ai (ci : Ai → +). Las acciones de todos los jugadores determinan, de manera probabilística, un resultado contractible o ∈ O, de acuerdo con una función de éxito t: A1×, . . . × An → Δ(O) (donde Δ(O) denota el conjunto de distribuciones de probabilidad en O). Una tecnología es un par, (t, c), de una función de éxito, t, y funciones de costo, c = (c1, c2, . . . , cn). El director tiene un valor específico para cada posible resultado, dado por la función v: O → . Dado que solo consideraremos jugadores neutrales al riesgo en este documento, también trataremos v como una función en Δ(O), tomando el valor esperado simple. Las acciones de los jugadores son invisibles, pero el resultado final es visible para él y para otros (en particular la corte), y puede diseñar contratos ejecutables basados en el resultado final. Por lo tanto, el contrato para el agente i es una función (pago) pi: O → ; nuevamente, también veremos pi como una función en Δ(O). Dado este escenario, los agentes han sido colocados en un juego, donde la utilidad del agente i bajo el vector de acciones a = (a1, . . . , an) está dada por ui(a) = pi(t(a))−ci(ai). Los agentes se asumirán que alcanzan el equilibrio de Nash, si dicho equilibrio existe. El problema principal (que es nuestro problema en este documento) es cómo diseñar los contratos pi para maximizar su propia utilidad esperada u(a) = v(t(a)) − P i pi(t(a)), donde las acciones a1, . . . , an están en equilibrio de Nash. En el caso de múltiples equilibrios de Nash permitimos que el principal elija el equilibrio, enfocándonos así en el mejor equilibrio de Nash. Una variante, que es similar en espíritu a la implementación fuerte en el diseño de mecanismos sería tomar el peor equilibrio de Nash, o incluso, aún más fuerte, requerir que solo exista un equilibrio. Finalmente, el bienestar social para un a ∈ A es u(a) + Σ i∈N ui(a) = v(t(a)) − Σ i∈N ci(ai). 2.2 El Modelo de Acción Binaria con Resultados Binarios Deseamos concentrarnos en las complejidades introducidas por la estructura combinatoria de la función de éxito t, nos restringimos a un escenario más simple que parece centrarse más claramente en la estructura de t. Un modelo similar fue utilizado en [12]. Primero restringimos los espacios de acción para que tengan solo dos estados (acción binaria): 0 (esfuerzo bajo) y 1 (esfuerzo alto). La función de costo del agente i es ahora solo un escalar ci > 0 que denota el costo de ejercer un esfuerzo alto (donde el esfuerzo bajo tiene un costo de 0). El vector de costos es c = (c1, c2, . . . , cn). El caso de aversión al riesgo sería obviamente un segundo paso natural en la investigación de este modelo, como ha sido para escenarios no combinatorios, y usamos la notación (t, c) para denotar una tecnología en un modelo de resultado binario. Luego restringimos el espacio de resultados para tener solo dos estados (resultado binario): 0 (fracaso del proyecto) y 1 (éxito del proyecto). El valor principal para un proyecto exitoso se da por un escalar v > 0 (donde el valor del fracaso del proyecto es 0). Suponemos que el principal puede pagar a los agentes pero no multarlos (conocido como la restricción de responsabilidad limitada). El contrato para el agente i se da ahora por un valor escalar pi ≥ 0 que denota el pago que i recibe en caso de éxito del proyecto. Si el proyecto falla, el agente recibe 0. Cuando la acción de menor costo tiene un costo de cero (como asumimos), esto implica inmediatamente que se cumple la restricción de participación. En este punto, la función de éxito t se convierte en una función t: {0, 1}n → [0, 1], donde t(a1, . . . , an) denota la probabilidad de éxito del proyecto, donde los jugadores con ai = 0 no hacen esfuerzo ni incurren en costos, y los jugadores con ai = 1 sí hacen esfuerzo e incurren en un costo de ci. Dado que deseamos concentrarnos en motivar a los agentes en lugar de en la coordinación entre ellos, asumimos que un mayor esfuerzo por parte de un agente siempre conduce a una mejor probabilidad de éxito, es decir, que la función de éxito t es estrictamente monótona. Formalmente, si denotamos por a−i ∈ A−i el vector (n − 1)dimensional de las acciones de todos los agentes excluyendo al agente i, es decir, a−i = (a1, . . . , ai−1, ai+1, . . . , an), entonces una función de éxito debe cumplir: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i). Además, asumimos que t(a) > 0 para cualquier a ∈ A (o equivalentemente, t(0, 0, . . . , 0) > 0). Definición 1. La contribución marginal del agente i, denotada por Δi, es la diferencia entre la probabilidad de éxito cuando i hace un esfuerzo y cuando se escaquea. Δi(a−i) = t(1, a−i) − t(0, a−i). Ten en cuenta que dado que t es monótona, Δi es una función estrictamente positiva. En este punto ya podemos hacer algunas observaciones simples. La mejor acción, ai ∈ Ai, del agente i ahora puede determinarse fácilmente como una función de lo que hacen los demás, a−i ∈ A−i, y su contrato pi. Reclamo 1. Dado un perfil de acciones a−i, la mejor estrategia del agente es ai = 1 si pi ≥ ci Δi(a−i), y ai = 0 si pi ≤ ci Δi(a−i). (En caso de igualdad, el agente es indiferente entre las dos alternativas). Dado que pi ≥ ci Δi(a−i) si y solo si ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), la mejor estrategia es elegir ai = 1 en este caso. Esto nos permite especificar los contratos que son óptimos para el principal, para inducir un equilibrio dado. Observación 1. Los mejores contratos (para el principal) que inducen a a ∈ A como un equilibrio son pi = 0 para el agente i que no realiza esfuerzo (ai = 0), y pi = ci Δi(a−i) para el agente i que realiza esfuerzo (ai = 1). En este caso, la utilidad esperada del agente i que se esfuerza es ci · t(1,a−i) Δi(a−i) − 1, y 0 para un agente que se escaquea. La utilidad esperada del principal se da por u(a, v) = (v−P)·t(a), donde P es el pago total en caso de éxito, dado por P = Σi|ai=1 ci Δi(a−i). Decimos que el principal contrata con el agente i si pi > 0 (y ai = 1 en el equilibrio a ∈ A). El objetivo principal es maximizar su utilidad dada su valor v, es decir, determinar el perfil de acciones a∗ ∈ A que brinde el mayor valor de u(a, v) en equilibrio. Elegir un ∈ A corresponde a elegir un conjunto S de agentes que ejercen esfuerzo (S = {i|ai = 1}). Llamamos al conjunto de agentes S∗ con los que el principal contrata en a∗ (S∗ = {i|a∗ i = 1}) un contrato óptimo para el principal con valor v. A veces abusamos de la notación y denotamos t(S) en lugar de t(a), cuando S es exactamente el conjunto de agentes que ejercen esfuerzo en a ∈ A. Un criterio natural para medir esta decisión es el caso no estratégico, es decir, cuando los agentes no necesitan estar motivados, sino que son controlados directamente por el principal (quien también asume sus costos). En este caso, el director simplemente elegirá el perfil a ∈ A que optimice el bienestar social (eficiencia global), t(a) · v − Σi|ai=1 ci. La peor proporción entre el bienestar social en este caso no estratégico y el bienestar social para el perfil a ∈ A elegido por el principal en el caso de la agencia, puede ser denominado el precio de la falta de responsabilidad. Dada una tecnología (t, c), sea S∗ (v) el contrato óptimo en el caso de agencia y sea S∗ ns(v) el contrato óptimo en el caso no estratégico, cuando el valor del principal es v. El bienestar social para el valor v cuando el conjunto S de agentes está contratado es t(S) · v − Σ i∈S ci (en ambos casos, de agencia y no estratégico). Definición 2. El precio de la falta de responsabilidad POU(t, c) de una tecnología (t, c) se define como la peor proporción (sobre v) entre el bienestar social total en el caso no estratégico y el caso de agencia: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci En casos donde varios conjuntos son óptimos en el caso de agencia, tomamos el peor conjunto (es decir, el conjunto que produce el menor bienestar social). Cuando la tecnología (t, c) esté clara en el contexto, utilizaremos POU para denotar el precio de la falta de responsabilidad de la tecnología (t, c). Ten en cuenta que el POU es al menos 1 para cualquier tecnología. Como nos gustaría centrarnos en los resultados que se derivan de las propiedades de la función de éxito, en la mayor parte del documento nos ocuparemos del caso en el que todos los agentes tienen un costo idéntico c, es decir, ci = c para todo i ∈ N. Denotamos una tecnología (t, c) con costos idénticos como (t, c). Para simplificar la presentación, a veces utilizamos el término función tecnológica para referirnos a la función de éxito de la tecnología. 2.3 Funciones Tecnológicas Estructuradas Para ser más concretos, nos enfocaremos especialmente en las funciones tecnológicas cuya estructura puede describirse fácilmente como derivada de tareas de agentes independientes, a las que llamamos funciones tecnológicas estructuradas. Esta subclase primero nos dará algunos ejemplos naturales de la función de la tecnología, y también proporcionará una forma sucinta y natural de representar las funciones de la tecnología. En una función tecnológica estructurada, cada individuo tiene éxito o fracasa en su propia tarea de forma independiente. El éxito o fracaso del proyecto depende, posiblemente de una manera compleja, del conjunto de sub tareas exitosas. Por lo tanto, asumiremos una función Booleana monótona f: {0, 1}n → {0, 1} que indica si el proyecto tiene éxito como función del éxito de las tareas de los n agentes (y no está determinada por ningún conjunto de n-1 agentes). Además, existen constantes 0 < γi < δi < 1, donde γi denota la probabilidad de éxito para el agente i si no hace esfuerzo, y δi (> γi) denota la probabilidad de éxito si hace esfuerzo. Para reducir el número de parámetros, restringiremos nuestra atención al caso donde γ1 = . . . = γn = γ y δ1 = . . . = δn = 1 − γ, dejándonos con un único parámetro γ tal que 0 < γ < 1 2. Bajo esta estructura, la función de tecnología t está definida por t(a1, . . . , an) siendo la probabilidad de que f(x1, . . . , xn) = 1 donde los bits x1, . . . , xn son elegidos de acuerdo a la siguiente distribución: si ai = 0 entonces xi = 1 con probabilidad γ y xi = 0 con probabilidad 1 − γ; de lo contrario, es decir, si ai = 1, entonces xi = 1 con probabilidad 1 − γ y xi = 0 con probabilidad γ. Denotamos x = (x1, . . . , xn). La cuestión de la representación de la función tecnológica se reduce ahora a la de representar la función Booleana monótona subyacente f. En el caso más general, la función f puede ser dada por un circuito Booleano monótono general. Una subclase especialmente natural de funciones en el entorno de tecnologías estructuradas serían funciones que pueden ser representadas como una red de lectura única: un grafo con una fuente y un sumidero dados, donde cada borde está etiquetado por un jugador diferente. El proyecto tiene éxito si los bordes que pertenecen a los jugadores cuya tarea tuvo éxito forman un camino entre la fuente y el sumidero. Unos cuantos ejemplos simples deberían estar en orden aquí: 1. La tecnología AND: f(x1, . . . , xn) es la conjunción lógica de xi (f(x) = V i∈N xi). Por lo tanto, el proyecto tiene éxito solo si todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(a). Si m agentes ejercen esfuerzo (P i ai = m), entonces t(a) = tm = γn−m (1 − γ)m. Por ejemplo, para dos jugadores, la función de tecnología t(a1a2) = ta1+a2 está dada por t0 = t(00) = γ2, t1 = t(01) = t(10) = γ(1 − γ), y t2 = t(11) = (1 − γ)2. La tecnología OR: f(x1, . . . , xn) es la disyunción lógica de xi (f(x) = W i∈N xi). Por lo tanto, el proyecto tiene éxito si al menos uno de los agentes tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 1(b). Si m agentes ejercen esfuerzo, entonces tm = 1 − γm (1 − γ)n−m. Por ejemplo, para dos jugadores, la función de tecnología se da por t(00) = 1 − (1 − γ)2, t(01) = t(10) = 1 − γ(1 − γ), y t(11) = 1 − γ2. La tecnología Or-de-Ands (OOA): f(x) es la disyunción lógica de conjunciones. En el caso más simple de cláusulas de igual longitud (denotado por nc el número de cláusulas y por nl su longitud), f(x) = Wnc j=1( Vnl k=1 xj k). Por lo tanto, el proyecto tiene éxito si en al menos una cláusula todos los agentes tienen éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(a). Si mis agentes en la ruta i hacen un esfuerzo, entonces t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) se define como t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), y así sucesivamente. Se puede ver esta representación como correspondiente directamente al proyecto de entregar un mensaje desde la fuente hasta el destino en una red real de computadoras, con los bordes controlados por agentes egoístas. Figura 1: Representaciones gráficas de las tecnologías (a) AND y (b) OR. Figura 2: Representaciones gráficas de las tecnologías (a) OOA y (b) AOO. 4. La tecnología And-of-Ors (AOO): f(x) es la conjunción lógica de disyunciones. En el caso más simple de cláusulas de igual longitud (denotadas por nl el número de cláusulas y por nc su longitud), f(x) = Σnl j=1( Πnc k=1 xj k). Por lo tanto, el proyecto tiene éxito si al menos un agente de cada cláusula en forma disyuntiva tiene éxito en sus tareas. Esto se muestra gráficamente como una red de lectura única en la Figura 2(b). Si mis agentes en la cláusula i hacen un esfuerzo, entonces t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ). Por ejemplo, para cuatro jugadores, la función de tecnología t(a1 1 a1 2, a2 1 a2 2) está dada por t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), y así sucesivamente. 5. La tecnología de la mayoría: f(x) es 1 si la mayoría de los valores xi son 1. Así, el proyecto tiene éxito si la mayoría de los jugadores tienen éxito. La función de mayoría, incluso con 3 entradas, no puede ser representada por una red de lectura única, pero es fácilmente representada por una fórmula booleana monótona maj(x, y, z) = xy+yz+xz. En este caso, la función de tecnología está dada por t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. ANÁLISIS DE ALGUNAS TECNOLOGÍAS ANÓNIMAS Una función de éxito t se llama anónima si es simétrica con respecto a los jugadores. Es decir, t(a1, . . . , an) depende solo de P i∈N ai (el número de agentes que hacen un esfuerzo). Una tecnología (t, c) es anónima si t es anónima y el costo c es idéntico para todos los agentes. De los ejemplos presentados anteriormente, las tecnologías AND, OR y majority eran anónimas (pero no AOO y OOA). En el caso de un t anónimo, solo es importante el número de agentes que ejercen esfuerzo, por lo que podemos acortar las notaciones y denotar tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 y um = tm · (v − m · pm), para el caso de costos idénticos c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figura 3: Número de agentes en el contrato óptimo de las tecnologías AND (izquierda) y OR (derecha) con 3 jugadores, en función de γ y v. Tecnología AND: se contratan 0 o 3 agentes, y el valor de transición es monótono en γ. Tecnología OR: para cualquier γ podemos ver todas las transiciones. 3.1 Tecnologías AND y OR Comencemos con un análisis directo y completo de las tecnologías AND y OR para dos jugadores en el caso γ = 1/4 y c = 1. Ejemplo 1. Y tecnología con dos agentes, c = 1, γ = 1/4: tenemos t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, y t2 = (1 − γ)2 = 9/16, por lo tanto Δ0 = 1/8 y Δ1 = 3/8. El director tiene 3 posibilidades: contratar con 0, 1 o 2 agentes. Vamos a escribir las expresiones para su utilidad en estos 3 casos: • 0 Agentes: Ningún agente recibe pago, por lo tanto la utilidad del principal es u0 = t0 · v = v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8 en caso de éxito y la utilidad del principal es u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8/3 en caso de éxito, y la utilidad del principal es u2 = t2(v−2p2) = 9v/16 − 3. Ten en cuenta que la opción de contratar con un solo agente siempre es inferior a la de contratar con ambos o con ninguno, y nunca será elegida por el principal. El director contratará sin agente cuando v < 6, con ambos agentes siempre que v > 6, y con uno o ambos para v = 6. Esto debe contrastarse con el caso no estratégico en el que el principal controla completamente a los agentes (y asume sus costos) y simplemente optimiza globalmente. En este caso, el director hará que ambos agentes hagan un esfuerzo cuando v ≥ 4. Por lo tanto, por ejemplo, para v = 6, la decisión óptima a nivel global (caso no estratégico) daría una utilidad global de 6 · 9/16 − 2 = 11/8, mientras que la decisión del principal (en el caso de la agencia) daría una utilidad global de 3/8, dando una proporción de 11/3. Resulta que este es el peor precio de falta de responsabilidad en este ejemplo, y se obtiene exactamente en el punto de transición del caso de la agencia, como mostramos a continuación. Ejemplo 2. Tecnología OR con dos agentes, c = 1, γ = 1/4: tenemos t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, y t2 = 1 − γ2 = 15/16, por lo tanto Δ0 = 3/8 y Δ1 = 1/8. Vamos a escribir las expresiones para la utilidad de los principales en estos tres casos: • 0 Agentes: Ningún agente recibe pago y la utilidad de los principales es u0 = t0 · v = 7v/16. • 1 Agente: Este agente recibe p1 = c/Δ0 = 8/3 en caso de éxito y la utilidad de los principales es u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agentes: cada agente recibe p2 = c/Δ1 = 8 en caso de éxito, y la utilidad de los principales es u2 = t2(v − 2p2) = 15v/16 − 15/2. Ahora, contratar con un agente es mejor que no contratar con ninguno siempre que v > 52/9 (y es equivalente para v = 52/9), y contratar con ambos agentes es mejor que contratar con un agente siempre que v > 128/3 (y es equivalente para v = 128/3), por lo tanto, el principal no contratará con ningún agente para 0 ≤ v ≤ 52/9, con un agente para 52/9 ≤ v ≤ 128/3, y con ambos agentes para v ≥ 128/3. En el caso no estratégico, en comparación, el principal hará que un solo agente haga un esfuerzo por v > 8/3, y el segundo también hará un esfuerzo cuando v > 8. Resulta que el precio de la falta de responsabilidad aquí es 19/13, y se logra en v = 52/9, que es exactamente el punto de transición de 0 a 1 agentes contratados en el caso de la agencia. No es una coincidencia que en ambas tecnologías AND y OR, el POU se obtenga para v que es un punto de transición (ver prueba completa en [2]). Lema 1. Para cualquier tecnología dada (t, c), el precio de la falta de responsabilidad POU(t, c) se obtiene en algún valor v que es un punto de transición, ya sea en los casos de agencia o no estratégicos. Bosquejo de la prueba: Observamos todos los puntos de transición en ambos casos. Para cualquier valor menor al primer punto de transición, 0 agentes son contratados en ambos casos, y la proporción del bienestar social es 1. De manera similar, para cualquier valor superior al último punto de transición, se contratan n agentes en ambos casos, y la proporción del bienestar social es 1. Por lo tanto, podemos enfocarnos en el intervalo entre el primer y último punto de transición. Entre cualquier par de puntos consecutivos, la proporción del bienestar social se encuentra entre dos funciones lineales de v (los contratos óptimos están fijados en dicho segmento). Luego demostramos que para cada segmento, la razón del supremo se obtiene en un punto final del segmento (un punto de transición). Dado que hay un número finito de puntos de este tipo, el supremo global se obtiene en el punto de transición con la proporción máxima de bienestar social. Ya vemos una diferencia cualitativa entre las tecnologías AND y OR (incluso con 2 agentes): en el primer caso, todos los agentes están contratados o ninguno, mientras que en el segundo caso, para cierto rango intermedio de valores v, exactamente un agente está contratado. La Figura 3 muestra el mismo fenómeno para las tecnologías AND y OR con 3 jugadores. Teorema 1. Para cualquier tecnología anónima Y tecnología7: • existe un valor8 v∗ < ∞ tal que para cualquier v < v∗ es óptimo no contratar con ningún agente, para v > v∗ es óptimo contratar con todos los n agentes, y para v = v∗, ambos contratos (0, n) son óptimos. 7 Tecnología Y con cualquier número de agentes n y cualquier γ, y cualquier costo c idéntico. 8 v∗ es una función de n, γ, c. 23 • el precio de la falta de responsabilidad se obtiene en el punto de transición del caso de la agencia, y es POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Esquema de prueba: Para cualquier número fijo de agentes contratados, k, la utilidad del principal es una función lineal en v, donde la pendiente es igual a la probabilidad de éxito bajo k agentes contratados. Por lo tanto, el contrato óptimo corresponde al máximo sobre un conjunto de funciones lineales. Que v∗ denote el punto en el que el principal es indiferente entre contratar con 0 o n agentes. En [2] mostramos que en v∗, la utilidad del principal al contratar con 0 (o n) agentes es mayor que su utilidad al contratar con cualquier número de agentes k ∈ {1, . . . , n − 1}. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), para cualquier v < v∗, contratar con 0 agentes es óptimo, y para cualquier v > v∗, contratar con n agentes es óptimo. Esto es cierto tanto para los casos de agencia como para los casos no estratégicos. Dado que en ambos casos hay un único punto de transición, la afirmación sobre el precio de la falta de responsabilidad para la tecnología AND se demuestra como un caso especial del Lema 2 que se presenta a continuación. Para la tecnología AND tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 y tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ, y las expresiones para el POU siguen. En [2] presentamos una caracterización general de tecnologías con una sola transición en la agencia y los casos no estratégicos, y proporcionamos una prueba completa del Teorema 1 como un caso especial. La propiedad de una sola transición ocurre tanto en los casos de agencia como en los no estratégicos, donde la transición ocurre a un valor más pequeño de v en el caso no estratégico. Observa que el POU no está acotado en la familia AND de tecnologías (para varios n, γ) a medida que POU → ∞ ya sea si γ → 0 (para cualquier n ≥ 2 dado) o n → ∞ (para cualquier γ fijo ∈ (0, 1 2 )). A continuación consideramos la tecnología OR y mostramos que exhibe todas las n transiciones. Teorema 2. Para cualquier tecnología OR anónima, existen valores finitos positivos v1 < v2 < . . . < vn tales que para cualquier v tal que vk < v < vk+1, la contratación con exactamente k agentes es óptima (para v < v1, ningún agente es contratado, y para v > vn, todos los n agentes son contratados). Para v = vk, el principal es indiferente entre contratar con k − 1 o k agentes. Bosquejo de la prueba: Para demostrar la afirmación, definimos vk como el valor para el cual el principal es indiferente entre contratar con k − 1 agentes y contratar con k agentes. Luego demostramos que para cualquier k, vk < vk+1. Dado que el número de agentes contratados es monótono no decreciente en el valor (debido al Lema 3), v1 < v2 < . . . < vn es una condición suficiente para que se cumpla el teorema. El mismo comportamiento ocurre tanto en el caso de la agencia como en el caso no estratégico. Esta caracterización es un corolario directo de una caracterización más general dada en [2]. Mientras que en la tecnología AND pudimos determinar completamente el POU de forma analítica, la tecnología OR es más difícil de analizar. Pregunta abierta 1. ¿Cuál es el POU para OR con n > 2 agentes? ¿Está acotado por una constante para cada n? Solo podemos determinar el POU de la tecnología OR para el caso de dos agentes [2]. Incluso para el caso de los 2 agentes, ya observamos una diferencia cualitativa entre el POU en las tecnologías AND y OR. Observación 2. Si bien en la tecnología AND el POU para n = 2 no está limitado superiormente (para γ → 0), el POU más alto en la tecnología OR con dos agentes es 2 (para γ → 0). ¿Qué determina las transiciones? Los teoremas 1 y 2 indican que tanto las tecnologías AND como OR presentan el mismo comportamiento de transición (cambios en el contrato óptimo) en los casos de agencia y no estratégicos. Sin embargo, esto no es cierto en general. En [2] proporcionamos una caracterización completa de las condiciones suficientes y necesarias para que las tecnologías anónimas generales tengan una sola transición y todas las n transiciones. Encontramos que las condiciones en el caso de la agencia son diferentes a las del caso no estratégico. Somos capaces de determinar el POU para cualquier tecnología anónima que muestre una sola transición en los casos de agencia y no estratégicos (ver prueba completa en [2]). Lema 2. Para cualquier tecnología anónima que tenga una sola transición en ambos casos, el POU se da por: POU = 1 + tn−1 t0 − tn−1 tn y se obtiene en el punto de transición del caso de la agencia. Bosquejo de prueba: Dado que los pagos en el caso de la agencia son más altos que en el caso no estratégico, el punto de transición en el caso de la agencia ocurre para un valor más alto que en el caso no estratégico. Por lo tanto, existe una región en la que los números óptimos de agentes contratados en la agencia y los casos no estratégicos son 0 y n, respectivamente. Según el Lema 1, el POU se obtiene en un punto de transición. A medida que la proporción del bienestar social está disminuyendo en esta región, el POU se obtiene en el valor más alto, es decir, en el punto de transición del caso de la agencia. El punto de transición en el caso de la agencia es el punto en el cual el principal es indiferente entre contratar con 0 y con n agentes, v∗ = c·n tn−t0 · tn tn−tn−1. Sustituir el punto de transición del caso de la agencia en la expresión POU produce la expresión requerida. La tecnología MAJORITY El proyecto bajo la función MAJORITY tiene éxito si la mayoría de los agentes tienen éxito en sus tareas (ver Sección 2.3). No podemos caracterizar el comportamiento de transición de la tecnología MAJORITY de forma analítica. La Figura 4 presenta el número óptimo de agentes contratados como función de v y γ, para n = 5. Los fenómenos que observamos en este ejemplo (y en otros que hemos analizado) nos llevan a la siguiente conjetura. Conjetura 1. Para cualquier tecnología de Mayoría (cualquier n, γ y c), existe un valor l, 1 ≤ l ≤ n/2, tal que la primera transición es de 0 a l agentes, y luego existen todas las n − l transiciones restantes. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figura 4: Resultados de simulaciones que muestran el número de agentes en el contrato óptimo de la tecnología de MAYORÍA con 5 jugadores, en función de γ y v. A medida que γ disminuye, la primera transición es a un valor más bajo y a un mayor número de agentes. Para cualquier γ suficientemente pequeño, la primera transición es a 3 = 5/2 agentes, y para cualquier γ suficientemente grande, la primera transición es a 1 agente. Para cualquier γ, la primera transición nunca es a más de 3 agentes, y después de la primera transición vemos todas las transiciones posibles siguientes. Además, para cualquier c fijo, n, l = 1 cuando γ está suficientemente cerca de 1 2 , l es una función no decreciente de γ (con imagen {1, . . . , n/2 }), y l = n/2 cuando γ está suficientemente cerca de 0. 4. En tecnologías no anónimas (incluso con costos idénticos), necesitamos hablar sobre el conjunto de agentes contratados y no solo sobre el número de agentes contratados. En esta sección, identificamos los conjuntos de agentes que pueden obtenerse como el contrato óptimo para algún v. Estos conjuntos construyen la órbita de una tecnología. Definición 3. Para una tecnología t, un conjunto de agentes S está en la órbita de t si para algún valor v, el contrato óptimo es exactamente con el conjunto S de agentes (donde los empates entre diferentes conjuntos S se resuelven de acuerdo con un orden lexicográfico). El korbit de t es la colección de conjuntos de tamaño exactamente k en la órbita. Observe que en el caso no estratégico, la k-órbita de cualquier tecnología con un costo idéntico c tiene un tamaño de a lo sumo 1 (ya que todos los conjuntos de tamaño k tienen el mismo costo, solo el que tiene la probabilidad máxima puede estar en la órbita). Por lo tanto, la órbita de cualquier tecnología de este tipo en el caso no estratégico tiene un tamaño de como máximo n + 1. Mostramos que la situación en el caso de la agencia es muy diferente. Una observación básica es que la órbita de una tecnología es en realidad una lista ordenada de conjuntos de agentes, donde el orden está determinado por el siguiente lema. Lema 3. (Lema de Monotonía) Para cualquier tecnología (t, c), tanto en los casos de agencia como en los no estratégicos, la utilidad esperada del principal en los contratos óptimos, la probabilidad de éxito de los contratos óptimos y el pago esperado del contrato óptimo, son todos monótonamente no decrecientes con el valor. Prueba. Supongamos que los conjuntos de agentes S1 y S2 son óptimos en v1 y v2 < v1, respectivamente. Que Q(S) denote el pago total esperado a todos los agentes en S en el caso de que el principal contrate con el conjunto S y el proyecto tenga éxito (para el caso de la agencia, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i), mientras que para el caso no estratégico Q(S) = P i∈S ci). La utilidad del principal es una función lineal del valor, u(S, v) = t(S)·v−Q(S). Dado que S1 es óptimo en v1, u(S1, v1) ≥ u(S2, v1), y dado que t(S2) ≥ 0 y v1 > v2, u(S2, v1) ≥ u(S2, v2). Concluimos que u(S1, v1) ≥ u(S2, v2), por lo tanto, la utilidad es monótona no decreciente en el valor. A continuación mostramos que la probabilidad de éxito es monótonamente no decreciente en el valor. S1 es óptimo en v1, por lo tanto: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 es óptimo en v2, por lo tanto: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Sumando estas dos ecuaciones, obtenemos que (t(S1) − t(S2)) · (v1 − v2) ≥ 0, lo que implica que si v1 > v2 entonces t(S1) ≥ t(S2). Finalmente demostramos que el pago esperado es monótono no decreciente en el valor. Dado que S2 es óptimo en v2 y t(S1) ≥ t(S2), observamos que: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) o, equivalentemente, Q(S2) ≤ Q(S1), que es lo que queríamos demostrar. 4.1 Tecnologías AOO y OOA Comenzamos nuestra discusión sobre tecnologías no anónimas con dos ejemplos; las tecnologías And-of-Ors (AOO) y Or-of-Ands (OOA). La tecnología AOO (ver figura 2) está compuesta por múltiples componentes OR que se combinan mediante una operación lógica AND. Teorema 3. Sea h una tecnología OR anónima, y sea f = Vnc j=1 h la tecnología AOO que se obtiene mediante una conjunción de nc de estos componentes OR en entradas disjuntas. Entonces, para cualquier valor v, un contrato óptimo contrata con el mismo número de agentes en cada componente OR. Por lo tanto, la órbita de f tiene un tamaño de como máximo nl + 1, donde nl es el número de agentes en h. Parte de la prueba del teorema (para ver la prueba completa, consulte [2]), se basa en que dicha tecnología AOO es un caso especial de una familia más general de tecnologías, en la que las tecnologías anónimas disjuntas se unen mediante la operación lógica \"Y\", como se explica en la siguiente sección. Conjeturamos que un resultado similar se aplica a la tecnología OOA. Conjetura 2. En una tecnología de OOA que es una disyunción de los mismos caminos anónimos (con el mismo número de agentes, γ y c, pero sobre entradas disjuntas), para cualquier valor v, el contrato óptimo se construye a partir de algún número de caminos completamente contratados. Además, existen v1 < . . . < vnl tal que para cualquier v, vi ≤ v ≤ vi+1, exactamente i caminos se contraen. No podemos demostrarlo en general, pero podemos demostrarlo para el caso de una tecnología OOA con dos caminos de longitud dos (ver [2]). 25 4.2 Caracterización de la Órbita El AOO es un ejemplo de una tecnología cuyo tamaño de órbita es lineal en su número de agentes. Si la conjetura 2 es verdadera, lo mismo se aplica a la tecnología OOA. ¿Qué se puede decir sobre el tamaño de la órbita de una tecnología general no anónima? En caso de costos idénticos, es imposible que todos los subconjuntos de agentes estén en la órbita. Esto se sostiene por la observación de que la órbita de 1 (un solo agente que ejerce esfuerzo) tiene un tamaño de como máximo 1. Solo el agente que ofrece la mayor probabilidad de éxito (cuando solo él se esfuerza) puede estar en la órbita (ya que también necesita ser el que menos se le pague). Sin embargo, a continuación mostramos que la órbita puede tener un tamaño exponencial. Una colección de conjuntos de k elementos (de un total de n) es admisible, si cada par de conjuntos en la colección difiere en al menos 2 elementos (por ejemplo, para k=3, 123 y 234 no pueden estar juntos en la colección, pero 123 y 345 sí pueden estar). Teorema 4. Cada colección admisible puede ser obtenida como la órbita k- de algún t. Boceto de la prueba: La prueba es constructiva. Sea S una colección admisible de conjuntos de tamaño k. Para cada conjunto S ∈ S en la colección elegimos S, de modo que para cualquier par de conjuntos admisibles Si = Sj, Si = Sj. Luego definimos la función de tecnología t de la siguiente manera: para cualquier S ∈ S, t(S) = 1/2 − S y ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Por lo tanto, la contribución marginal de cada i ∈ S es S. Nótese que dado que S es admisible, t está bien definida, ya que para cualquier par de conjuntos S, S ∈ S y cualquier par de agentes i, j, S \\ i = S \\ j. Para cualquier otro conjunto Z, definimos t(Z) de tal manera que garantiza que la contribución marginal de cada agente en Z sea muy pequeña (los detalles técnicos aparecen en la versión completa). Esto completa la definición de t. Mostramos que cada conjunto admisible S ∈ S es óptimo en el valor vS = ck 2 2 S. Primero demostramos que es mejor que cualquier otro S ∈ S. En el valor vS = ck 2 2 S, el conjunto S que corresponde a S maximiza la utilidad del principal. Este resultado se obtiene tomando la derivada de u(S, v). Por lo tanto, S produce una utilidad mayor que cualquier otro S ∈ S. También seleccionamos el rango de S para asegurar que en vS, S sea mejor que cualquier otro conjunto S \\ i s.t. S ∈ S. Ahora nos queda demostrar que en vS, el conjunto S produce una utilidad mayor que cualquier otro conjunto Z ∈ S. La construcción de t(Z) asegura esto, ya que la contribución marginal de cada agente en Z es tan pequeña que el pago es demasiado alto para que el conjunto sea óptimo. En [2] presentamos la prueba completa del teorema, así como las pruebas completas de todas las demás afirmaciones presentadas en esta sección sin tal prueba. A continuación mostramos que existen colecciones admisibles muy grandes. Lema 4. Para cualquier n ≥ k, existe una colección admisible de conjuntos de tamaño k de tamaño Ω( 1 n · `n k ´ ). Bosquejo de la prueba: La prueba se basa en un código corrector de errores que corrige un bit. Un código con una distancia ≥ 3, por lo tanto es admisible. Se sabe que existen tales códigos con Ω(2n /n) palabras de código. Para asegurar que una fracción adecuada de estas palabras de código tengan peso k, construimos un nuevo código realizando la operación XOR entre cada palabra de código y una palabra aleatoria r. Las propiedades de XOR garantizan que el nuevo código siga siendo admisible. Cada palabra de código ahora se asigna uniformemente a todo el cubo, y por lo tanto su probabilidad de tener peso k es `n k ´ /2n. Por lo tanto, el número esperado de palabras de peso k es Ω(`n k ´/n), y para algunos r esta expectativa se cumple o se supera. Para k = n/2 podemos construir una colección admisible de tamaño exponencial, que según el Teorema 4 puede ser utilizada para construir una tecnología con órbita de tamaño exponencial. Corolario 1. Existe una tecnología (t, c) con órbita de tamaño Ω( 2n n √ n ). Por lo tanto, somos capaces de construir una tecnología con órbita exponencial, pero esta tecnología no es una tecnología de red o una tecnología estructurada. Abra la Pregunta 2. ¿Existe una red de lectura única con órbita exponencial? ¿Existe una tecnología estructurada con órbita exponencial? Sin embargo, hasta ahora, no hemos visto ejemplos de redes en serie-paralelo cuyo tamaño de órbita sea mayor que n + 1. Abra la Pregunta 3. ¿Qué tan grande puede ser el tamaño de la órbita de una red en serie-paralelo? Damos el primer paso hacia una solución de esta pregunta al mostrar que el tamaño de la órbita de una conjunción de dos redes disjuntas (tomando las dos en serie) es a lo sumo la suma de los tamaños de las órbitas de las dos redes. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). El contrato óptimo para f para algún v, denotado por S, está compuesto por algunos agentes de la parte h y algunos de la parte g, llámelos T y R respectivamente. Lema 5. Sea S un contrato óptimo para f = g V h en v. Entonces, T es un contrato óptimo para h en v · tg(R), y R es un contrato óptimo para g en v · th(T). Bosquejo de prueba: Expresamos la utilidad principal u(S, v) del principal al contratar con el conjunto S cuando su valor es v. Abusamos de la notación y utilizamos la función para denotar también la tecnología. Sea Δf i (S \\ i) el aporte marginal del agente i ∈ S. Entonces, para cualquier i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), y para cualquier i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i). Al sustituir estas expresiones y f(S) = h(T) · g(R), derivamos que u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) . El primer término se maximiza en un conjunto T que es óptimo para h en el valor g(R) · v, mientras que el segundo término es independiente de T y h. Por lo tanto, S es óptimo para f en v si y solo si T es un contrato óptimo para h en v · tg(R). Del mismo modo, demostramos que R es un contrato óptimo para g en v · th(T). 2 Lema 6. La función real v → th(T), donde T es la parte h− de un contrato óptimo para f en v, es monótona no decreciente (y de manera similar para la función v → tg(R)). Prueba. Sea S1 = T1 ∪ R1 el contrato óptimo para f en v1, y sea S2 = T2 ∪ R2 el contrato óptimo para f en v2 < v1. Por el Lema 3, f(S1) ≥ f(S2), y dado que f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2). Supongamos en contradicción que h(T1) < h(T2), entonces dado que h(T1)·g(R1) ≥ h(T2)·g(R2) esto implica que g(R1) > g(R2). Según el Lema 5, T1 es óptimo para h en v1 · g(R1), y T2 es óptimo para h en v2 · g(R2). Dado que v1 > v2 y g(R1) > g(R2), T1 es óptimo para h en un valor mayor que T2, por lo tanto, según el Lema 3, h(T1) ≥ h(T2), una contradicción. Basándonos en el Lema 5 y el Lema 6, obtenemos el siguiente Lema. Para la prueba completa, ver [2]. Lema 7. Sean g y h dos funciones booleanas en entradas disjuntas y sea f = g V h (es decir, tomar sus redes en serie). Supongamos que x e y son los tamaños de órbita respectivos de g y h; entonces, el tamaño de órbita de f es menor o igual a x + y − 1. Por inducción obtenemos el siguiente corolario. Corolario 2. Supongamos que {(gj, cj)}m j=1 es un conjunto de tecnologías anónimas en entradas disjuntas, cada una con un costo de agente idéntico (todos los agentes de la tecnología gj tienen el mismo costo cj). Entonces, la órbita de f = Vm j=1 gj tiene un tamaño de a lo sumo ( Pm j=1 nj ) − 1, donde nj es el número de agentes en la tecnología gj (la órbita es lineal en el número de agentes). En particular, esto se aplica a la tecnología AOO donde cada componente-OR es anónimo. También sería interesante considerar una disyunción de dos funciones booleanas. Abre la Pregunta 4. ¿El Lema 7 también se cumple para la función Booleana f = g W h (es decir, cuando las redes g, h se toman en paralelo)? Conjeturamos que este es efectivamente el caso, y que los Lemas correspondientes 5 y 7 también existen para el caso de la disyunción. Si esto es cierto, esto demostrará que las redes en serie-paralelo tienen un tamaño de órbita polinomial. 5. Nuestro análisis a lo largo del documento arroja algo de luz sobre los aspectos algorítmicos de calcular el mejor contrato. En esta sección mencionamos estas implicaciones (para las pruebas ver [2]). Primero consideramos el modelo general donde la función de tecnología está dada por una función t arbitraria monótona (con valores racionales), y luego consideramos el caso de tecnologías estructuradas dadas por una representación de red de la función booleana subyacente. 5.1 Tecnologías de Resultado Binario y Acción Binaria Aquí asumimos que se nos da una tecnología y un valor v como entrada, y nuestro resultado debería ser el contrato óptimo, es decir, el conjunto S∗ de agentes a ser contratados y el contrato pi para cada i ∈ S∗. En el caso general, la función de éxito t es de tamaño exponencial en n, el número de agentes, y tendremos que lidiar con eso. En el caso especial de tecnologías anónimas, la descripción de t es solo los n+1 números t0, . . . , tn, y en este caso nuestro análisis en la sección 3 es completamente suficiente para calcular el contrato óptimo. Proposición 1. Dado como entrada la descripción completa de una tecnología (los valores t0, . . . , tn y el costo idéntico c para una tecnología anónima, o el valor t(S) para todos los 2n posibles subconjuntos S ⊆ N de los jugadores, y un vector de costos c para tecnologías no anónimas), lo siguiente se puede calcular en tiempo polinómico: • La órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos. • Un contrato óptimo para cualquier valor dado v, tanto en la agencia como en los casos no estratégicos. • El precio de la falta de responsabilidad POU(t, c). Prueba. Demostramos las afirmaciones para el caso no anónimo, la prueba para el caso anónimo es similar. Primero mostramos cómo construir la órbita de la tecnología (el mismo procedimiento se aplica en ambos casos). Para construir la órbita, encontramos todos los puntos de transición y los conjuntos que están en la órbita. El contrato vacío siempre es óptimo para v = 0. Supongamos que hemos calculado los contratos óptimos y los puntos de transición hasta algún punto de transición v para el cual S es un contrato óptimo con la mayor probabilidad de éxito. Mostramos cómo calcular el próximo punto de transición y el próximo contrato óptimo. Según el Lema 3, el siguiente contrato en la órbita (para valores más altos) tiene una probabilidad de éxito más alta (no hay dos conjuntos con la misma probabilidad de éxito en la órbita). Calculamos el siguiente contrato óptimo mediante el siguiente procedimiento. Revisamos todos los conjuntos T tales que t(T) > t(S), y calculamos el valor para el cual el principal es indiferente entre contratar con T y contratar con S. El valor mínimo de indiferencia es el próximo punto de transición y el contrato que tiene el valor mínimo de indiferencia es el próximo contrato óptimo. La linealidad de la utilidad en el valor y la monotonía de la probabilidad de éxito de los contratos óptimos garantizan que lo anterior funcione. Claramente el cálculo anterior es polinómico en el tamaño de la entrada. Una vez que tengamos la órbita, es claro que se puede calcular un contrato óptimo para cualquier valor dado v. Encontramos el punto de transición más grande que no sea mayor que el valor v, y el contrato óptimo en v es el conjunto con la mayor probabilidad de éxito en este punto de transición. Finalmente, como podemos calcular la órbita de la tecnología en ambos casos, tanto en la agencia como en los casos no estratégicos, en tiempo polinómico, podemos encontrar el precio de la falta de responsabilidad en tiempo polinómico. Según el Lema 1, el precio de la falta de responsabilidad POU(t) se obtiene en algún punto de transición, por lo que solo necesitamos revisar todos los puntos de transición y encontrar aquel con la proporción de bienestar social máxima. Una pregunta más interesante es si, dado la función t como una caja negra, podemos calcular el contrato óptimo en un tiempo que sea polinómico en n. Podemos demostrar que, en general, esto no es el caso: Teorema 5. Dado como entrada un cuadro negro para una función de éxito t (cuando los costos son idénticos), y un valor v, el número de consultas que se necesita, en el peor de los casos, para encontrar el contrato óptimo es exponencial en n. Demostración. Considera la siguiente familia de tecnologías. Para algún pequeño > 0 y k = n/2 definimos la probabilidad de éxito para un conjunto dado T de la siguiente manera. Si |T| < k, entonces t(T) = |T| · . Si |T| > k, entonces t(T) = 1 − (n − |T|) · . Para cada conjunto de agentes ˆT de tamaño k, la tecnología t ˆT se define como t( ˆT) = 1 − (n − | ˆT|) · y t(T) = |T| · para cualquier T = ˆT de tamaño k. Para el valor v = c·(k + 1/2), el contrato óptimo para t ˆT es ˆT (para el contrato ˆT la utilidad del principal es aproximadamente v −c·k = 1/2·c > 0, mientras que para cualquier otro contrato la utilidad es negativa). Si el algoritmo consulta sobre como máximo ` n n/2 ´ − 2 conjuntos de tamaño k, entonces no siempre puede determinar el contrato óptimo (ya que cualquiera de los conjuntos sobre los que no ha consultado podría ser el óptimo). Concluimos que se necesitan ` n n/2 ´ − 1 consultas para determinar el contrato óptimo, y esto es exponencial en n. 27 5.2 Tecnologías Estructuradas En esta sección consideraremos la representación natural de las redes de lectura única para la función Booleana subyacente. Así, el problema que abordaremos será: El Problema del Contrato Óptimo para Redes de Lectura Única: Entrada: Una red de lectura única G = (V, E), con dos vértices específicos s, t; valores racionales γe, δe para cada jugador e ∈ E (y ce = 1), y un valor racional v. Salida: Un conjunto S de agentes que deberían ser contratados en un contrato óptimo. Que t(E) denote la probabilidad de éxito cuando cada borde tiene éxito con probabilidad δe. Primero notamos que incluso calcular el valor t(E) es un problema difícil: se llama el problema de confiabilidad de red y se sabe que es #P-difícil [8]. Un pequeño esfuerzo revelará que nuestro problema no es más fácil: Teorema 6. El Problema del Contrato Óptimo para Redes de Lectura Única es #P-difícil (bajo reducciones de Turing). Prueba. Mostraremos que un algoritmo para este problema puede ser utilizado para resolver el problema de confiabilidad de la red. Dado una instancia de un problema de confiabilidad de red < G, {ζe}e∈E > (donde ζe denota la probabilidad de éxito de e), definimos una instancia del problema del contrato óptimo de la siguiente manera: primero definimos un nuevo grafo G que se obtiene al unir G con un nuevo jugador x, con γx muy cercano a 1/2 y δx = 1 − γx. Para los otros bordes, dejamos que δe = ζe y γe = ζe/2. Al elegir γx lo suficientemente cercano a 1/2, podemos asegurarnos de que el jugador x solo entrará en el contrato óptimo para valores muy grandes de v, después de que todos los demás agentes estén contratados (si podemos encontrar el contrato óptimo para cualquier valor, es fácil encontrar un valor para el cual en la red original el contrato óptimo sea E, al seguir duplicando el valor y solicitando el contrato óptimo). Una vez que encontramos dicho valor, elegimos γx de manera que c 1−2γx sea mayor que ese valor. Denotemos βx = 1 − 2γx. El valor crítico de v donde el jugador x entra en el contrato óptimo de G, se puede encontrar utilizando la búsqueda binaria sobre el algoritmo que supuestamente encuentra el contrato óptimo para cualquier red y cualquier valor. Ten en cuenta que en este valor crítico v, el principal es indiferente entre el conjunto E y E ∪ {x}. Ahora, al escribir la expresión para esta indiferencia, en términos de t(E) y Δt i(E), observamos lo siguiente. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! si y solo si t(E) = (1 − γx) · c (βx)2 · v así, si siempre podemos encontrar el contrato óptimo, también podemos calcular el valor de t(E). En conclusión, calcular el contrato óptimo en general es difícil. Estos resultados sugieren dos direcciones naturales de investigación. La primera vía es estudiar familias de tecnologías cuyos contratos óptimos puedan ser calculados en tiempo polinómico. La segunda opción es explorar algoritmos de aproximación para el problema del contrato óptimo. Un posible candidato para la primera dirección es la familia de redes en serie-paralelo, para la cual el problema de confiabilidad de la red (calcular el valor de t) es polinomial. Abre la Pregunta 5. ¿Se puede resolver el problema del contrato óptimo para redes en serie-paralelo de Leer una Vez en tiempo polinómico? Solo podemos manejar el nivel no trivial de redes AOO: Lema 8. Dado una red de tipo \"Read Once AND-of-OR\" en la que cada componente OR es una tecnología anónima, el problema del contrato óptimo puede resolverse en tiempo polinómico. Agradecimientos. Este trabajo está respaldado por la Fundación para la Ciencia de Israel, la Fundación Binacional de Ciencia Estados Unidos-Israel, el Fondo de Becas Lady Davis y por una subvención de la Fundación Nacional de Ciencias número ANI-0331659. REFERENCIAS [1] M. Babaioff, M. Feldman y N. Nisan. El precio de la pureza y el trabajo libre en la agencia combinatoria. En el documento de trabajo, 2005. [2] M. Babaioff, M. Feldman y N. Nisan. Agencia combinatoria, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica y S. Shenker. Acción oculta en enrutamiento de múltiples saltos. En EC05, páginas 117-126, 2005. [4] B. Holmstrom. Riesgo moral en equipos. Revista Bell de Economía, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston y J. Verde. Teoría microeconómica. Oxford University Press, 1995. [6] N. Nisan y A. Ronen. Diseño mecanismos algorítmicos. Juegos y Comportamiento Económico, 35:166 - 196, 2001. Una versión preliminar apareció en STOC 1999. [7] C. Papadimitriou. Algoritmos, Juegos y el Internet. En Actas de la 33ª Conferencia Anual sobre Teoría de la Computación (STOC), páginas 749-753, 2001. [8] J. S. Provan y M. O. Pelota. La complejidad de contar cortes y de calcular la probabilidad de que un grafo esté conectado. Revista SIAM. Comput., 12(4):777-788, 1983. [9] A. Ronen y L. Wahrmann. Juegos de predicción. VINO, páginas 129-140, 2005. [10] R. Smorodinsky y M. Tennenholtz. Elicitación de información secuencial en sistemas multiagente. 20ª Conferencia sobre Incertidumbre en Inteligencia Artificial, 2004. [11] R. Smorodinsky y M. Tennenholtz. Superando el problema del aprovechamiento gratuito en computaciones de múltiples partes - El caso anónimo. Próximamente, GEB, 2005. [12] E. Winter. Incentivos y discriminación. Revista Económica Americana, 94:764-773, 2004. 28 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "con": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research <br>con</br>cerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "The field of Algorithmic Mechanism Design handles the issue of private information held by the different parties in such computational settings.",
                "This paper deals with a complementary problem in such settings: handling the hidden actions that are performed by the different parties.",
                "Our model is a combinatorial variant of the classical principalagent problem from e<br>con</br>omic theory.",
                "In our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf, but their actions are hidden from him.",
                "Our focus is on cases where complex combinations of the efforts of the agents influence the outcome.",
                "The principal motivates the agents by offering to them a set of <br>con</br>tracts, which together put the agents in an equilibrium point of the induced game.",
                "We present formal models for this setting, suggest and embark on an analysis of some basic issues, but leave many questions open.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: E<br>con</br>omics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, E<br>con</br>omics, Theory 1.",
                "INTRODUCTION 1.1 Background One of the most striking characteristics of modern computer networks - in particular the Internet - is that different parts of it are owned and operated by different individuals, firms, and organizations.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish e<br>con</br>omic interests of the different participants.",
                "Indeed, the last few years have seen much work addressing this issue using game-theoretic notions (see [7] for an influential survey).",
                "A significant part of the difficulty stems from underlying asymmetries of information: one participant may not know everything that is known or done by another.",
                "In particular, the field of algorithmic mechanism design [6] uses appropriate incentives to extract the private information from the participants.",
                "This paper deals with the complementary lack of knowledge, that of hidden actions.",
                "In many cases the actual behaviors - actions - of the different participants are hidden from others and only influence the final outcome indirectly.",
                "Hidden here covers a wide range of situations including not precisely measurable, costly to determine, or even non-<br>con</br>tractible - meaning that it can not be formally used in a legal <br>con</br>tract.",
                "An example that was discussed in [3] is Quality of Service routing in a network: every intermediate link or router may exert a different amount of effort (priority, bandwidth, ...) when attempting to forward a packet of information.",
                "While the final outcome of whether a packet reached its destination is clearly visible, it is rarely feasible to monitor the exact amount of effort exerted by each intermediate link - how can we ensure that they really do exert the appropriate amount of effort?",
                "Many other complex resource allocation problems exhibit similar hidden actions, e.g., a task that runs on a collection of shared servers may be allocated, by each server, an unknown percentage of the CPUs processing power or of the physical memory.",
                "How can we ensure that the right combination of allocations is actually made by the different servers?",
                "A related class of examples <br>con</br>cerns security issues: each link in a complex system may exert different levels of effort for protecting some desired security property of the system.",
                "How can we ensure that the desired level of 18 collective security is obtained?",
                "Our approach to this problem is based on the well studied principal-agent problem in e<br>con</br>omic theory: How can a principal motivate a rational agent to exert costly effort towards the welfare of the principal?",
                "The crux of the model is that the agents action (i.e. whether he exerts effort or not) is invisible to the principal and only the final outcome, which is probabilistic and also influenced by other factors, is visible.",
                "This problem is well studied in many <br>con</br>texts in classical e<br>con</br>omic theory and we refer the readers to introductory texts on economic theory such as [5] Chapter 14.",
                "The solution is based on the observation that a properly designed <br>con</br>tract, in which the payments are <br>con</br>tingent upon the final outcome, can influence a rational agent to exert the required effort.",
                "In this paper we initiate a general study of handling combinations of agents rather than a single agent.",
                "While much work was already done on motivating teams of agents [4], our emphasis is on dealing with the complex combinatorial structure of dependencies between agents actions.",
                "In the general case, each combination of efforts exerted by the n different agents may result in a different expected gain for the principal.",
                "The general question asks which <br>con</br>ditional payments should the principal offer to which agents as to maximize his net utility?",
                "In our setting and unlike in previous work (see, e.g., [12]), the main challenge is to determine the optimal amount of effort desired from each agent.",
                "This paper suggest models for and provides some interesting initial results about this combinatorial agency problem.",
                "We believe that we have only scratched the surface and leave many open questions, <br>con</br>jectures, and directions for further research.",
                "We believe that this type of analysis may also find applications in regular e<br>con</br>omic activity.",
                "Consider for example a firm that sub-<br>con</br>tracts a family of related tasks to many individuals (or other firms).",
                "It will often not be possible to exactly monitor the actual effort level of each sub-<br>con</br>tractor (e.g., in cases of public-relations activities, <br>con</br>sulting activities, or any activities that require cooperation between different sub-contractors.)",
                "When the dependencies between the different subtasks are complex, we believe that combinatorial agency models can offer a foundation for the design of <br>con</br>tracts with appropriate incentives.",
                "It may also be useful to view our work as part of a general research agenda stemming from the fact that all types of e<br>con</br>omic activity are increasingly being handled with the aid of sophisticated computer systems.",
                "In general, in such computerized settings, complex scenarios involving multiple agents and goods can naturally occur, and they need to be algorithmically handled.",
                "This calls for the study of the standard issues in e<br>con</br>omic theory in new complex settings.",
                "The principal-agent problem is a prime example where such complex settings introduce new challenges. 1.2 Our Models We start by presenting a general model: in this model each of n agents has a set of possible actions, the combination of actions by the players results in some outcome, where this happens probabilistically.",
                "The main part of the specification of a problem in this model is a function that specifies this distribution for each n-tuple of agents actions.",
                "Additionally, the problem specifies the principals utility for each possible outcome, and for each agent, the agents cost for each possible action.",
                "The principal motivates the agents by offering to each of them a <br>con</br>tract that specifies a payment for each possible outcome of the whole project1 .",
                "Key here is that the actions of the players are non-observable and thus the <br>con</br>tract cannot make the payments directly <br>con</br>tingent on the actions of the players, but rather only on the outcome of the whole project.",
                "Given a set of <br>con</br>tracts, the agents will each optimize his own utility: i.e. will choose the action that maximizes his expected payment minus the cost of his action.",
                "Since the outcome depends on the actions of all players together, the agents are put in a game and are assumed to reach a Nash equilibrium2 .",
                "The principals problem, our problem in this paper, is of designing an optimal set of <br>con</br>tracts: i.e. <br>con</br>tracts that maximize his expected utility from the outcome, minus his expected total payment.",
                "The main difficulty is that of determining the required Nash equilibrium point.",
                "In order to focus on the main issues, the rest of the paper deals with the basic binary case: each agent has only two possible actions exert effort and shirk and there are only two possible outcomes success and failure.",
                "It seems that this case already captures the main interesting ingredients3 .",
                "In this case, each agents problem boils down to whether to exert effort or not, and the principals problem boils down to which agents should be <br>con</br>tracted to exert effort.",
                "This model is still pretty abstract, and every problem description <br>con</br>tains a complete table specifying the success probability for each subset of the agents who exert effort.",
                "We then <br>con</br>sider a more <br>con</br>crete model which concerns a subclass of problem instances where this exponential size table is succinctly represented.",
                "This subclass will provide many natural types of problem instances.",
                "In this subclass every agent performs a subtask which succeeds with a low probability γ if the agent does not exert effort and with a higher probability δ > γ, if the agent does exert effort.",
                "The whole project succeeds as a deterministic Boolean function of the success of the subtasks.",
                "This Boolean function can now be represented in various ways.",
                "Two basic examples are the AND function in which the project succeeds only if all subtasks succeed, and the OR function which succeeds if any of the subtasks succeeds.",
                "A more complex example <br>con</br>siders a communication network, where each agent <br>con</br>trols a single edge, and success of the subtask means that a message is forwarded by that edge.",
                "Effort by the edge increases this success probability.",
                "The complete project succeeds if there is a complete path of successful edges between a given source and sink.",
                "Complete definitions of the models appear in Section 2. 1.3 Our Results 1 One could think of a different model in which the agents have intrinsic utility from the outcome and payments may not be needed, as in [10, 11]. 2 In this paper our philosophy is that the principal can suggest a Nash equilibrium point to the agents, thus focusing on the best Nash equilibrium.",
                "One may alternatively study the worst case equilibrium as in [12], or alternatively, attempt modeling some kind of an extensive game between the agents, as in [9, 10, 11]. 3 However, some of the more advanced questions we ask for this case can be viewed as instances of the general model. 19 We address a host of questions and prove a large number of results.",
                "We believe that despite the large amount of work that appears here, we have only scratched the surface.",
                "In many cases we were not able to achieve the general characterization theorems that we desired and had to settle for analyzing special cases or proving partial results.",
                "In many cases, simulations reveal structure that we were not able to formally prove.",
                "We present here an informal overview of the issues that we studied, what we were able to do, and what we were not.",
                "The full treatment of most of our results appears only in the extended version [2], and only some are discussed, often with associated simulation results, in the body of the paper.",
                "Our first object of study is the structure of the class of sets of agents that can be <br>con</br>tracted for a given problem instance.",
                "Let us fix a given function describing success probabilities, fix the agents costs, and let us <br>con</br>sider the set of <br>con</br>tracted agents for different values of the principals associated value from success.",
                "For very low values, no agent will be <br>con</br>tracted since even a single agents cost is higher than the principals value.",
                "For very high values, all agents will always be <br>con</br>tracted since the marginal <br>con</br>tribution of an agent multiplied by the principals value will overtake any associated payment.",
                "What happens for intermediate principals values?",
                "We first observe that there is a finite number of transitions between different sets, as the principals project value increases.",
                "These transitions behave very differently for different functions.",
                "For example, we show that for the AND function only a single transition occurs: for low enough values no agent will be <br>con</br>tracted, while for higher values all agents will be <br>con</br>tracted - there is no intermediate range for which only some of the agents are contracted.",
                "For the OR function, the situation is opposite: as the principals value increases, the set of <br>con</br>tracted agents increases one-by-one.",
                "We are able to fully characterize the types of functions for which these two extreme types of transitions behavior occur.",
                "However, the structure of these transitions in general seems quite complex, and we were not able to fully analyze them even in simple cases like the Majority function (the project succeeds if a majority of subtasks succeeds) or very simple networks.",
                "We do have several partial results, including a <br>con</br>struction with an exponential number of transitions.",
                "During the previous analysis we also study what we term the price of unaccountability: How much is the social utility achieved under the optimal <br>con</br>tracts worse than what could be achieved in the non-strategic case4 , where the socially optimal actions are simply dictated by the principal?",
                "We are able to fully analyze this price for the AND function, where it is shown to tend to infinity as the number of agents tends to infinity.",
                "More general analysis remains an open problem.",
                "Our analysis of these questions sheds light on the difficulty of the various natural associated algorithmic problems.",
                "In particular, we observe that the optimal <br>con</br>tract can be found in time polynomial in the explicit representation of the probability function.",
                "We prove a lower bound that shows that the optimal <br>con</br>tract cannot be found in number of queries that is polynomial just in the number of agents, in a general black-box model.",
                "We also show that when the probability function is succinctly represented as 4 The non-strategic case is often referred to as the case with <br>con</br>tractible actions or the principals first-best solution. a read-once network, the problem becomes #P-hard.",
                "The status of some algorithmic questions remains open, in particular that of finding the optimal <br>con</br>tract for technologies defined by serial-parallel networks.",
                "In a follow-up paper [1] we deal with equilibria in mixed strategies and show that the principal can gain from inducing a mixed-Nash equilibrium between the agents rather than a pure one.",
                "We also show cases where the principal can gain by asking agents to reduce their effort level, even when this effort comes for free.",
                "Both phenomena can not occur in the non-strategic setting. 2.",
                "MODEL AND PRELIMINARIES 2.1 The General Setting A principal employs a set of agents N of size n. Each agent i ∈ N has a possible set of actions Ai, and a cost (effort) ci(ai) ≥ 0 for each possible action ai ∈ Ai (ci : Ai → +).",
                "The actions of all players determine, in a probabilistic way, a <br>con</br>tractible outcome o ∈ O, according to a success function t : A1×, . . . × An → Δ(O) (where Δ(O) denotes the set of probability distributions on O).",
                "A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, . . . , cn).",
                "The principal has a certain value for each possible outcome, given by the function v : O → .",
                "As we will only <br>con</br>sider risk-neutral players in this paper5 , we will also treat v as a function on Δ(O), by taking simple expected value.",
                "Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable <br>con</br>tracts based on the final outcome.",
                "Thus the <br>con</br>tract for agent i is a function (payment) pi : O → ; again, we will also view pi as a function on Δ(O).",
                "Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, . . . , an) is given by ui(a) = pi(t(a))−ci(ai).",
                "The agents will be assumed to reach Nash equilibrium, if such equilibrium exists.",
                "The principals problem (which is our problem in this paper) is how to design the <br>con</br>tracts pi as to maximize his own expected utility u(a) = v(t(a)) − P i pi(t(a)), where the actions a1, . . . , an are at Nash-equilibrium.",
                "In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium.",
                "A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists.",
                "Finally, the social welfare for a ∈ A is u(a) + P i∈N ui(a) = v(t(a)) − P i∈N ci(ai). 2.2 The Binary-Outcome Binary-Action Model We wish to <br>con</br>centrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t. A similar model was used in [12].",
                "We first restrict the action spaces to have only two states (binary-action): 0 (low effort) and 1 (high effort).",
                "The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0).",
                "The vector of costs is c = (c1, c2, . . . , cn), 5 The risk-averse case would obviously be a natural se<br>con</br>d step in the research of this model, as has been for noncombinatorial scenarios. 20 and we use the notation (t, c) to denote a technology in such a binary-outcome model.",
                "We then restrict the outcome space to have only two states (binary-outcome): 0 (project failure) and 1 (project success).",
                "The principals value for a successful project is given by a scalar v > 0 (where the value of project failure is 0).",
                "We assume that the principal can pay the agents but not fine them (known as the limited liability <br>con</br>straint).",
                "The <br>con</br>tract to agent i is thus now given by a scalar value pi ≥ 0 that denotes the payment that i gets in case of project success.",
                "If the project fails, the agent gets 0.",
                "When the lowest cost action has zero cost (as we assume), this immediately implies that the participation <br>con</br>straint holds.",
                "At this point the success function t becomes a function t : {0, 1}n → [0, 1], where t(a1, . . . , an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci.",
                "As we wish to <br>con</br>centrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e. that the success function t is strictly monotone.",
                "Formally, if we denote by a−i ∈ A−i the (n − 1)dimensional vector of the actions of all agents excluding agent i. i.e., a−i = (a1, . . . , ai−1, ai+1, . . . , an), then a success function must satisfy: ∀i ∈ N, ∀a−i ∈ A−i t(1, a−i) > t(0, a−i) Additionally, we assume that t(a) > 0 for any a ∈ A (or equivalently, t(0, 0, . . . , 0) > 0).",
                "Definition 1.",
                "The marginal <br>con</br>tribution of agent i, denoted by Δi, is the difference between the probability of success when i exerts effort and when he shirks.",
                "Δi(a−i) = t(1, a−i) − t(0, a−i) Note that since t is monotone, Δi is a strictly positive function.",
                "At this point we can already make some simple observations.",
                "The best action, ai ∈ Ai, of agent i can now be easily determined as a function of what the others do, a−i ∈ A−i, and his <br>con</br>tract pi.",
                "Claim 1.",
                "Given a profile of actions a−i, agent is best strategy is ai = 1 if pi ≥ ci Δi(a−i) , and is ai = 0 if pi ≤ ci Δi(a−i) . (In the case of equality the agent is indifferent between the two alternatives.)",
                "As pi ≥ ci Δi(a−i) if and only if ui(1, a−i) = pi ·t(1, a−i)−ci ≥ pi ·t(0, a−i) = ui(0, a−i), is best strategy is to choose ai = 1 in this case.",
                "This allows us to specify the <br>con</br>tracts that are the principals optimal, for inducing a given equilibrium.",
                "Observation 1.",
                "The best <br>con</br>tracts (for the principal) that induce a ∈ A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci Δi(a−i) for agent i who exerts effort (ai = 1).",
                "In this case, the expected utility of agent i who exerts effort is ci · t(1,a−i) Δi(a−i) − 1 , and 0 for an agent who shirk.",
                "The principals expected utility is given by u(a, v) = (v−P)·t(a), where P is the total payment in case of success, given by P = P i|ai=1 ci Δi(a−i) .",
                "We say that the principal <br>con</br>tracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ∈ A).",
                "The principals goal is to maximize his utility given his value v, i.e. to determine the profile of actions a∗ ∈ A, which gives the highest value of u(a, v) in equilibrium.",
                "Choosing a ∈ A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}).",
                "We call the set of agents S∗ that the principal <br>con</br>tracts with in a∗ (S∗ = {i|a∗ i = 1}) an optimal <br>con</br>tract for the principal at value v. We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ∈ A.",
                "A natural yardstick by which to measure this decision is the non-strategic case, i.e. when the agents need not be motivated but are rather <br>con</br>trolled directly by the principal (who also bears their costs).",
                "In this case the principal will simply choose the profile a ∈ A that optimizes the social welfare (global efficiency), t(a) · v − P i|ai=1 ci.",
                "The worst ratio between the social welfare in this non-strategic case and the social welfare for the profile a ∈ A chosen by the principal in the agency case, may be termed the price of unaccountability.",
                "Given a technology (t, c), let S∗ (v) denote the optimal <br>con</br>tract in the agency case and let S∗ ns(v) denote an optimal <br>con</br>tract in the non-strategic case, when the principals value is v. The social welfare for value v when the set S of agents is contracted is t(S) · v − P i∈S ci (in both the agency and non-strategic cases).",
                "Definition 2.",
                "The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non-strategic case and the agency case: POU(t, c) = Supv>0 t(S∗ ns(v)) · v − P i∈S∗ ns(v) ci t(S∗(v)) · v − P i∈S∗(v) ci In cases where several sets are optimal in the agency case, we take the worst set (i.e., the set that yields the lowest social welfare).",
                "When the technology (t, c) is clear in the <br>con</br>text we will use POU to denote the price of unaccountability for technology (t, c).",
                "Note that the POU is at least 1 for any technology.",
                "As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ∈ N. We denote a technology (t, c) with identical costs by (t, c).",
                "For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology. 2.3 Structured Technology Functions In order to be more <br>con</br>crete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks - we call these structured technology functions.",
                "This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions.",
                "In a structured technology function, each individual succeeds or fails in his own task independently.",
                "The projects success or failure depends, possibly in a complex way, on the set of successful sub-tasks.",
                "Thus we will assume a monotone Boolean function f : {0, 1}n → {0, 1} which denotes 21 whether the project succeeds as a function of the success of the n agents tasks (and is not determined by any set of n−1 agents).",
                "Additionally there are <br>con</br>stants 0 < γi < δi < 1, where γi denotes the probability of success for agent i if he does not exert effort, and δi (> γi) denotes the probability of success if he does exert effort.",
                "In order to reduce the number of parameters, we will restrict our attention to the case where γ1 = . . . = γn = γ and δ1 = . . . = δn = 1 − γ thus leaving ourselves with a single parameter γ s.t. 0 < γ < 1 2 .",
                "Under this structure, the technology function t is defined by t(a1, . . . , an) being the probability that f(x1, . . . , xn) = 1 where the bits x1, . . . , xn are chosen according to the following distribution: if ai = 0 then xi = 1 with probability γ and xi = 0 with probability 1 − γ; otherwise, i.e. if ai = 1, then xi = 1 with probability 1 − γ and xi = 0 with probability γ.",
                "We denote x = (x1, . . . , xn).",
                "The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f. In the most general case, the function f can be given by a general monotone Boolean circuit.",
                "An especially natural sub-class of functions in the structured technologies setting would be functions that can be represented as a read-once network - a graph with a given source and sink, where every edge is labeled by a different player.",
                "The project succeeds if the edges that belong to players whose task succeeded form a path between the source and the sink6 .",
                "A few simple examples should be in order here: 1.",
                "The AND technology: f(x1, . . . , xn) is the logical <br>con</br>junction of xi (f(x) = V i∈N xi).",
                "Thus the project succeeds only if all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(a).",
                "If m agents exert effort ( P i ai = m), then t(a) = tm = γn−m (1 − γ)m .",
                "E.g. for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = γ2 , t1 = t(01) = t(10) = γ(1 − γ), and t2 = t(11) = (1 − γ)2 . 2.",
                "The OR technology: f(x1, . . . , xn) is the logical disjunction of xi (f(x) = W i∈N xi).",
                "Thus the project succeeds if at least one of the agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 1(b).",
                "If m agents exert effort, then tm = 1 − γm (1 − γ)n−m .E.g. for two players, the technology function is given by t(00) = 1 − (1 − γ)2 , t(01) = t(10) = 1 − γ(1 − γ), and t(11) = 1 − γ2 . 3.",
                "The Or-of-Ands (OOA) technology: f(x) is the logical disjunction of <br>con</br>junctions.",
                "In the simplest case of equal-length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k).",
                "Thus the project succeeds if in at least one clause all agents succeed in their tasks.",
                "This is shown graphically as a read-once network in Figure 2(a).",
                "If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 − Q i(1 − γnl−mi (1 − γ)mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = 1 − (1 − γ2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = 1 − (1 − γ(1 − γ))(1 − γ2 ), and so on. 6 One may view this representation as directly corresponding to the project of delivering a message from the source to the sink in a real network of computers, with the edges being <br>con</br>trolled by selfish agents.",
                "Figure 1: Graphical representations of (a) AND and (b) OR technologies.",
                "Figure 2: Graphical representations of (a) OOA and (b) AOO technologies. 4.",
                "The And-of-Ors (AOO) technology: f(x) is the logical <br>con</br>junction of disjunctions.",
                "In the simplest case of equal-length clauses (denote by nl the number of clauses and by nc their length), f(x) = Vnl j=1( Wnc k=1 xj k).",
                "Thus the project succeeds if at least one agent from each disjunctive-form-clause succeeds in his tasks.",
                "This is shown graphically as a read-once network in Figure 2(b).",
                "If mi agents on clause i exert effort, then t(m1, ..., mnc ) = Q i(1 − γmi (1 − γ)nc−mi ).",
                "E.g. for four players, the technology function t(a1 1 a1 2, a2 1 a2 2) is given by t(00, 00) = (1 − (1 − γ)2 )2 , t(01, 00) = t(10, 00) = t(00, 01) = t(00, 10) = (1 − γ(1 − γ))(1 − (1 − γ)2 ), and so on. 5.",
                "The Majority technology: f(x) is 1 if a majority of the values xi are 1.",
                "Thus the project succeeds if most players succeed.",
                "The majority function, even on 3 inputs, can not be represented by a read-once network, but is easily represented by a monotone Boolean formula maj(x, y, z) = xy+yz+xz.",
                "In this case the technology function is given by t(000) = 3γ2 (1 − γ) + γ3 , t(001) = t(010) = t(100) = γ3 +2(1−γ)2 γ +γ2 (1−γ), etc. 3.",
                "ANALYSIS OF SOME ANONYMOUS TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players.",
                "I.e. t(a1, . . . , an) depends only on P i∈N ai (the number of agents that exert effort).",
                "A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents.",
                "Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA).",
                "As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n−m ), Δm = tm+1 − tm, pm = c Δm−1 and um = tm · (v − m · pm), for the case of identical cost c. 22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3: Number of agents in the optimal <br>con</br>tract of the AND (left) and OR (right) technologies with 3 players, as a function of γ and v. AND technology: either 0 or 3 agents are <br>con</br>tracted, and the transition value is monotonic in γ.",
                "OR technology: for any γ we can see all transitions. 3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case γ = 1/4 and c = 1.",
                "Example 1.",
                "AND technology with two agents, c = 1, γ = 1/4: we have t0 = γ2 = 1/16, t1 = γ(1 − γ) = 3/16, and t2 = (1 − γ)2 = 9/16 thus Δ0 = 1/8 and Δ1 = 3/8.",
                "The principal has 3 possibilities: <br>con</br>tracting with 0, 1, or 2 agents.",
                "Let us write down the expressions for his utility in these 3 cases: • 0 Agents: No agent is paid thus and the principals utility is u0 = t0 · v = v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8 on success and the principals utility is u1 = t1(v − p1) = 3v/16− 3/2. • 2 Agents: each agent is paid p2 = c/Δ1 = 8/3 on success, and the principals utility is u2 = t2(v−2p2) = 9v/16 − 3.",
                "Notice that the option of <br>con</br>tracting with one agent is always inferior to either <br>con</br>tracting with both or with none, and will never be taken by the principal.",
                "The principal will <br>con</br>tract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6.",
                "This should be <br>con</br>trasted with the non-strategic case in which the principal completely <br>con</br>trols the agents (and bears their costs) and thus simply optimizes globally.",
                "In this case the principal will make both agents exert effort whenever v ≥ 4.",
                "Thus for example, for v = 6 the globally optimal decision (non-strategic case) would give a global utility of 6 · 9/16 − 2 = 11/8 while the principals decision (in the agency case) would give a global utility of 3/8, giving a ratio of 11/3.",
                "It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below.",
                "Example 2.",
                "OR technology with two agents, c = 1, γ = 1/4: we have t0 = 1 − (1 − γ)2 = 7/16, t1 = 1 − γ(1 − γ) = 13/16, and t2 = 1 − γ2 = 15/16 thus Δ0 = 3/8 and Δ1 = 1/8.",
                "Let us write down the expressions for the principals utility in these three cases: • 0 Agents: No agent is paid and the principals utility is u0 = t0 · v = 7v/16. • 1 Agent: This agent is paid p1 = c/Δ0 = 8/3 on success and the principals utility is u1 = t1(v − p1) = 13v/16 − 13/6. • 2 Agents: each agent is paid p2 = c/Δ1 = 8 on success, and the principals utility is u2 = t2(v − 2p2) = 15v/16 − 15/2.",
                "Now <br>con</br>tracting with one agent is better than <br>con</br>tracting with none whenever v > 52/9 (and is equivalent for v = 52/9), and contracting with both agents is better than contracting with one agent whenever v > 128/3 (and is equivalent for v = 128/3), thus the principal will contract with no agent for 0 ≤ v ≤ 52/9, with one agent for 52/9 ≤ v ≤ 128/3, and with both agents for v ≥ 128/3.",
                "In the non-strategic case, in comparison, the principal will make a single agent exert effort for v > 8/3, and the se<br>con</br>d one exert effort as well when v > 8.",
                "It turns out that the price of unaccountability here is 19/13, and is achieved at v = 52/9, which is exactly the transition point from 0 to 1 <br>con</br>tracted agents in the agency case.",
                "This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]).",
                "Lemma 1.",
                "For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non-strategic cases.",
                "Proof sketch: We look at all transition points in both cases.",
                "For any value lower than the first transition point, 0 agents are <br>con</br>tracted in both cases, and the social welfare ratio is 1.",
                "Similarly, for any value higher than the last transition point, n agents are <br>con</br>tracted in both cases, and the social welfare ratio is 1.",
                "Thus, we can focus on the interval between the first and last transition points.",
                "Between any pair of <br>con</br>secutive points, the social welfare ratio is between two linear functions of v (the optimal <br>con</br>tracts are fixed on such a segment).",
                "We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point).",
                "As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio. 2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents): in the first case either all agents are <br>con</br>tracted or none, while in the se<br>con</br>d case, for some intermediate range of values v, exactly one agent is contracted.",
                "Figure 3 shows the same phenomena for AND and OR technologies with 3 players.",
                "Theorem 1.",
                "For any anonymous AND technology7 : • there exists a value8 v∗ < ∞ such that for any v < v∗ it is optimal to <br>con</br>tract with no agent, for v > v∗ it is optimal to <br>con</br>tract with all n agents, and for v = v∗, both contracts (0, n) are optimal. 7 AND technology with any number of agents n and any γ, and any identical cost c. 8 v∗ is a function of n, γ, c. 23 • the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 γ − 1 ´n−1 + (1 − γ 1 − γ ) Proof sketch: For any fixed number of contracted agents, k, the principals utility is a linear function in v, where the slope equals the success probability under k contracted agents.",
                "Thus, the optimal <br>con</br>tract corresponds to the maximum over a set of linear functions.",
                "Let v∗ denote the point at which the principal is indifferent between <br>con</br>tracting with 0 or n agents.",
                "In [2] we show that at v∗, the principals utility from <br>con</br>tracting with 0 (or n) agents is higher than his utility when <br>con</br>tracting with any number of agents k ∈ {1, . . . , n − 1}.",
                "As the number of <br>con</br>tracted agents is monotonic non-decreasing in the value (due to Lemma 3), for any v < v∗, <br>con</br>tracting with 0 agents is optimal, and for any v > v∗, contracting with n agents is optimal.",
                "This is true for both the agency and the non-strategic cases.",
                "As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below.",
                "For AND technology tn−1 t0 = (1−γ)n−1 ·γ γn = 1 γ − 1 n−1 and tn−1 tn = (1−γ)n−1 ·γ (1−γ)n = γ 1−γ , and the expressions for the POU follows. 2 In [2] we present a general characterization of technologies with a single transition in the agency and the non-strategic cases, and provide a full proof of Theorem 1 as a special case.",
                "The property of a single transition occurs in both the agency and the non-strategic cases, where the transition occurs at a smaller value of v in the non-strategic case.",
                "Notice that the POU is not bounded across the AND family of technologies (for various n, γ) as POU → ∞ either if γ → 0 (for any given n ≥ 2) or n → ∞ (for any fixed γ ∈ (0, 1 2 )).",
                "Next we <br>con</br>sider the OR technology and show that it exhibits all n transitions.",
                "Theorem 2.",
                "For any anonymous OR technology, there exist finite positive values v1 < v2 < . . . < vn such that for any v s.t. vk < v < vk+1, <br>con</br>tracting with exactly k agents is optimal (for v < v1, no agent is <br>con</br>tracted, and for v > vn, all n agents are contracted).",
                "For v = vk, the principal is indifferent between <br>con</br>tracting with k − 1 or k agents.",
                "Proof sketch: To prove the claim we define vk to be the value for which the principal is indifferent between <br>con</br>tracting with k − 1 agents, and <br>con</br>tracting with k agents.",
                "We then show that for any k, vk < vk+1.",
                "As the number of <br>con</br>tracted agents is monotonic non-decreasing in the value (due to Lemma 3), v1 < v2 < . . . < vn is a sufficient <br>con</br>dition for the theorem to hold. 2 The same behavior occurs in both the agency and the nonstrategic case.",
                "This characterization is a direct corollary of a more general characterization given in [2].",
                "While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze.",
                "Open Question 1.",
                "What is the POU for OR with n > 2 agents?",
                "Is it bounded by a <br>con</br>stant for every n?",
                "We are only able to determine the POU of the OR technology for the case of two agents [2].",
                "Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies.",
                "Observation 2.",
                "While in the AND technology the POU for n = 2 is not bounded from above (for γ → 0), the highest POU in OR technology with two agents is 2 (for γ → 0). 3.2 What Determines the Transitions?",
                "Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal <br>con</br>tract) in the agency and the non-strategic cases.",
                "However, this is not true in general.",
                "In [2] we provide a full characterization of the sufficient and necessary <br>con</br>ditions for general anonymous technologies to have a single transition and all n transitions.",
                "We find that the <br>con</br>ditions in the agency case are different than the ones in the non-strategic case.",
                "We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non-strategic cases (see full proof in [2]).",
                "Lemma 2.",
                "For any anonymous technology that has a single transition in both the agency and the non-strategic cases, the POU is given by: POU = 1 + tn−1 t0 − tn−1 tn and it is obtained at the transition point of the agency case.",
                "Proof sketch: Since the payments in the agency case are higher than in the non-strategic case, the transition point in the agency case occurs for a higher value than in the non-strategic case.",
                "Thus, there exists a region in which the optimal numbers of <br>con</br>tracted agents in the agency and the non-strategic cases are 0 and n, respectively.",
                "By Lemma 1 the POU is obtained at a transition point.",
                "As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case.",
                "The transition point in the agency case is the point at which the principal is indifferent between <br>con</br>tracting with 0 and with n agents, v∗ = c·n tn−t0 · tn tn−tn−1 .",
                "Substituting the transition point of the agency case into the POU expression yields the required expression.",
                "POU = v∗ · tn − c · n v∗ · t0 = 1 + tn−1 t0 − tn−1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3).",
                "We are unable to characterize the transition behavior of the MAJORITY technology analytically.",
                "Figure 4 presents the optimal number of <br>con</br>tracted agents as a function of v and γ, for n = 5.",
                "The phenomena that we observe in this example (and others that we looked at) leads us to the following <br>con</br>jecture.",
                "Conjecture 1.",
                "For any Majority technology (any n, γ and c), there exists l, 1 ≤ l ≤ n/2 such that the first transition is from 0 to l agents, and then all the remaining n − l transitions exist. 24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4: Simulations results showing the number of agents in the optimal <br>con</br>tract of the MAJORITY technology with 5 players, as a function of γ and v. As γ decreases the first transition is at a lower value and to a higher number of agents.",
                "For any sufficiently small γ, the first transition is to 3 = 5/2 agents, and for any sufficiently large γ, the first transition is to 1 agents.",
                "For any γ, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions.",
                "Moreover, for any fixed c, n, l = 1 when γ is close enough to 1 2 , l is a non-decreasing function of γ (with image {1, . . . , n/2 }), and l = n/2 when γ is close enough to 0. 4.",
                "NON-ANONYMOUS TECHNOLOGIES In non-anonymous technologies (even with identical costs), we need to talk about the <br>con</br>tracted set of agents and not only about the number of <br>con</br>tracted agents.",
                "In this section, we identify the sets of agents that can be obtained as the optimal <br>con</br>tract for some v. These sets <br>con</br>struct the orbit of a technology.",
                "Definition 3.",
                "For a technology t, a set of agents S is in the orbit of t if for some value v, the optimal <br>con</br>tract is exactly with the set S of agents (where ties between different Ss are broken according to a lexicographic order9 ).",
                "The korbit of t is the collection of sets of size exactly k in the orbit.",
                "Observe that in the non-strategic case the k-orbit of any technology with identical cost c is of size at most 1 (as all sets of size k has the same cost, only the one with the maximal probability can be on the orbit).",
                "Thus, the orbit of any such technology in the non-strategic case is of size at most n + 1.",
                "We show that the picture in the agency case is very different.",
                "A basic observation is that the orbit of a technology is actually an ordered list of sets of agents, where the order is determined by the following lemma.",
                "Lemma 3. ( Monotonicity lemma) For any technology (t, c), in both the agency and the non-strategic cases, the 9 This implies that there are no two sets with the same success probability in the orbit. expected utility of the principal at the optimal <br>con</br>tracts, the success probability of the optimal <br>con</br>tracts, and the expected payment of the optimal contract, are all monotonically nondecreasing with the value.",
                "Proof.",
                "Suppose the sets of agents S1 and S2 are optimal in v1 and v2 < v1, respectively.",
                "Let Q(S) denote the expected total payment to all agents in S in the case that the principal <br>con</br>tracts with the set S and the project succeeds (for the agency case, Q(S) = t(S) · P i∈S ci t(S)−t(S\\i) , while for the non-strategic case Q(S) = P i∈S ci).",
                "The principals utility is a linear function of the value, u(S, v) = t(S)·v−Q(S).",
                "As S1 is optimal at v1, u(S1, v1) ≥ u(S2, v1), and as t(S2) ≥ 0 and v1 > v2, u(S2, v1) ≥ u(S2, v2).",
                "We <br>con</br>clude that u(S1, v1) ≥ u(S2, v2), thus the utility is monotonic non-decreasing in the value.",
                "Next we show that the success probability is monotonic non-decreasing in the value.",
                "S1 is optimal at v1, thus: t(S1) · v1 − Q(S1) ≥ t(S2) · v1 − Q(S2) S2 is optimal at v2, thus: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) Summing these two equations, we get that (t(S1) − t(S2)) · (v1 − v2) ≥ 0, which implies that if v1 > v2 than t(S1) ≥ t(S2).",
                "Finally we show that the expected payment is monotonic non-decreasing in the value.",
                "As S2 is optimal at v2 and t(S1) ≥ t(S2), we observe that: t(S2) · v2 − Q(S2) ≥ t(S1) · v2 − Q(S1) ≥ t(S2) · v2 − Q(S1) or equivalently, Q(S2) ≤ Q(S1), which is what we wanted to show. 4.1 AOO and OOA Technologies We begin our discussion of non-anonymous technologies with two examples; the And-of-Ors (AOO) and Or-of-Ands (OOA) technologies.",
                "The AOO technology (see figure 2) is composed of multiple OR-components that are Anded together.",
                "Theorem 3.",
                "Let h be an anonymous OR technology, and let f = Vnc j=1 h be the AOO technology that is obtained by a <br>con</br>junction of nc of these OR-components on disjoint inputs.",
                "Then for any value v, an optimal <br>con</br>tract <br>con</br>tracts with the same number of agents in each OR-component.",
                "Thus, the orbit of f is of size at most nl + 1, where nl is the number of agents in h. Part of the proof of the theorem (for the complete proof see [2]), is based on such AOO technology being a special case of a more general family of technologies, in which disjoint anonymous technologies are And-ed together, as explained in the next section.",
                "We <br>con</br>jecture that a similar result holds for the OOA technology.",
                "Conjecture 2.",
                "In an OOA technology which is a disjunction of the same anonymous paths (with the same number of agents, γ and c, but over disjoint inputs), for any value v the optimal <br>con</br>tract is <br>con</br>structed from some number of fully-contracted paths.",
                "Moreover, there exist v1 < . . . < vnl such that for any v, vi ≤ v ≤ vi+1, exactly i paths are <br>con</br>tracted.",
                "We are unable to prove it in general, but can prove it for the case of an OOA technology with two paths of length two (see [2]). 25 4.2 Orbit Characterization The AOO is an example of a technology whose orbit size is linear in its number of agents.",
                "If <br>con</br>jecture 2 is true, the same holds for the OOA technology.",
                "What can be said about the orbit size of a general non-anonymous technology?",
                "In case of identical costs, it is impossible for all subsets of agents to be on the orbit.",
                "This holds by the observation that the 1-orbit (a single agent that exerts effort) is of size at most 1.",
                "Only the agent that gives the highest success probability (when only he exerts effort) can be on the orbit (as he also needs to be paid the least).",
                "Nevertheless, we next show that the orbit can have exponential size.",
                "A collection of sets of k elements (out of n) is admissible, if every two sets in the collection differ by at least 2 elements (e.g. for k=3, 123 and 234 can not be together in the collection, but 123 and 345 can be).",
                "Theorem 4.",
                "Every admissible collection can be obtained as the k − orbit of some t. Proof sketch: The proof is <br>con</br>structive.",
                "Let S be some admissible collection of k-size sets.",
                "For each set S ∈ S in the collection we pick S, such that for any two admissible sets Si = Sj, Si = Sj .",
                "We then define the technology function t as follows: for any S ∈ S, t(S) = 1/2 − S and ∀i ∈ S, t(S \\ i) = 1/2 − 2 S. Thus, the marginal <br>con</br>tribution of every i ∈ S is S. Note that since S is admissible, t is well defined, as for any two sets S, S ∈ S and any two agents i, j, S \\ i = S \\ j.",
                "For any other set Z, we define t(Z) in a way that ensures that the marginal <br>con</br>tribution of each agent in Z is a very small (the technical details appear in the full version).",
                "This completes the definition of t. We show that each admissible set S ∈ S is optimal at the value vS = ck 2 2 S .",
                "We first show that it is better than any other S ∈ S. At the value vS = ck 2 2 S , the set S that corresponds to S maximizes the utility of the principal.",
                "This result is obtained by taking the derivative of u(S, v).",
                "Therefore S yields a higher utility than any other S ∈ S. We also pick the range of S to ensure that at vS, S is better than any other set S \\ i s.t.",
                "S ∈ S. Now we are left to show that at vS, the set S yields a higher utility than any other set Z ∈ S. The <br>con</br>struction of t(Z) ensures this since the marginal <br>con</br>tribution of each agent in Z is such a small , that the payment is too high for the set to be optimal. 2 In [2] we present the full proof of the theorem, as well as the full proofs of all other claims presented in this section without such a proof.",
                "We next show that there exist very large admissible collections.",
                "Lemma 4.",
                "For any n ≥ k, there exists an admissible collection of k-size sets of size Ω( 1 n · `n k ´ ).",
                "Proof sketch: The proof is based on an error correcting code that corrects one bit.",
                "Such a code has a distance ≥ 3, thus admissible.",
                "It is known that there are such codes with Ω(2n /n) code words.",
                "To ensure that an appropriate fraction of these code words have weight k, we <br>con</br>struct a new code by XOR-ing each code word with a random word r. The properties of XOR ensure that the new code remains admissible.",
                "Each code word is now uniformly mapped to the whole cube, and thus its probability of having weight k is `n k ´ /2n .",
                "Thus the expected number of weight k words is Ω( `n k ´ /n), and for some r this expectation is achieved or exceeded. 2 For k = n/2 we can <br>con</br>struct an exponential size admissible collection, which by Theorem 4 can be used to build a technology with exponential size orbit.",
                "Corollary 1.",
                "There exists a technology (t, c) with orbit of size Ω( 2n n √ n ).",
                "Thus, we are able to <br>con</br>struct a technology with exponential orbit, but this technology is not a network technology or a structured technology.",
                "Open Question 2.",
                "Is there a Read Once network with exponential orbit?",
                "Is there a structured technology with exponential orbit?",
                "Nevertheless, so far, we have not seen examples of seriesparallel networks whose orbit size is larger than n + 1.",
                "Open Question 3.",
                "How big can the orbit size of a seriesparallel network be?",
                "We make the first step towards a solution of this question by showing that the size of the orbit of a <br>con</br>junction of two disjoint networks (taking the two in a serial) is at most the sum of the two networks orbit sizes.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "The optimal <br>con</br>tract for f for some v, denoted by S, is composed of some agents from the h-part and some from the g-part, call them T and R respectively.",
                "Lemma 5.",
                "Let S be an optimal <br>con</br>tract for f = g V h on v. Then, T is an optimal <br>con</br>tract for h on v · tg(R), and R is an optimal contract for g on v · th(T).",
                "Proof sketch: We exress the pricipals utility u(S, v) from <br>con</br>tracting with the set S when his value is v. We abuse notation and use the function to denote the technology as well.",
                "Let Δf i (S \\ i) denote the marginal <br>con</br>tribution of agent i ∈ S. Then, for any i ∈ T, Δf i (S \\ i) = g(R) · Δh i (T \\ i), and for any i ∈ R, Δf i (S \\ i) = h(T) · Δg i (R \\ i).",
                "By substituting these expressions and f(S) = h(T) · g(R), we derive that u(S, v) = h(T) g(R) · v − P i∈T ci Δh i (T \\i) + g(R) · P i∈R ci Δ g i (R\\i) .",
                "The first term is maximized at a set T that is optimal for h on the value g(R) · v, while the se<br>con</br>d term is independent of T and h. Thus, S is optimal for f on v if and only if T is an optimal <br>con</br>tract for h on v · tg(R).",
                "Similarly, we show that R is an optimal <br>con</br>tract for g on v · th(T). 2 Lemma 6.",
                "The real function v → th(T), where T is the h − part of an optimal <br>con</br>tract for f on v, is monotone non-decreasing (and similarly for the function v → tg(R)).",
                "Proof.",
                "Let S1 = T1 ∪ R1 be the optimal <br>con</br>tract for f on v1, and let S2 = T2 ∪R2 be the optimal <br>con</br>tract for f on v2 < v1.",
                "By Lemma 3 f(S1) ≥ f(S2), and since f = g · h, f(S1) = h(T1) · g(R1) ≥ h(T2) · g(R2) = f(S2).",
                "Assume in <br>con</br>tradiction that h(T1) < h(T2), then since h(T1)·g(R1) ≥ h(T2)·g(R2) this implies that g(R1) > g(R2).",
                "By Lemma 5, T1 is optimal for h on v1 · g(R1), and T2 is optimal for h on v2 ·g(R2).",
                "As v1 > v2 and g(R1) > g(R2), T1 is optimal for h on a larger value than T2, thus by Lemma 3, h(T1) ≥ h(T2), a <br>con</br>tradiction. 26 Based on Lemma 5 and Lemma 6, we obtain the following Lemma.",
                "For the full proof, see [2].",
                "Lemma 7.",
                "Let g and h be two Boolean functions on disjoint inputs and let f = g V h (i.e., take their networks in series).",
                "Suppose x and y are the respective orbit sizes of g and h; then, the orbit size of f is less or equal to x + y − 1.",
                "By induction we get the following corollary.",
                "Corollary 2.",
                "Assume that {(gj, cj )}m j=1 is a set of anonymous technologies on disjoint inputs, each with identical agent cost (all agents of technology gj has the same cost cj).",
                "Then the orbit of f = Vm j=1 gj is of size at most ( Pm j=1 nj ) − 1, where nj is the number of agents in technology gj (the orbit is linear in the number of agents).",
                "In particular, this holds for AOO technology where each OR-component is anonymous.",
                "It would also be interesting to <br>con</br>sider a disjunction of two Boolean functions.",
                "Open Question 4.",
                "Does Lemma 7 hold also for the Boolean function f = g W h (i.e., when the networks g, h are taken in parallel)?",
                "We <br>con</br>jecture that this is indeed the case, and that the corresponding Lemmas 5 and 7 exist for the OR case as well.",
                "If this is true, this will show that series-parallel networks have polynomial size orbit. 5.",
                "ALGORITHMIC ASPECTS Our analysis throughout the paper sheds some light on the algorithmic aspects of computing the best <br>con</br>tract.",
                "In this section we state these implications (for the proofs see [2]).",
                "We first <br>con</br>sider the general model where the technology function is given by an arbitrary monotone function t (with rational values), and we then <br>con</br>sider the case of structured technologies given by a network representation of the underlying Boolean function. 5.1 Binary-Outcome Binary-Action Technologies Here we assume that we are given a technology and value v as the input, and our output should be the optimal contract, i.e. the set S∗ of agents to be contracted and the contract pi for each i ∈ S∗ .",
                "In the general case, the success function t is of size exponential in n, the number of agents, and we will need to deal with that.",
                "In the special case of anonymous technologies, the description of t is only the n+1 numbers t0, . . . , tn, and in this case our analysis in section 3 completely suffices for computing the optimal <br>con</br>tract.",
                "Proposition 1.",
                "Given as input the full description of a technology (the values t0, . . . , tn and the identical cost c for an anonymous technology, or the value t(S) for all the 2n possible subsets S ⊆ N of the players, and a vector of costs c for non-anonymous technologies), the following can all be computed in polynomial time: • The orbit of the technology in both the agency and the non-strategic cases. • An optimal <br>con</br>tract for any given value v, for both the agency and the non-strategic cases. • The price of unaccountability POU(t, c).",
                "Proof.",
                "We prove the claims for the non-anonymous case, the proof for the anonymous case is similar.",
                "We first show how to <br>con</br>struct the orbit of the technology (the same procedure apply in both cases).",
                "To <br>con</br>struct the orbit we find all transition points and the sets that are in the orbit.",
                "The empty <br>con</br>tract is always optimal for v = 0.",
                "Assume that we have calculated the optimal <br>con</br>tracts and the transition points up to some transition point v for which S is an optimal <br>con</br>tract with the highest success probability.",
                "We show how to calculate the next transition point and the next optimal <br>con</br>tract.",
                "By Lemma 3 the next <br>con</br>tract on the orbit (for higher values) has a higher success probability (there are no two sets with the same success probability on the orbit).",
                "We calculate the next optimal <br>con</br>tract by the following procedure.",
                "We go over all sets T such that t(T) > t(S), and calculate the value for which the principal is indifferent between <br>con</br>tracting with T and <br>con</br>tracting with S. The minimal indifference value is the next transition point and the contract that has the minimal indifference value is the next optimal contract.",
                "Linearity of the utility in the value and monotonicity of the success probability of the optimal <br>con</br>tracts ensure that the above works.",
                "Clearly the above calculation is polynomial in the input size.",
                "Once we have the orbit, it is clear that an optimal <br>con</br>tract for any given value v can be calculated.",
                "We find the largest transition point that is not larger than the value v, and the optimal <br>con</br>tract at v is the set with the higher success probability at this transition point.",
                "Finally, as we can calculate the orbit of the technology in both the agency and the non-strategic cases in polynomial time, we can find the price of unaccountability in polynomial time.",
                "By Lemma 1 the price of unaccountability POU(t) is obtained at some transition point, so we only need to go over all transition points, and find the one with the maximal social welfare ratio.",
                "A more interesting question is whether if given the function t as a black box, we can compute the optimal <br>con</br>tract in time that is polynomial in n. We can show that, in general this is not the case: Theorem 5.",
                "Given as input a black box for a success function t (when the costs are identical), and a value v, the number of queries that is needed, in the worst case, to find the optimal <br>con</br>tract is exponential in n. Proof.",
                "Consider the following family of technologies.",
                "For some small > 0 and k = n/2 we define the success probability for a given set T as follows.",
                "If |T| < k, then t(T) = |T| · .",
                "If |T| > k, then t(T) = 1 − (n − |T|) · .",
                "For each set of agents ˆT of size k, the technology t ˆT is defined by t( ˆT) = 1 − (n − | ˆT|) · and t(T) = |T| · for any T = ˆT of size k. For the value v = c·(k + 1/2), the optimal <br>con</br>tract for t ˆT is ˆT (for the <br>con</br>tract ˆT the utility of the principal is about v −c·k = 1/2·c > 0, while for any other contract the utility is negative).",
                "If the algorithm queries about at most ` n n/2 ´ − 2 sets of size k, then it cannot always determine the optimal <br>con</br>tract (as any of the sets that it has not queried about might be the optimal one).",
                "We <br>con</br>clude that ` n n/2 ´ − 1 queries are needed to determine the optimal <br>con</br>tract, and this is exponential in n. 27 5.2 Structured Technologies In this section we will consider the natural representation of read-once networks for the underlying Boolean function.",
                "Thus the problem we address will be: The Optimal Contract Problem for Read Once Networks: Input: A read-once network G = (V, E), with two specific vertices s, t; rational values γe, δe for each player e ∈ E (and ce = 1), and a rational value v. Output: A set S of agents who should be <br>con</br>tracted in an optimal <br>con</br>tract.",
                "Let t(E) denote the probability of success when each edge succeeds with probability δe.",
                "We first notice that even computing the value t(E) is a hard problem: it is called the network reliability problem and is known to be #P − hard [8].",
                "Just a little effort will reveal that our problem is not easier: Theorem 6.",
                "The Optimal Contract Problem for Read Once Networks is #P-hard (under Turing reductions).",
                "Proof.",
                "We will show that an algorithm for this problem can be used to solve the network reliability problem.",
                "Given an instance of a network reliability problem < G, {ζe}e∈E > (where ζe denotes es probability of success), we define an instance of the optimal <br>con</br>tract problem as follows: first define a new graph G which is obtained by Anding G with a new player x, with γx very close to 1 2 and δx = 1 − γx.",
                "For the other edges, we let δe = ζe and γe = ζe/2.",
                "By choosing γx close enough to 1 2 , we can make sure that player x will enter the optimal <br>con</br>tract only for very large values of v, after all other agents are <br>con</br>tracted (if we can find the optimal contract for any value, it is easy to find a value for which in the original network the optimal contract is E, by keep doubling the value and asking for the optimal contract.",
                "Once we find such a value, we choose γx s.t. c 1−2γx is larger than that value).",
                "Let us denote βx = 1 − 2γx.",
                "The critical value of v where player x enters the optimal <br>con</br>tract of G , can be found using binary search over the algorithm that supposedly finds the optimal <br>con</br>tract for any network and any value.",
                "Note that at this critical value v, the principal is indifferent between the set E and E ∪ {x}.",
                "Now when we write the expression for this indifference, in terms of t(E) and Δt i(E) , we observe the following. t(E) · γx · v − X i∈E c γx · Δt i(E \\ i) ! = t(E)(1 − γx) v − X i∈E c (1 − γx) · Δt i(E \\ i) − c t(E) · βx ! if and only if t(E) = (1 − γx) · c (βx)2 · v thus, if we can always find the optimal <br>con</br>tract we are also able to compute the value of t(E).",
                "In <br>con</br>clusion, computing the optimal <br>con</br>tract in general is hard.",
                "These results suggest two natural research directions.",
                "The first avenue is to study families of technologies whose optimal <br>con</br>tracts can be computed in polynomial time.",
                "The se<br>con</br>d avenue is to explore approximation algorithms for the optimal <br>con</br>tract problem.",
                "A possible candidate for the first direction is the family of series-parallel networks, for which the network reliability problem (computing the value of t) is polynomial.",
                "Open Question 5.",
                "Can the optimal <br>con</br>tract problem for Read Once series-parallel networks be solved in polynomial time?",
                "We can only handle the non-trivial level of AOO networks: Lemma 8.",
                "Given a Read Once AND-of-OR network such that each OR-component is an anonymous technology, the optimal <br>con</br>tract problem can be solved in polynomial time.",
                "Acknowledgments.",
                "This work is supported by the Israel Science Foundation, the USA-Israel Binational Science Foundation, the Lady Davis Fellowship Trust, and by a National Science Foundation grant number ANI-0331659. 6.",
                "REFERENCES [1] M. Babaioff, M. Feldman, and N. Nisan.",
                "The Price of Purity and Free-Labor in Combinatorial Agency.",
                "In Working Paper, 2005. [2] M. Babaioff, M. Feldman, and N. Nisan.",
                "Combinatorial agency, 2006. www.sims.berkeley.edu/˜moshe/comb-agency.pdf. [3] M. Feldman, J. Chuang, I. Stoica, and S. Shenker.",
                "Hidden-action in multi-hop routing.",
                "In EC05, pages 117-126, 2005. [4] B. Holmstrom.",
                "Moral Hazard in Teams.",
                "Bell Journal of E<br>con</br>omics, 13:324-340, 1982. [5] A. Mass-Colell, M. Whinston, and J.",
                "Green.",
                "Microe<br>con</br>omic Theory.",
                "Oxford University Press, 1995. [6] N. Nisan and A. Ronen.",
                "Algorithmic mechanism design.",
                "Games and E<br>con</br>omic Behaviour, 35:166 - 196, 2001.",
                "A preliminary version appeared in STOC 1999. [7] C. Papadimitriou.",
                "Algorithms, Games, and the Internet.",
                "In Proceedings of 33rd STOC, pages 749-753, 2001. [8] J. S. Provan and M. O.",
                "Ball.",
                "The complexity of counting cuts and of computing the probability that a graph is <br>con</br>nected.",
                "SIAM J.",
                "Comput., 12(4):777-788, 1983. [9] A. Ronen and L. Wahrmann.",
                "Prediction Games.",
                "WINE, pages 129-140, 2005. [10] R. Smorodinsky and M. Tennenholtz.",
                "Sequential Information Elicitation in Multi-Agent Systems. 20th Conference on Uncertainty in AI, 2004. [11] R. Smorodinsky and M. Tennenholtz.",
                "Overcoming Free-Riding in Multi-Party Computations - The Anonymous Case.",
                "Forthcoming, GEB, 2005. [12] E. Winter.",
                "Incentives and Discrimination.",
                "American E<br>con</br>omic Review, 94:764-773, 2004. 28"
            ],
            "original_annotated_samples": [
                "Combinatorial Agency [Extended Abstract] ∗ Moshe Babaioff School of Information Management and Systems UC Berkeley Berkeley, CA, 94720 USA moshe@sims.berkeley.edu Michal Feldman School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan School of Engineering and Computer Science The Hebrew University of Jerusalem Jerusalem, 91904 Israel noam@cs.huji.ac.il ABSTRACT Much recent research <br>con</br>cerns systems, such as the Internet, whose components are owned and operated by different parties, each with his own selfish goal.",
                "Our model is a combinatorial variant of the classical principalagent problem from e<br>con</br>omic theory.",
                "The principal motivates the agents by offering to them a set of <br>con</br>tracts, which together put the agents in an equilibrium point of the induced game.",
                "Categories and Subject Descriptors J.4 [Social and Behavioral Sciences]: E<br>con</br>omics; K.4.4 [Electronic Commerce]: Payment schemes; C.2.4 [ComputerCommunication Networks]: Distributed Systems General Terms Design, E<br>con</br>omics, Theory 1.",
                "The analysis and design of protocols for this environment thus naturally needs to take into account the different selfish e<br>con</br>omic interests of the different participants."
            ],
            "translated_annotated_samples": [
                "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo <br>egoísta</br>.",
                "Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la <br>teoría económica</br>.",
                "El principal motiva a los agentes ofreciéndoles un conjunto de <br>contratos</br>, que juntos colocan a los agentes en un punto de equilibrio del juego inducido.",
                "Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: <br>Economía</br>; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, <br>Economía</br>, Teoría 1.",
                "El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes <br>intereses económicos</br> egoístas de los distintos participantes."
            ],
            "translated_text": "Agencia combinatoria [Resumen extendido] ∗ Moshe Babaioff Escuela de Gestión de Información y Sistemas UC Berkeley Berkeley, CA, 94720 EE. UU. moshe@sims.berkeley.edu Michal Feldman Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel mfeldman@cs.huji.ac.il Noam Nisan Escuela de Ingeniería e Informática Universidad Hebrea de Jerusalén Jerusalén, 91904 Israel noam@cs.huji.ac.il RESUMEN Mucha investigación reciente se centra en sistemas, como Internet, cuyos componentes son propiedad y están operados por diferentes partes, cada una con su propio objetivo <br>egoísta</br>. El campo del Diseño de Mecanismos Algorítmicos aborda el problema de la información privada mantenida por las diferentes partes en entornos computacionales. Este documento aborda un problema complementario en tales contextos: manejar las acciones ocultas que realizan las diferentes partes. Nuestro modelo es una variante combinatoria del clásico problema principal-agente de la <br>teoría económica</br>. En nuestro entorno, un director debe motivar a un equipo de agentes estratégicos para que realicen un esfuerzo costoso en su nombre, pero sus acciones están ocultas para él. Nuestro enfoque se centra en casos donde combinaciones complejas de los esfuerzos de los agentes influyen en el resultado. El principal motiva a los agentes ofreciéndoles un conjunto de <br>contratos</br>, que juntos colocan a los agentes en un punto de equilibrio del juego inducido. Presentamos modelos formales para este escenario, sugerimos y nos embarcamos en un análisis de algunos problemas básicos, pero dejamos muchas preguntas abiertas. Categorías y Descriptores de Asignaturas J.4 [Ciencias Sociales y del Comportamiento]: <br>Economía</br>; K.4.4 [Comercio Electrónico]: Esquemas de pago; C.2.4 [Redes de Comunicación de Computadoras]: Sistemas Distribuidos Términos Generales Diseño, <br>Economía</br>, Teoría 1. INTRODUCCIÓN 1.1 Antecedentes Una de las características más llamativas de las redes informáticas modernas, en particular de Internet, es que diferentes partes de ella son propiedad y están operadas por distintos individuos, empresas y organizaciones. El análisis y diseño de protocolos para este entorno debe tener en cuenta de manera natural los diferentes <br>intereses económicos</br> egoístas de los distintos participantes. ",
            "candidates": [],
            "error": [
                [
                    "egoísta",
                    "teoría económica",
                    "contratos",
                    "Economía",
                    "Economía",
                    "intereses económicos"
                ]
            ]
        }
    }
}