{
    "id": "H-64",
    "original_text": "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries. Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection. The goal of this discovery is twofold. First we desire a practical aid for information architects. Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces. The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text. In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations. Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1. INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 . Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces. To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques. In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site. The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]). Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems. The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections. By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures. Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site. Our approach combines supervised and unsupervised learning techniques. A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6]. But strictly supervised techniques [5] are inappropriate, too. Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal. Thus we hope to learn an additional set of concepts by letting the data speak for themselves. The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation. In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website. This section also describes evidence that this structure leaves room for improvement. Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text. Section 6 describes a two-part evaluation of the derived conceptual structures. Finally, we conclude in Section 7 by outlining upcoming work on the project. 2. STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad. Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences. The agencys website acts as a clearinghouse for this process. With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13]. The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics. In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 . The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate. Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2]. Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy. Within this subset of the collection, they might further eliminate documents published more than a year ago. Finally, they might request to see only documents published in PDF format. As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial. But successful implementations of the relation browser also rely on topical classification. This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access. Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website. As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories. These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether. However, this approach proved unsatisfactory. In personal meetings, BLS officials voiced dissatisfaction with the existing topics. Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space. In other words, the topics reflected official divisions rather than semantic clusters. The BLS agents suggested that re-designing this classification structure would be desirable. The agents misgivings were borne out in subsequent analysis. The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages. Thus there are 7 pages associated with Inflation. Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics). Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page. To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]). Figure 3 shows the resultant scree plot4 . Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank. During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0). What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues. The four largest eigenvlaues account for 62.2% of the total variance in the data. This fact suggests a high degree of redundancy among the topics. Topical redundancy is not in itself problematic. However, the documents in this very shallow classificatory structure are almost all gateways to more specific information. Thus the listing of the Producer Price Index under three categories could be confusing to the sites users. In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3. A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods. In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material. To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html. This led to a corpus of 15,165 documents. Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery. The problems with standard clustering are threefold. 1. Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2. Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc.), many documents terms provide noisy topical information. 3. For application to the relation browser, we require a small number (k ≈ 10) of topics. Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity. In light of these problems, we take a hybrid approach to topic discovery. First, we limit the clustering process to a sample of the entire collection, described in Section 4. Working on a focused subset of the data helps to overcome problems two and three, listed above. To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4. FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis. Let A be the n×p data matrix with n observations in p variables. Thus aij shows the measurement for the ith observation on the jth variable. As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation. Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance. Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject. Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]). However, k-means clustering requires that the researcher specify k, the number of clusters to define. When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal. This paramterization led to semantically intelligible clusters. However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons. Chief among these is the computational efficiency enjoyed by the k-means approach. Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms. In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser. Moreover, the granularity of these clusters was unsuitably fine. For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist. These words are certainly related, but they are related at a level of specificity far below what we sought. To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection. In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 . These are brief articles, written by BLS employees. BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency. The column is published daily, and each entry describes an important current issue in the BLS domain. The Editors Desk column has been written daily (five times per week) since 1998. As such, we operated on a set of N = 1279 documents. Limiting attention to these 1279 documents not only reduced the dimensionality of the problem. It also allowed the clustering process to learn on a relatively clean data set. While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc.), the Editors Desk documents are all written in clear, journalistic prose. Each document is highly topical, further aiding the discovery of termtopic relations. Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata. Each of the 1279 documents contains a list of one or more keywords. Additionally, a subset of the documents (1112) contained a subject heading. This metadata informed our learning and evaluation, as described in Section 6.1. 5. COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques. Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1). Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes. However, these clusters mark only the first step in a two-phase process of topic identification. At the end of the process, documentcluster affinity is measured by a real-valued number. Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck. We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs). All were implemented using McCallums BOW text classification library [14]. Prind is a probabilistic version of the Rocchio classification algorithm [9]. Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method. Like prind, naive Bayes attempts to classify documents into the most probable class. It is described in detail in [15]. Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10]. They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable. Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification. That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . . Ck. Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time. The output of this process is a score for every document in the collection on each of the automatically discovered topics. These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system. To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest. In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds. Also, evaluation of the utility of the learned topics for users will be undertaken. 6. EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects. To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments. During the first experiment we compared three methods of document representation for the clustering task. The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata. During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata. Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles. With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering. We hypothesized that keyword-based clustering would provide a useful model. But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations. To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively. Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector. These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data. To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20. As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions. To select a single integer value, we calculated which value of k led to the least variation in cluster size. This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters. Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10. Clusters based on document titles were constructed similarly. However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles. Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10. The dimensionality of the keyword-based clustering was very similar to that of the title-based approach. There were 299 keywords in the data, all of which were retained. The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index. It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS. Using the keywords, the documents were clustered into 10 classes. To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents. Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications. Like the keywords, subject headings were assigned to documents by BLS publishers. Unlike the keywords, however, subject headings were drawn from a controlled vocabulary. Our analysis began with the assumption that documents with the same subject headings should cluster together. To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique. Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class. Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents. As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned. These document-subject pairings formed the basis of our analysis. Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust. The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects. Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified. Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class. For instance, There were 92 documents whose subject heading was prices. Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster. Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6. Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56. Repeating this process for each topic across all three representations led to the contingency table shown in Table 2. The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions. Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001. Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords. The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio. Additionally, each cluster has been given a label by the researchers. Evaluating the results of clustering is notoriously difficult. In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions. Most problematic is the fact that we have assumed that each document belongs in only a single category. This assumption is certainly false. However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem. Analogically, this is akin to considering the location of books on a library shelf. Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health. The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects. This flattening obscures the multivalence of documents. We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser. The matter of roughly fourteen thousand unclassified documents remained to be addressed. To solve this problem, we trained the statistical classifiers described above in Section 5. For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class. All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters. The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av. Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model. To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents. During cross-validation the data are split randomly into n subsets (in this case n = 10). The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets. Cross validation is described in [15]. Using this methodology, we compared the performance of the three classification models described above. Table 4 gives the results from cross validation. Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance. Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation. Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small. In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set. For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class. Further, each query was limited to the domain www.bls.gov. For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google). This led to a training set of 4113 documents in the augmented model, as we call it below8 . Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32). As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment. The results of our cross validation experiment are encouraging. However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website. To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website. The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project. However, none of the reviewers had prior knowledge of the outcome of the classification before their participation. For the experiment, a random sample of 100 documents was drawn from the entire BLS collection. On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4]. Table 5: Human-Model Agreement on 100 Sample Docs. Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit. Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents. In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges. In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories. Thus a document with the correct class as its second choice would still be easily available to a user. Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes. There were 72 multiclass documents in our sample, as seen in Figure 4. The remaining 28 documents were assigned to 1 or 0 classes. Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50. The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole. However, the improvement afforded by the augmented model comes at some cost. In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes. Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model. For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable. But this is not necessarily the case in general. It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories. We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model. The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations. On the other hand, the naive Bayes classifier distributed classes more evenly across the topics. This behavior suggests areas for future improvement. Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations). This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7. CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here. Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time? Data mining and machine learning methods hold a great deal of promise with respect to this problem. Empirical methods of knowledge discovery can aid in the organization and retrieval of information. As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces. This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser. Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website. The goal of this initial stage is to discover the most basic and far-reaching topics in the collection. Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection. In the study reported here, this approach has demonstrated promise. In its favor, our approach is highly scalable. It also appears to give fairly good results. Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings. While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining. However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models. After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection. While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering. The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent. While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model. Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically. It also suggests that a more sophisticated modeling approach might yield 158 better results in the future. In upcoming work we will experiment with streamlining the two-phase technique described here. Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk. In current work we have defined algorithms to identify documents likely to help the topic discovery task. Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure. Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining. What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design. Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8. REFERENCES [1] A. Agresti. An Introduction to Categorical Data Analysis. Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman. Dynamic queries for information exploration: an implementation and evaluation. In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. ACM Press, 1999. [4] A. Blum and T. Mitchell. Combining labeled and unlabeled data with co-training. In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100. ACM Press, 1998. [5] H. Chen and S. Dumais. Hierarchical classification of web content. In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang. Implications of the recursive representation problem for automatic concept identification in on-line governmental information. In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery. How many clusters? which clustering method? answers via model-based cluster analysis. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn. Data clustering: a review. ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims. A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997. Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims. Text categorization with support vector machines: learning with many relevant features. In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Principal Component Analysis. Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw. Finding Groups in Data: an Introduction to Cluster Analysis. Wiley, 1990. [13] G. Marchionini and B. Brunk. Toward a general relation browser: a GUI for information architects. Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Machine Learning. McGraw Hill, 1997. [16] E. Rasmussen. Clustering algorithms. In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie. Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. The Nature of Statistical Learning Theory. Springer, 2000. 159",
    "original_translation": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159",
    "original_sentences": [
        "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
        "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
        "The goal of this discovery is twofold.",
        "First we desire a practical aid for information architects.",
        "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
        "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
        "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
        "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
        "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
        "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
        "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
        "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
        "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
        "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
        "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
        "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
        "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
        "Our approach combines supervised and unsupervised learning techniques.",
        "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
        "But strictly supervised techniques [5] are inappropriate, too.",
        "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
        "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
        "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
        "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
        "This section also describes evidence that this structure leaves room for improvement.",
        "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
        "Section 6 describes a two-part evaluation of the derived conceptual structures.",
        "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
        "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
        "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
        "The agencys website acts as a clearinghouse for this process.",
        "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
        "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
        "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
        "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
        "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
        "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
        "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
        "Finally, they might request to see only documents published in PDF format.",
        "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
        "But successful implementations of the relation browser also rely on topical classification.",
        "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
        "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
        "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
        "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
        "However, this approach proved unsatisfactory.",
        "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
        "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
        "In other words, the topics reflected official divisions rather than semantic clusters.",
        "The BLS agents suggested that re-designing this classification structure would be desirable.",
        "The agents misgivings were borne out in subsequent analysis.",
        "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
        "Thus there are 7 pages associated with Inflation.",
        "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
        "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
        "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
        "Figure 3 shows the resultant scree plot4 .",
        "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
        "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
        "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
        "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
        "This fact suggests a high degree of redundancy among the topics.",
        "Topical redundancy is not in itself problematic.",
        "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
        "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
        "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
        "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
        "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
        "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
        "This led to a corpus of 15,165 documents.",
        "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
        "The problems with standard clustering are threefold. 1.",
        "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
        "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
        "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
        "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
        "In light of these problems, we take a hybrid approach to topic discovery.",
        "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
        "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
        "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
        "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
        "Let A be the n×p data matrix with n observations in p variables.",
        "Thus aij shows the measurement for the ith observation on the jth variable.",
        "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
        "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
        "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
        "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
        "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
        "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
        "This paramterization led to semantically intelligible clusters.",
        "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
        "Chief among these is the computational efficiency enjoyed by the k-means approach.",
        "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
        "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
        "Moreover, the granularity of these clusters was unsuitably fine.",
        "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
        "These words are certainly related, but they are related at a level of specificity far below what we sought.",
        "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
        "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
        "These are brief articles, written by BLS employees.",
        "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
        "The column is published daily, and each entry describes an important current issue in the BLS domain.",
        "The Editors Desk column has been written daily (five times per week) since 1998.",
        "As such, we operated on a set of N = 1279 documents.",
        "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
        "It also allowed the clustering process to learn on a relatively clean data set.",
        "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
        "Each document is highly topical, further aiding the discovery of termtopic relations.",
        "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
        "Each of the 1279 documents contains a list of one or more keywords.",
        "Additionally, a subset of the documents (1112) contained a subject heading.",
        "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
        "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
        "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
        "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
        "However, these clusters mark only the first step in a two-phase process of topic identification.",
        "At the end of the process, documentcluster affinity is measured by a real-valued number.",
        "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
        "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
        "All were implemented using McCallums BOW text classification library [14].",
        "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
        "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
        "Like prind, naive Bayes attempts to classify documents into the most probable class.",
        "It is described in detail in [15].",
        "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
        "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
        "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
        "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
        "Ck.",
        "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
        "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
        "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
        "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
        "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
        "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
        "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
        "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
        "During the first experiment we compared three methods of document representation for the clustering task.",
        "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
        "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
        "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
        "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
        "We hypothesized that keyword-based clustering would provide a useful model.",
        "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
        "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
        "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
        "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
        "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
        "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
        "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
        "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
        "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
        "Clusters based on document titles were constructed similarly.",
        "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
        "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
        "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
        "There were 299 keywords in the data, all of which were retained.",
        "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
        "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
        "Using the keywords, the documents were clustered into 10 classes.",
        "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
        "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
        "Like the keywords, subject headings were assigned to documents by BLS publishers.",
        "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
        "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
        "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
        "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
        "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
        "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
        "These document-subject pairings formed the basis of our analysis.",
        "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
        "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
        "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
        "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
        "For instance, There were 92 documents whose subject heading was prices.",
        "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
        "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
        "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
        "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
        "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
        "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
        "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
        "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
        "Additionally, each cluster has been given a label by the researchers.",
        "Evaluating the results of clustering is notoriously difficult.",
        "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
        "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
        "This assumption is certainly false.",
        "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
        "Analogically, this is akin to considering the location of books on a library shelf.",
        "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
        "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
        "This flattening obscures the multivalence of documents.",
        "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
        "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
        "To solve this problem, we trained the statistical classifiers described above in Section 5.",
        "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
        "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
        "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
        "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
        "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
        "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
        "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
        "Cross validation is described in [15].",
        "Using this methodology, we compared the performance of the three classification models described above.",
        "Table 4 gives the results from cross validation.",
        "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
        "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
        "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
        "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
        "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
        "Further, each query was limited to the domain www.bls.gov.",
        "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
        "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
        "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
        "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
        "The results of our cross validation experiment are encouraging.",
        "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
        "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
        "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
        "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
        "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
        "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
        "Table 5: Human-Model Agreement on 100 Sample Docs.",
        "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
        "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
        "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
        "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
        "Thus a document with the correct class as its second choice would still be easily available to a user.",
        "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
        "There were 72 multiclass documents in our sample, as seen in Figure 4.",
        "The remaining 28 documents were assigned to 1 or 0 classes.",
        "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
        "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
        "However, the improvement afforded by the augmented model comes at some cost.",
        "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
        "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
        "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
        "But this is not necessarily the case in general.",
        "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
        "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
        "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
        "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
        "This behavior suggests areas for future improvement.",
        "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
        "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
        "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
        "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
        "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
        "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
        "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
        "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
        "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
        "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
        "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
        "In the study reported here, this approach has demonstrated promise.",
        "In its favor, our approach is highly scalable.",
        "It also appears to give fairly good results.",
        "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
        "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
        "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
        "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
        "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
        "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
        "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
        "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
        "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
        "In upcoming work we will experiment with streamlining the two-phase technique described here.",
        "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
        "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
        "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
        "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
        "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
        "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
        "REFERENCES [1] A. Agresti.",
        "An Introduction to Categorical Data Analysis.",
        "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
        "Dynamic queries for information exploration: an implementation and evaluation.",
        "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
        "Modern Information Retrieval.",
        "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
        "Combining labeled and unlabeled data with co-training.",
        "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
        "ACM Press, 1998. [5] H. Chen and S. Dumais.",
        "Hierarchical classification of web content.",
        "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
        "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
        "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
        "How many clusters? which clustering method? answers via model-based cluster analysis.",
        "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
        "Data clustering: a review.",
        "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
        "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
        "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
        "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
        "Text categorization with support vector machines: learning with many relevant features.",
        "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
        "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
        "Principal Component Analysis.",
        "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
        "Finding Groups in Data: an Introduction to Cluster Analysis.",
        "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
        "Toward a general relation browser: a GUI for information architects.",
        "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
        "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
        "Machine Learning.",
        "McGraw Hill, 1997. [16] E. Rasmussen.",
        "Clustering algorithms.",
        "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
        "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
        "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
        "The Nature of Statistical Learning Theory.",
        "Springer, 2000. 159"
    ],
    "translated_text_sentences": [
        "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas.",
        "Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección.",
        "El objetivo de este descubrimiento es doble.",
        "Primero deseamos una ayuda práctica para arquitectos de la información.",
        "Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas.",
        "El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo.",
        "En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo.",
        "Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1.",
        "INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland.",
        "Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras.",
        "Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático.",
        "En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio.",
        "El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]).",
        "Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente.",
        "El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones.",
        "Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia.",
        "Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia.",
        "Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado.",
        "Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6].",
        "Pero las técnicas estrictamente supervisadas [5] también son inapropiadas.",
        "Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo.",
        "Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos.",
        "El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior.",
        "En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS.",
        "Esta sección también describe evidencia de que esta estructura deja espacio para mejoras.",
        "A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo.",
        "La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas.",
        "Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2.",
        "ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero.",
        "Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas.",
        "El sitio web de la agencia actúa como un centro de intercambio para este proceso.",
        "Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13].",
        "El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas.",
        "En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats.",
        "El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses.",
        "Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2].",
        "Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía.",
        "Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año.",
        "Finalmente, podrían solicitar ver solo documentos publicados en formato PDF.",
        "Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial.",
        "Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática.",
        "Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos.",
        "Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web.",
        "Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías.",
        "Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones.",
        "Sin embargo, este enfoque resultó insatisfactorio.",
        "En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes.",
        "Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web.",
        "En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas.",
        "Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación.",
        "Las dudas de los agentes se confirmaron en el análisis posterior.",
        "Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas.",
        "Por lo tanto, hay 7 páginas asociadas con la Inflación.",
        "En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas).",
        "Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS.",
        "Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]).",
        "La Figura 3 muestra el gráfico de escombros resultante.",
        "Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango.",
        "Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0).",
        "Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores.",
        "Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos.",
        "Este hecho sugiere un alto grado de redundancia entre los temas.",
        "La redundancia temática no es problemática en sí misma.",
        "Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica.",
        "Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio.",
        "A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3.",
        "Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado.",
        "En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material.",
        "Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html.",
        "Esto dio lugar a un corpus de 15,165 documentos.",
        "Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel.",
        "Los problemas con el agrupamiento estándar son triples. 1.",
        "Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas.",
        "Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3.",
        "Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas.",
        "Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino.",
        "A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas.",
        "Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4.",
        "Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente.",
        "Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4.",
        "CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados.",
        "Sea A la matriz de datos n×p con n observaciones en p variables.",
        "Así, aij muestra la medición para la i-ésima observación en la variable j-ésima.",
        "Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster.",
        "Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana.",
        "Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema.",
        "El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]).",
        "Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir.",
        "Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo.",
        "Esta parametrización condujo a agrupaciones semánticamente inteligibles.",
        "Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones.",
        "Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias.",
        "Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos.",
        "En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos.",
        "Además, la granularidad de estos grupos era inadecuadamente fina.",
        "Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico.",
        "Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos.",
        "Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección.",
        "En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores.",
        "Estos son artículos breves, escritos por empleados de la BLS.",
        "Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia.",
        "La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS.",
        "La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998.",
        "Por lo tanto, trabajamos con un conjunto de N = 1279 documentos.",
        "Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema.",
        "También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio.",
        "Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario.",
        "Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos.",
        "Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes.",
        "Cada uno de los 1279 documentos contiene una lista de una o más palabras clave.",
        "Además, un subconjunto de los documentos (1112) contenía un encabezado de tema.",
        "Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5.",
        "COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto.",
        "Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1).",
        "La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases.",
        "Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases.",
        "Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real.",
        "Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck.",
        "Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs).",
        "Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14].",
        "Prind es una versión probabilística del algoritmo de clasificación Rocchio [9].",
        "Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación.",
        "Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable.",
        "Se describe detalladamente en [15].",
        "Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10].",
        "Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables.",
        "Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática.",
        "Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . .",
        "I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish?",
        "La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU.",
        "La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente.",
        "Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información.",
        "Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta.",
        "En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos.",
        "Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6.",
        "EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados.",
        "Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos.",
        "Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento.",
        "El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos.",
        "Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos.",
        "Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos.",
        "Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento.",
        "Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil.",
        "Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo.",
        "Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente.",
        "Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908.",
        "Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos.",
        "Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20.",
        "A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones.",
        "Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo.",
        "Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia.",
        "Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10.",
        "Los grupos basados en los títulos de los documentos fueron construidos de manera similar.",
        "Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos.",
        "Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10.",
        "La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos.",
        "Había 299 palabras clave en los datos, todas las cuales fueron retenidas.",
        "El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor.",
        "Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS.",
        "Usando las palabras clave, los documentos fueron agrupados en 10 clases.",
        "Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor.",
        "Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento.",
        "Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS.",
        "A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado.",
        "Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos.",
        "Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas.",
        "Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase.",
        "La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos.",
        "Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas.",
        "Estas combinaciones de documentos y temas formaron la base de nuestro análisis.",
        "Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas.",
        "La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas.",
        "Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó.",
        "Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase.",
        "Por ejemplo, había 92 documentos cuyo encabezado de tema era precios.",
        "Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo.",
        "Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6.",
        "Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56.",
        "Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2.",
        "La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión.",
        "Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001.",
        "Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores.",
        "Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades.",
        "Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores.",
        "Evaluar los resultados de la agrupación es notoriamente difícil.",
        "Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras.",
        "Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría.",
        "Esta suposición es ciertamente falsa.",
        "Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema.",
        "Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca.",
        "Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional.",
        "La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema.",
        "Esta aplanamiento oculta la multivalencia de los documentos.",
        "Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones.",
        "El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar.",
        "Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5.",
        "Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k.",
        "Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales.",
        "Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av.",
        "Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado.",
        "Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores.",
        "Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10).",
        "El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos.",
        "La validación cruzada se describe en [15].",
        "Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente.",
        "La tabla 4 muestra los resultados de la validación cruzada.",
        "Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento.",
        "Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación.",
        "Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño.",
        "Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado.",
        "Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase.",
        "Además, cada consulta estaba limitada al dominio www.bls.gov.",
        "Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google).",
        "Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación.",
        "La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32).",
        "Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento.",
        "Los resultados de nuestro experimento de validación cruzada son alentadores.",
        "Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS.",
        "Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS.",
        "La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat.",
        "Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación.",
        "Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS.",
        "En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4].",
        "Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra.",
        "El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado.",
        "Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores.",
        "En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos.",
        "En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías.",
        "Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario.",
        "Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases.",
        "Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4.",
        "Los 28 documentos restantes fueron asignados a 1 o 0 clases.",
        "Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50.",
        "La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad.",
        "Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo.",
        "En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección.",
        "Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado.",
        "Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible.",
        "Pero esto no es necesariamente el caso en general.",
        "También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías.",
        "Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado.",
        "La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones.",
        "Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas.",
        "Este comportamiento sugiere áreas para futuras mejoras.",
        "Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones).",
        "Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento.",
        "CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí.",
        "Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo?",
        "Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema.",
        "Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información.",
        "Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas.",
        "Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones.",
        "Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS.",
        "El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección.",
        "Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección.",
        "En el estudio reportado aquí, este enfoque ha demostrado promesa.",
        "A su favor, nuestro enfoque es altamente escalable.",
        "También parece dar resultados bastante buenos.",
        "Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos.",
        "Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos.",
        "Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados.",
        "Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección.",
        "Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento.",
        "La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes.",
        "Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos.",
        "En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática.",
        "También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro.",
        "En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí.",
        "En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores.",
        "En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas.",
        "Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado.",
        "El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto.",
        "Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces.",
        "Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8.",
        "REFERENCIAS [1] A. Agresti.",
        "Una introducción al análisis de datos categóricos.",
        "Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman.",
        "Consultas dinámicas para la exploración de información: una implementación y evaluación.",
        "En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto.",
        "Recuperación de información moderna.",
        "ACM Press, 1999. [4] A. Blum y T. Mitchell.",
        "Combinando datos etiquetados y no etiquetados con co-entrenamiento.",
        "En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100.",
        "ACM Press, 1998. [5] H. Chen y S. Dumais.",
        "Clasificación jerárquica de contenido web.",
        "En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang.",
        "Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea.",
        "En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery.",
        "¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos.",
        "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn.",
        "Agrupamiento de datos: una revisión.",
        "ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims.",
        "Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos.",
        "En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997.",
        "Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims.",
        "Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes.",
        "En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998.",
        "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
        "Análisis de Componentes Principales.",
        "Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw.",
        "Encontrando grupos en los datos: una introducción al análisis de clusters.",
        "Wiley, 1990. [13] G. Marchionini y B. Brunk.",
        "Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información.",
        "Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
        "Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
        "Aprendizaje automático.",
        "McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen.",
        "Algoritmos de agrupamiento.",
        "En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442.",
        "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie.",
        "Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
        "La naturaleza de la teoría del aprendizaje estadístico.",
        "Springer, 2000. 159\n\nSpringer, 2000. 159"
    ],
    "error_count": 4,
    "keys": {
        "machine learning technique": {
            "translated_key": "técnicas de aprendizaje automático",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of <br>machine learning technique</br>s for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and <br>machine learning technique</br>s.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of <br>machine learning technique</br>s for improving access to governmental information in complex digital libraries.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and <br>machine learning technique</br>s."
            ],
            "translated_annotated_samples": [
                "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de <br>técnicas de aprendizaje automático</br> para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas.",
                "Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de <br>técnicas de aprendizaje automático</br> para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "access": {
            "translated_key": "acceso",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving <br>access</br> to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user <br>access</br> to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING <br>access</br> TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing <br>access</br> to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that <br>access</br> to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information <br>access</br>.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve <br>access</br> to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving <br>access</br> to governmental information in complex digital libraries.",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user <br>access</br> to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "STRUCTURING <br>access</br> TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing <br>access</br> to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that <br>access</br> to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information <br>access</br>."
            ],
            "translated_annotated_samples": [
                "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el <br>acceso</br> a la información gubernamental en bibliotecas digitales complejas.",
                "Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de <br>acceso</br> de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras.",
                "ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero.",
                "Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar <br>acceso</br> a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el <br>acceso</br> a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13].",
                "Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el <br>acceso</br> a la información consciente de los metadatos."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el <br>acceso</br> a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de <br>acceso</br> de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar <br>acceso</br> a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el <br>acceso</br> a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el <br>acceso</br> a la información consciente de los metadatos. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "complex digital library": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to <br>complex digital library</br> content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "For the purposes of applying the relation browser to <br>complex digital library</br> content (where documents will be classified along multiple categories), the augmented model is preferable."
            ],
            "translated_annotated_samples": [
                "Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                []
            ]
        },
        "data-driven approach": {
            "translated_key": "enfoque basado en datos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a <br>data-driven approach</br>, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "To enable such models and interfaces, we propose a <br>data-driven approach</br>, based on data mining and machine learning techniques."
            ],
            "translated_annotated_samples": [
                "Para habilitar tales modelos e interfaces, proponemos un <br>enfoque basado en datos</br>, utilizando técnicas de minería de datos y aprendizaje automático."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un <br>enfoque basado en datos</br>, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "supervised and unsupervised learning technique": {
            "translated_key": "aprendizaje supervisado y no supervisado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines <br>supervised and unsupervised learning technique</br>s.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "Our approach combines <br>supervised and unsupervised learning technique</br>s."
            ],
            "translated_annotated_samples": [
                "Nuestro enfoque combina técnicas de <br>aprendizaje supervisado y no supervisado</br>."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de <br>aprendizaje supervisado y no supervisado</br>. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "bureau of labor statistics": {
            "translated_key": "Oficina de Estadísticas Laborales",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The <br>bureau of labor statistics</br> is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "STRUCTURING ACCESS TO THE BLS WEBSITE The <br>bureau of labor statistics</br> is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad."
            ],
            "translated_annotated_samples": [
                "ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La <br>Oficina de Estadísticas Laborales</br> es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La <br>Oficina de Estadísticas Laborales</br> es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "eigenvalue": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth <br>eigenvalue</br> versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 <br>eigenvalue</br> RankMEigenvalue RankM <br>eigenvalue</br> Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth <br>eigenvalue</br> versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 <br>eigenvalue</br> RankMEigenvalue RankM <br>eigenvalue</br> Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0)."
            ],
            "translated_annotated_samples": [
                "Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo <br>valor propio</br> versus su rango.",
                "Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los <br>valores propios</br> 16...65 = 0)."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo <br>valor propio</br> versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los <br>valores propios</br> 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    "valor propio",
                    "valores propios"
                ]
            ]
        },
        "bls collection": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the <br>bls collection</br> (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire <br>bls collection</br> contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the <br>bls collection</br>, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire <br>bls collection</br>.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "Due to the heterogeneity of the data housed in the <br>bls collection</br> (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "While the entire <br>bls collection</br> contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the <br>bls collection</br>, we combined document clustering with text classification techniques.",
                "For the experiment, a random sample of 100 documents was drawn from the entire <br>bls collection</br>."
            ],
            "translated_annotated_samples": [
                "Debido a la heterogeneidad de los datos alojados en la <br>colección de la BLS</br> (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3.",
                "Si bien toda la <br>colección de BLS</br> contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario.",
                "COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la <br>colección de BLS</br>, combinamos técnicas de agrupamiento de documentos con clasificación de texto.",
                "Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la <br>colección de BLS</br>."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la <br>colección de la BLS</br> (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la <br>colección de BLS</br> contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la <br>colección de BLS</br>, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la <br>colección de BLS</br>. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    "colección de la BLS",
                    "colección de BLS",
                    "colección de BLS",
                    "colección de BLS"
                ]
            ]
        },
        "k-means clustering": {
            "translated_key": "agrupamiento k-means",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, <br>k-means clustering</br> requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of <br>k-means clustering</br> to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "However, <br>k-means clustering</br> requires that the researcher specify k, the number of clusters to define.",
                "Topics based on full-text documents were derived by application of <br>k-means clustering</br> to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector."
            ],
            "translated_annotated_samples": [
                "Sin embargo, el <br>agrupamiento k-means</br> requiere que el investigador especifique k, el número de clústeres a definir.",
                "Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el <br>agrupamiento k-means</br> requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "multiway classification": {
            "translated_key": "clasificación de múltiples vías",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a <br>multiway classification</br>, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a <br>multiway classification</br>, where each document is classified into multiple categories."
            ],
            "translated_annotated_samples": [
                "En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una <br>clasificación de múltiples vías</br>, donde cada documento se clasifica en múltiples categorías."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una <br>clasificación de múltiples vías</br>, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "digital library": {
            "translated_key": "biblioteca digital",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular <br>digital library</br>-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex <br>digital library</br> content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "In particular, our work analyzes a particular <br>digital library</br>-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "For the purposes of applying the relation browser to complex <br>digital library</br> content (where documents will be classified along multiple categories), the augmented model is preferable."
            ],
            "translated_annotated_samples": [
                "En particular, nuestro trabajo analiza una <br>biblioteca digital</br> en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio.",
                "Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una <br>biblioteca digital</br> (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una <br>biblioteca digital</br> en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una <br>biblioteca digital</br> (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "machine learn": {
            "translated_key": "aprendizaje automático",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of <br>machine learn</br>ing techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and <br>machine learn</br>ing techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised <br>machine learn</br>ing methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and <br>machine learn</br>ing methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of <br>machine learn</br>ing techniques for improving access to governmental information in complex digital libraries.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and <br>machine learn</br>ing techniques.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised <br>machine learn</br>ing methods.",
                "Data mining and <br>machine learn</br>ing methods hold a great deal of promise with respect to this problem."
            ],
            "translated_annotated_samples": [
                "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de <br>aprendizaje automático</br> para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas.",
                "Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y <br>aprendizaje automático</br>.",
                "Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de <br>aprendizaje automático</br> no supervisado.",
                "Los métodos de minería de datos y <br>aprendizaje automático</br> prometen mucho con respecto a este problema."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de <br>aprendizaje automático</br> para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y <br>aprendizaje automático</br>. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de <br>aprendizaje automático</br> no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y <br>aprendizaje automático</br> prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "information architecture": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for <br>information architecture</br> in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level <br>information architecture</br> discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as <br>information architecture</br> and interface design.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "Machine Learning for <br>information architecture</br> in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level <br>information architecture</br> discovery.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as <br>information architecture</br> and interface design."
            ],
            "translated_annotated_samples": [
                "Aprendizaje automático para la <br>arquitectura de la información</br> en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas.",
                "Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de <br>arquitectura de información</br> de alto nivel.",
                "Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la <br>arquitectura de la información</br> y el diseño de interfaces."
            ],
            "translated_text": "Aprendizaje automático para la <br>arquitectura de la información</br> en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de <br>arquitectura de información</br> de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la <br>arquitectura de la información</br> y el diseño de interfaces. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    "arquitectura de la información",
                    "arquitectura de información",
                    "arquitectura de la información"
                ]
            ]
        },
        "interface design": {
            "translated_key": "diseño de interfaces",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Machine Learning for Information Architecture in a Large Governmental Website ∗ Miles Efron School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang School of Information & Library Science CB#3360, 100 Manning Hall University of North Carolina Chapel Hill, NC 27599-3360 junliang@email.unc.edu ABSTRACT This paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries.",
                "Under the auspices of the GovStat Project, our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection.",
                "The goal of this discovery is twofold.",
                "First we desire a practical aid for information architects.",
                "Second, automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces.",
                "The current study compares concept learning strategies based on three document representations: keywords, titles, and full-text.",
                "In statistical and user-based studies, human-created keywords provide significant improvements in concept learning over both title-only and full-text representations.",
                "Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: Digital Libraries-Systems Issues, User Issues; H.3.3 [Information Storage and Retrieval]: Information Search and RetrievalClustering General Terms Design, Experimentation 1.",
                "INTRODUCTION The GovStat Project is a joint effort of the University of North Carolina Interaction Design Lab and the University of Maryland Human-Computer Interaction Lab1 .",
                "Citing end-user difficulty in finding governmental information (especially statistical data) online, the project seeks to create an integrated model of user access to US government statistical information that is rooted in realistic data models and innovative user interfaces.",
                "To enable such models and interfaces, we propose a data-driven approach, based on data mining and machine learning techniques.",
                "In particular, our work analyzes a particular digital library-the website of the Bureau of Labor Statistics2 (BLS)-in efforts to discover a small number of linguistically meaningful concepts, or bins, that collectively summarize the semantic domain of the site.",
                "The project goal is to classify the sites web content according to these inferred concepts as an initial step towards data filtering via active user interfaces (cf. [13]).",
                "Many digital libraries already make use of content classification, both explicitly and implicitly; they divide their resources manually by topical relation; they organize content into hierarchically oriented file systems.",
                "The goal of the present 1 http://www.ils.unc.edu/govstat 2 http://www.bls.gov 151 research is to develop another means of browsing the content of these collections.",
                "By analyzing the distribution of terms across documents, our goal is to supplement the agencys pre-existing information structures.",
                "Statistical learning technologies are appealing in this context insofar as they stand to define a data-driven-as opposed to an agency-drivennavigational structure for a site.",
                "Our approach combines supervised and unsupervised learning techniques.",
                "A pure document clustering [12] approach to such a large, diverse collection as BLS led to poor results in early tests [6].",
                "But strictly supervised techniques [5] are inappropriate, too.",
                "Although BLS designers have defined high-level subject headings for their collections, as we discuss in Section 2, this scheme is less than optimal.",
                "Thus we hope to learn an additional set of concepts by letting the data speak for themselves.",
                "The remainder of this paper describes the details of our concept discovery efforts and subsequent evaluation.",
                "In Section 2 we describe the previously existing, human-created conceptual structure of the BLS website.",
                "This section also describes evidence that this structure leaves room for improvement.",
                "Next (Sections 3-5), we turn to a description of the concepts derived via content clustering under three document representations: keyword, title only, and full-text.",
                "Section 6 describes a two-part evaluation of the derived conceptual structures.",
                "Finally, we conclude in Section 7 by outlining upcoming work on the project. 2.",
                "STRUCTURING ACCESS TO THE BLS WEBSITE The Bureau of Labor Statistics is a federal government agency charged with compiling and publishing statistics pertaining to labor and production in the US and abroad.",
                "Given this broad mandate, the BLS publishes a wide array of information, intended for diverse audiences.",
                "The agencys website acts as a clearinghouse for this process.",
                "With over 15,000 text/html documents (and many more documents if spreadsheets and typeset reports are included), providing access to the collection provides a steep challenge to information architects. 2.1 The Relation Browser The starting point of this work is the notion that access to information in the BLS website could be improved by the addition of a dynamic interface such as the relation browser described by Marchionini and Brunk [13].",
                "The relation browser allows users to traverse complex data sets by iteratively slicing the data along several topics.",
                "In Figure 1 we see a prototype instantiation of the relation browser, applied to the FedStats website3 .",
                "The relation browser supports information seeking by allowing users to form queries in a stepwise fashion, slicing and re-slicing the data as their interests dictate.",
                "Its motivation is in keeping with Shneidermans suggestion that queries and their results should be tightly coupled [2].",
                "Thus in Fig3 http://www.fedstats.gov Figure 1: Relation Browser Prototype ure 1, users might limit their search set to those documents about energy.",
                "Within this subset of the collection, they might further eliminate documents published more than a year ago.",
                "Finally, they might request to see only documents published in PDF format.",
                "As Marchionini and Brunk discuss, capturing the publication date and format of documents is trivial.",
                "But successful implementations of the relation browser also rely on topical classification.",
                "This presents two stumbling blocks for system designers: • Information architects must define the appropriate set of topics for their collection • Site maintainers must classify each document into its appropriate categories These tasks parallel common problems in the metadata community: defining appropriate elements and marking up documents to support metadata-aware information access.",
                "Given a collection of over 15,000 documents, these hurdles are especially daunting, and automatic methods of approaching them are highly desirable. 2.2 A Pre-Existing Structure Prior to our involvement with the project, designers at BLS created a shallow classificatory structure for the most important documents in their website.",
                "As seen in Figure 2, the BLS home page organizes 65 top-level documents into 15 categories.",
                "These include topics such as Employment and Unemployment, Productivity, and Inflation and Spending. 152 Figure 2: The BLS Home Page We hoped initially that these pre-defined categories could be used to train a 15-way document classifier, thus automating the process of populating the relation browser altogether.",
                "However, this approach proved unsatisfactory.",
                "In personal meetings, BLS officials voiced dissatisfaction with the existing topics.",
                "Their form, it was argued, owed as much to the institutional structure of BLS as it did to the inherent topology of the websites information space.",
                "In other words, the topics reflected official divisions rather than semantic clusters.",
                "The BLS agents suggested that re-designing this classification structure would be desirable.",
                "The agents misgivings were borne out in subsequent analysis.",
                "The BLS topics comprise a shallow classificatory structure; each of the 15 top-level categories is linked to a small number of related pages.",
                "Thus there are 7 pages associated with Inflation.",
                "Altogether, the link structure of this classificatory system contains 65 documents; that is, excluding navigational links, there are 65 documents linked from the BLS home page, where each hyperlink connects a document to a topic (pages can be linked to multiple topics).",
                "Based on this hyperlink structure, we defined M, a symmetric 65×65 matrix, where mij counts the number of topics in which documents i and j are both classified on the BLS home page.",
                "To analyze the redundancy inherent in the pre-existing structure, we derived the principal components of M (cf. [11]).",
                "Figure 3 shows the resultant scree plot4 .",
                "Because all 65 documents belong to at least one BLS topic, 4 A scree plot shows the magnitude of the kth eigenvalue versus its rank.",
                "During principal component analysis scree plots visualize the amount of variance captured by each component. m00M0M 0 1010M10M 10 2020M20M 20 3030M30M 30 4040M40M 40 5050M50M 50 6060M60M 60 m00M0M 0 22M2M 2 44M4M 4 66M6M 6 88M8M 8 1010M10M 10 1212M12M 12 1414M14M 14 Eigenvalue RankMEigenvalue RankM Eigenvalue Rank Eigenvlue MagnitudeMEigenvlue MagnitudeM EigenvlueMagnitude Figure 3: Scree Plot of BLS Categories the rank of M is guaranteed to be less than or equal to 15 (hence, eigenvalues 16 . . . 65 = 0).",
                "What is surprising about Figure 3, however, is the precipitous decline in magnitude among the first four eigenvalues.",
                "The four largest eigenvlaues account for 62.2% of the total variance in the data.",
                "This fact suggests a high degree of redundancy among the topics.",
                "Topical redundancy is not in itself problematic.",
                "However, the documents in this very shallow classificatory structure are almost all gateways to more specific information.",
                "Thus the listing of the Producer Price Index under three categories could be confusing to the sites users.",
                "In light of this potential for confusion and the agencys own request for redesign, we undertook the task of topic discovery described in the following sections. 3.",
                "A HYBRID APPROACH TO TOPIC DISCOVERY To aid in the discovery of a new set of high-level topics for the BLS website, we turned to unsupervised machine learning methods.",
                "In efforts to let the data speak for themselves, we desired a means of concept discovery that would be based not on the structure of the agency, but on the content of the material.",
                "To begin this process, we crawled the BLS website, downloading all documents of MIME type text/html.",
                "This led to a corpus of 15,165 documents.",
                "Based on this corpus, we hoped to derive k ≈ 10 topical categories, such that each document di is assigned to one or more classes. 153 Document clustering (cf. [16]) provided an obvious, but only partial solution to the problem of automating this type of high-level information architecture discovery.",
                "The problems with standard clustering are threefold. 1.",
                "Mutually exclusive clusters are inappropriate for identifying the topical content of documents, since documents may be about many subjects. 2.",
                "Due to the heterogeneity of the data housed in the BLS collection (tables, lists, surveys, etc. ), many documents terms provide noisy topical information. 3.",
                "For application to the relation browser, we require a small number (k ≈ 10) of topics.",
                "Without significant data reduction, term-based clustering tends to deliver clusters at too fine a level of granularity.",
                "In light of these problems, we take a hybrid approach to topic discovery.",
                "First, we limit the clustering process to a sample of the entire collection, described in Section 4.",
                "Working on a focused subset of the data helps to overcome problems two and three, listed above.",
                "To address the problem of mutual exclusivity, we combine unsupervised with supervised learning methods, as described in Section 5. 4.",
                "FOCUSING ON CONTENT-RICH DOCUMENTS To derive empirically evidenced topics we initially turned to cluster analysis.",
                "Let A be the n×p data matrix with n observations in p variables.",
                "Thus aij shows the measurement for the ith observation on the jth variable.",
                "As described in [12], the goal of cluster analysis is to assign each of the n observations to one of a small number k groups, each of which is characterized by high intra-cluster correlation and low inter-cluster correlation.",
                "Though the algorithms for accomplishing such an arrangement are legion, our analysis focuses on k-means clustering5 , during which, each observation oi is assigned to the cluster Ck whose centroid is closest to it, in terms of Euclidean distance.",
                "Readers interested in the details of the algorithm are referred to [12] for a thorough treatment of the subject.",
                "Clustering by k-means is well-studied in the statistical literature, and has shown good results for text analysis (cf. [8, 16]).",
                "However, k-means clustering requires that the researcher specify k, the number of clusters to define.",
                "When applying k-means to our 15,000 document collection, indicators such as the gap statistic [17] and an analysis of the mean-squared distance across values of k suggested that k ≈ 80 was optimal.",
                "This paramterization led to semantically intelligible clusters.",
                "However, 80 clusters are far too many for application to an interface such as the relation 5 We have focused on k-means as opposed to other clustering algorithms for several reasons.",
                "Chief among these is the computational efficiency enjoyed by the k-means approach.",
                "Because we need only a flat clustering there is little to be gained by the more expensive hierarchical algorithms.",
                "In future work we will turn to model-based clustering [7] as a more principled method of selecting the number of clusters and of representing clusters. browser.",
                "Moreover, the granularity of these clusters was unsuitably fine.",
                "For instance, the 80-cluster solution derived a cluster whose most highly associated words (in terms of log-odds ratio [1]) were drug, pharmacy, and chemist.",
                "These words are certainly related, but they are related at a level of specificity far below what we sought.",
                "To remedy the high dimensionality of the data, we resolved to limit the algorithm to a subset of the collection.",
                "In consultation with employees of the BLS, we continued our analysis on documents that form a series titled From the Editors Desk6 .",
                "These are brief articles, written by BLS employees.",
                "BLS agents suggested that we focus on the Editors Desk because it is intended to span the intellectual domain of the agency.",
                "The column is published daily, and each entry describes an important current issue in the BLS domain.",
                "The Editors Desk column has been written daily (five times per week) since 1998.",
                "As such, we operated on a set of N = 1279 documents.",
                "Limiting attention to these 1279 documents not only reduced the dimensionality of the problem.",
                "It also allowed the clustering process to learn on a relatively clean data set.",
                "While the entire BLS collection contains a great deal of nonprose text (i.e. tables, lists, etc. ), the Editors Desk documents are all written in clear, journalistic prose.",
                "Each document is highly topical, further aiding the discovery of termtopic relations.",
                "Finally, the Editors Desk column provided an ideal learning environment because it is well-supplied with topical metadata.",
                "Each of the 1279 documents contains a list of one or more keywords.",
                "Additionally, a subset of the documents (1112) contained a subject heading.",
                "This metadata informed our learning and evaluation, as described in Section 6.1. 5.",
                "COMBINING SUPERVISED AND UNSUPERVISED LEARNING FORTOPIC DISCOVERY To derive suitably general topics for the application of a dynamic interface to the BLS collection, we combined document clustering with text classification techniques.",
                "Specifically, using k-means, we clustered each of the 1279 documents into one of k clusters, with the number of clusters chosen by analyzing the within-cluster mean squared distance at different values of k (see Section 6.1).",
                "Constructing mutually exclusive clusters violates our assumption that documents may belong to multiple classes.",
                "However, these clusters mark only the first step in a two-phase process of topic identification.",
                "At the end of the process, documentcluster affinity is measured by a real-valued number.",
                "Once the Editors Desk documents were assigned to clusters, we constructed a k-way classifier that estimates the strength of evidence that a new document di is a member of class Ck.",
                "We tested three statistical classification techniques: probabilistic Rocchio (prind), naive Bayes, and support vector machines (SVMs).",
                "All were implemented using McCallums BOW text classification library [14].",
                "Prind is a probabilistic version of the Rocchio classification algorithm [9].",
                "Interested readers are referred to Joachims article for 6 http://www.bls.gov/opub/ted 154 further details of the classification method.",
                "Like prind, naive Bayes attempts to classify documents into the most probable class.",
                "It is described in detail in [15].",
                "Finally, support vector machines were thoroughly explicated by Vapnik [18], and applied specifically to text in [10].",
                "They define a decision boundary by finding the maximally separating hyperplane in a high-dimensional vector space in which document classes become linearly separable.",
                "Having clustered the documents and trained a suitable classifier, the remaining 14,000 documents in the collection are labeled by means of automatic classification.",
                "That is, for each document di we derive a k-dimensional vector, quantifying the association between di and each class C1 . . .",
                "Ck.",
                "Deriving topic scores via naive Bayes for the entire 15,000document collection required less than two hours of CPU time.",
                "The output of this process is a score for every document in the collection on each of the automatically discovered topics.",
                "These scores may then be used to populate a relation browser interface, or they may be added to a traditional information retrieval system.",
                "To use these weights in the relation browser we currently assign to each document the two topics on which it scored highest.",
                "In future work we will adopt a more rigorous method of deriving documenttopic weight thresholds.",
                "Also, evaluation of the utility of the learned topics for users will be undertaken. 6.",
                "EVALUATION OF CONCEPT DISCOVERY Prior to implementing a relation browser interface and undertaking the attendant user studies, it is of course important to evaluate the quality of the inferred concepts, and the ability of the automatic classifier to assign documents to the appropriate subjects.",
                "To evaluate the success of the two-stage approach described in Section 5, we undertook two experiments.",
                "During the first experiment we compared three methods of document representation for the clustering task.",
                "The goal here was to compare the quality of document clusters derived by analysis of full-text documents, documents represented only by their titles, and documents represented by human-created keyword metadata.",
                "During the second experiment, we analyzed the ability of the statistical classifiers to discern the subject matter of documents from portions of the database in addition to the Editors Desk. 6.1 Comparing Document Representations Documents from The Editors Desk column came supplied with human-generated keyword metadata.",
                "Additionally, The titles of the Editors Desk documents tend to be germane to the topic of their respective articles.",
                "With such an array of distilled evidence of each documents subject matter, we undertook a comparison of document representations for topic discovery by clustering.",
                "We hypothesized that keyword-based clustering would provide a useful model.",
                "But we hoped to see whether comparable performance could be attained by methods that did not require extensive human indexing, such as the title-only or full-text representations.",
                "To test this hypothesis, we defined three modes of document representation-full-text, title-only, and keyword only-we generated three sets of topics, Tfull, Ttitle, and Tkw, respectively.",
                "Topics based on full-text documents were derived by application of k-means clustering to the 1279 Editors Desk documents, where each document was represented by a 1908dimensional vector.",
                "These 1908 dimensions captured the TF.IDF weights [3] of each term ti in document dj, for all terms that occurred at least three times in the data.",
                "To arrive at the appropriate number of clusters for these data, we inspected the within-cluster mean-squared distance for each value of k = 1 . . . 20.",
                "As k approached 10 the reduction in error with the addition of more clusters declined notably, suggesting that k ≈ 10 would yield good divisions.",
                "To select a single integer value, we calculated which value of k led to the least variation in cluster size.",
                "This metric stemmed from a desire to suppress the common result where one large cluster emerges from the k-means algorithm, accompanied by several accordingly small clusters.",
                "Without reason to believe that any single topic should have dramatically high prior odds of document membership, this heuristic led to kfull = 10.",
                "Clusters based on document titles were constructed similarly.",
                "However, in this case, each document was represented in the vector space spanned by the 397 terms that occur at least twice in document titles.",
                "Using the same method of minimizing the variance in cluster membership ktitle-the number of clusters in the title-based representation-was also set to 10.",
                "The dimensionality of the keyword-based clustering was very similar to that of the title-based approach.",
                "There were 299 keywords in the data, all of which were retained.",
                "The median number of keywords per document was 7, where a keyword is understood to be either a single word, or a multiword term such as consumer price index.",
                "It is worth noting that the keywords were not drawn from any controlled vocabulary; they were assigned to documents by publishers at the BLS.",
                "Using the keywords, the documents were clustered into 10 classes.",
                "To evaluate the clusters derived by each method of document representation, we used the subject headings that were included with 1112 of the Editors Desk documents.",
                "Each of these 1112 documents was assigned one or more subject headings, which were withheld from all of the cluster applications.",
                "Like the keywords, subject headings were assigned to documents by BLS publishers.",
                "Unlike the keywords, however, subject headings were drawn from a controlled vocabulary.",
                "Our analysis began with the assumption that documents with the same subject headings should cluster together.",
                "To facilitate this analysis, we took a conservative approach; we considered multi-subject classifications to be unique.",
                "Thus if document di was assigned to a single subject prices, while document dj was assigned to two subjects, international comparisons, prices, documents di and dj are not considered to come from the same class.",
                "Table 1 shows all Editors Desk subject headings that were assigned to at least 10 documents.",
                "As noted in the table, 155 Table 1: Top Editors Desk Subject Headings Subject Count prices 92 unemployment 55 occupational safety & health 53 international comparisons, prices 48 manufacturing, prices 45 employment 44 productivity 40 consumer expenditures 36 earnings & wages 27 employment & unemployment 27 compensation costs 25 earnings & wages, metro. areas 18 benefits, compensation costs 18 earnings & wages, occupations 17 employment, occupations 14 benefits 14 earnings & wage, regions 13 work stoppages 12 earnings & wages, industries 11 Total 609 Table 2: Contingecy Table for Three Document Representations Representation Right Wrong Accuracy Full-text 392 217 0.64 Title 441 168 0.72 Keyword 601 8 0.98 there were 19 such subject headings, which altogether covered 609 (54%) of the documents with subjects assigned.",
                "These document-subject pairings formed the basis of our analysis.",
                "Limiting analysis to subjects with N > 10 kept the resultant χ2 tests suitably robust.",
                "The clustering derived by each document representation was tested by its ability to collocate documents with the same subjects.",
                "Thus for each of the 19 subject headings in Table 1, Si, we calculated the proportion of documents assigned to Si that each clustering co-classified.",
                "Further, we assumed that whichever cluster captured the majority of documents for a given class constituted the right answer for that class.",
                "For instance, There were 92 documents whose subject heading was prices.",
                "Taking the BLS editors classifications as ground truth, all 92 of these documents should have ended up in the same cluster.",
                "Under the full-text representation 52 of these documents were clustered into category 5, while 35 were in category 3, and 5 documents were in category 6.",
                "Taking the majority cluster as the putative right home for these documents, we consider the accuracy of this clustering on this subject to be 52/92 = 0.56.",
                "Repeating this process for each topic across all three representations led to the contingency table shown in Table 2.",
                "The obvious superiority of the keyword-based clustering evidenced by Table 2 was borne out by a χ2 test on the accuracy proportions.",
                "Comparing the proportion right and Table 3: Keyword-Based Clusters benefits costs international jobs plans compensation import employment benefits costs prices jobs employees benefits petroleum youth occupations prices productivity safety workers prices productivity safety earnings index output health operators inflation nonfarm occupational spending unemployment expenditures unemployment consumer mass spending jobless wrong achieved by keyword and title-based clustering led to p 0.001.",
                "Due to this result, in the remainder of this paper, we focus our attention on the clusters derived by analysis of the Editors Desk keywords.",
                "The ten keyword-based clusters are shown in Table 3, represented by the three terms most highly associated with each cluster, in terms of the log-odds ratio.",
                "Additionally, each cluster has been given a label by the researchers.",
                "Evaluating the results of clustering is notoriously difficult.",
                "In order to lend our analysis suitable rigor and utility, we made several simplifying assumptions.",
                "Most problematic is the fact that we have assumed that each document belongs in only a single category.",
                "This assumption is certainly false.",
                "However, by taking an extremely rigid view of what constitutes a subject-that is, by taking a fully qualified and often multipart subject heading as our unit of analysis-we mitigate this problem.",
                "Analogically, this is akin to considering the location of books on a library shelf.",
                "Although a given book may cover many subjects, a classification system should be able to collocate books that are extremely similar, say books about occupational safety and health.",
                "The most serious liability with this evaluation, then, is the fact that we have compressed multiple subject headings, say prices : international into single subjects.",
                "This flattening obscures the multivalence of documents.",
                "We turn to a more realistic assessment of document-class relations in Section 6.2. 6.2 Accuracy of the Document Classifiers Although the keyword-based clusters appear to classify the Editors Desk documents very well, their discovery only solved half of the problem required for the successful implementation of a dynamic user interface such as the relation browser.",
                "The matter of roughly fourteen thousand unclassified documents remained to be addressed.",
                "To solve this problem, we trained the statistical classifiers described above in Section 5.",
                "For each document in the collection di, these classifiers give pi, a k-vector of probabilities or distances (depending on the classification method used), where pik quantifies the strength of association between the ith document and the kth class.",
                "All classifiers were trained on the full text of each document, regardless of the representation used to discover the initial clusters.",
                "The different training sets were thus constructed simply by changing the 156 Table 4: Cross Validation Results for 3 Classifiers Method Av.",
                "Percent Accuracy SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 class variable for each instance (document) to reflect its assigned cluster under a given model.",
                "To test the ability of each classifier to locate documents correctly, we first performed a 10-fold cross validation on the Editors Desk documents.",
                "During cross-validation the data are split randomly into n subsets (in this case n = 10).",
                "The process proceeds by iteratively holding out each of the n subsets as a test collection for a model trained on the remaining n − 1 subsets.",
                "Cross validation is described in [15].",
                "Using this methodology, we compared the performance of the three classification models described above.",
                "Table 4 gives the results from cross validation.",
                "Although naive Bayes is not significantly more accurate for these data than the SVM classifier, we limit the remainder of our attention to analysis of its performance.",
                "Our selection of naive Bayes is due to the fact that it appears to work comparably to the SVM approach for these data, while being much simpler, both in theory and implementation.",
                "Because we have only 1279 documents and 10 classes, the number of training documents per class is relatively small.",
                "In addition to models fitted to the Editors Desk data, then, we constructed a fourth model, supplementing the training sets of each class by querying the Google search engine7 and applying naive Bayes to the augmented test set.",
                "For each class, we created a query by submitting the three terms with the highest log-odds ratio with that class.",
                "Further, each query was limited to the domain www.bls.gov.",
                "For each class we retrieved up to 400 documents from Google (the actual number varied depending on the size of the result set returned by Google).",
                "This led to a training set of 4113 documents in the augmented model, as we call it below8 .",
                "Cross validation suggested that the augmented model decreased classification accuracy (accuracy= 58.16%, with standard error= 0.32).",
                "As we discuss below, however, augmenting the training set appeared to help generalization during our second experiment.",
                "The results of our cross validation experiment are encouraging.",
                "However, the success of our classifiers on the Editors Desk documents that informed the cross validation study may not be good predictors of the models performance on the remainder to the BLS website.",
                "To test the generality of the naive Bayes classifier, we solicited input from 11 human judges who were familiar with the BLS website.",
                "The sample was chosen by convenience, and consisted of faculty and graduate students who work on the GovStat project.",
                "However, none of the reviewers had prior knowledge of the outcome of the classification before their participation.",
                "For the experiment, a random sample of 100 documents was drawn from the entire BLS collection.",
                "On average each re7 http://www.google.com 8 A more formal treatment of the combination of labeled and unlabeled data is available in [4].",
                "Table 5: Human-Model Agreement on 100 Sample Docs.",
                "Human Judge 1st Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 24 N. Bayes 24 1 Human Judge 2nd Choice Model Model 1st Choice Model 2nd Choice N. Bayes (aug.) 14 21 N. Bayes 21 4 viewer classified 83 documents, placing each document into as many of the categories shown in Table 3 as he or she saw fit.",
                "Results from this experiment suggest that room for improvement remains with respect to generalizing to the whole collection from the class models fitted to the Editors Desk documents.",
                "In Table 5, we see, for each classifier, the number of documents for which its first or second most probable class was voted best or second best by the 11 human judges.",
                "In the context of this experiment, we consider a first- or second-place classification by the machine to be accurate because the relation browser interface operates on a multiway classification, where each document is classified into multiple categories.",
                "Thus a document with the correct class as its second choice would still be easily available to a user.",
                "Likewise, a correct classification on either the most popular or second most popular category among the human judges is considered correct in cases where a given document was classified into multiple classes.",
                "There were 72 multiclass documents in our sample, as seen in Figure 4.",
                "The remaining 28 documents were assigned to 1 or 0 classes.",
                "Under this rationale, The augmented naive Bayes classifier correctly grouped 73 documents, while the smaller model (not augmented by a Google search) correctly classified 50.",
                "The resultant χ2 test gave p = 0.001, suggesting that increasing the training set improved the ability of the naive Bayes model to generalize from the Editors Desk documents to the collection as a whole.",
                "However, the improvement afforded by the augmented model comes at some cost.",
                "In particular, the augmented model is significantly inferior to the model trained solely on Editors Desk documents if we concern ourselves only with documents selected by the majority of human reviewers-i.e. only first-choice classes.",
                "Limiting the right answers to the left column of Table 5 gives p = 0.02 in favor of the non-augmented model.",
                "For the purposes of applying the relation browser to complex digital library content (where documents will be classified along multiple categories), the augmented model is preferable.",
                "But this is not necessarily the case in general.",
                "It must also be said that 73% accuracy under a fairly liberal test condition leaves room for improvement in our assignment of topics to categories.",
                "We may begin to understand the shortcomings of the described techniques by consulting Figure 5, which shows the distribution of categories across documents given by humans and by the augmented naive Bayes model.",
                "The majority of reviewers put 157 Number of Human-Assigned ClassesMNumber of Human-Assigned ClassesM Number of Human-Assigned Classes FrequencyMFrequencyM Frequency m00M0M 0 11M1M 1 22M2M 2 33M3M 3 44M4M 4 55M5M 5 66M6M 6 77M7M 7 m00M0M 055M5M 51010M10M 101515M15M 152020M20M 202525M25M 253030M30M 303535M35M 35 Figure 4: Number of Classes Assigned to Documents by Judges documents into only three categories, jobs, benefits, and occupations.",
                "On the other hand, the naive Bayes classifier distributed classes more evenly across the topics.",
                "This behavior suggests areas for future improvement.",
                "Most importantly, we observed a strong correlation among the three most frequent classes among the human judges (for instance, there was 68% correlation between benefits and occupations).",
                "This suggests that improving the clustering to produce topics that were more nearly orthogonal might improve performance. 7.",
                "CONCLUSIONS AND FUTURE WORK Many developers and maintainers of digital libraries share the basic problem pursued here.",
                "Given increasingly large, complex bodies of data, how may we improve access to collections without incurring extraordinary cost, and while also keeping systems receptive to changes in content over time?",
                "Data mining and machine learning methods hold a great deal of promise with respect to this problem.",
                "Empirical methods of knowledge discovery can aid in the organization and retrieval of information.",
                "As we have argued in this paper, these methods may also be brought to bear on the design and implementation of advanced user interfaces.",
                "This study explored a hybrid technique for aiding information architects as they implement dynamic interfaces such as the relation browser.",
                "Our approach combines unsupervised learning techniques, applied to a focused subset of the BLS website.",
                "The goal of this initial stage is to discover the most basic and far-reaching topics in the collection.",
                "Based mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityHuman ClassificationsMHuman ClassificationsM Human Classifications m0.000.00M0.00M 0.00 0.050.100.150.15M0.15M 0.15 0.200.25mjobsjobsMjobsM jobs benefitsunemploymentpricespricesMpricesM prices safetyinternationalspendingspendingMspendingM spending occupationscostscostsMcostsM costs productivityMachine ClassificationsMMachine ClassificationsM Machine Classifications m0.000.00M0.00M 0.00 0.050.100.10M0.10M 0.10 0.15 Figure 5: Distribution of Classes Across Documents on a statistical model of these topics, the second phase of our approach uses supervised learning (in particular, a naive Bayes classifier, trained on individual words), to assign topical relations to the remaining documents in the collection.",
                "In the study reported here, this approach has demonstrated promise.",
                "In its favor, our approach is highly scalable.",
                "It also appears to give fairly good results.",
                "Comparing three modes of document representation-full-text, title only, and keyword-we found 98% accuracy as measured by collocation of documents with identical subject headings.",
                "While it is not surprising that editor-generated keywords should give strong evidence for such learning, their superiority over fulltext and titles was dramatic, suggesting that even a small amount of metadata can be very useful for data mining.",
                "However, we also found evidence that learning topics from a subset of the collection may lead to overfitted models.",
                "After clustering 1279 Editors Desk documents into 10 categories, we fitted a 10-way naive Bayes classifier to categorize the remaining 14,000 documents in the collection.",
                "While we saw fairly good results (classification accuracy of 75% with respect to a small sample of human judges), this experiment forced us to reconsider the quality of the topics learned by clustering.",
                "The high correlation among human judgments in our sample suggests that the topics discovered by analysis of the Editors Desk were not independent.",
                "While we do not desire mutually exclusive categories in our setting, we do desire independence among the topics we model.",
                "Overall, then, the techniques described here provide an encouraging start to our work on acquiring subject metadata for dynamic interfaces automatically.",
                "It also suggests that a more sophisticated modeling approach might yield 158 better results in the future.",
                "In upcoming work we will experiment with streamlining the two-phase technique described here.",
                "Instead of clustering documents to find topics and then fitting a model to the learned clusters, our goal is to expand the unsupervised portion of our analysis beyond a narrow subset of the collection, such as The Editors Desk.",
                "In current work we have defined algorithms to identify documents likely to help the topic discovery task.",
                "Supplied with a more comprehensive training set, we hope to experiment with model-based clustering, which combines the clustering and classification processes into a single modeling procedure.",
                "Topic discovery and document classification have long been recognized as fundamental problems in information retrieval and other forms of text mining.",
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and <br>interface design</br>.",
                "Finally, then, in future work we will build on the user studies undertaken by Marchionini and Brunk in efforts to evaluate the utility of automatically populated dynamic interfaces for the users of digital libraries. 8.",
                "REFERENCES [1] A. Agresti.",
                "An Introduction to Categorical Data Analysis.",
                "Wiley, New York, 1996. [2] C. Ahlberg, C. Williamson, and B. Shneiderman.",
                "Dynamic queries for information exploration: an implementation and evaluation.",
                "In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 619-626, 1992. [3] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press, 1999. [4] A. Blum and T. Mitchell.",
                "Combining labeled and unlabeled data with co-training.",
                "In Proceedings of the eleventh annual conference on Computational learning theory, pages 92-100.",
                "ACM Press, 1998. [5] H. Chen and S. Dumais.",
                "Hierarchical classification of web content.",
                "In Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval, pages 256-263, 2000. [6] M. Efron, G. Marchionini, and J. Zhang.",
                "Implications of the recursive representation problem for automatic concept identification in on-line governmental information.",
                "In Proceedings of the ASIST Special Interest Group on Classification Research (ASIST SIG-CR), 2003. [7] C. Fraley and A. E. Raftery.",
                "How many clusters? which clustering method? answers via model-based cluster analysis.",
                "The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, and P. J. Flynn.",
                "Data clustering: a review.",
                "ACM Computing Surveys, 31(3):264-323, September 1999. [9] T. Joachims.",
                "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.",
                "In D. H. Fisher, editor, Proceedings of ICML-97, 14th International Conference on Machine Learning, pages 143-151, Nashville, US, 1997.",
                "Morgan Kaufmann Publishers, San Francisco, US. [10] T. Joachims.",
                "Text categorization with support vector machines: learning with many relevant features.",
                "In C. N´edellec and C. Rouveirol, editors, Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137-142, Chemnitz, DE, 1998.",
                "Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe.",
                "Principal Component Analysis.",
                "Springer, 2nd edition, 2002. [12] L. Kaufman and P. J. Rosseeuw.",
                "Finding Groups in Data: an Introduction to Cluster Analysis.",
                "Wiley, 1990. [13] G. Marchionini and B. Brunk.",
                "Toward a general relation browser: a GUI for information architects.",
                "Journal of Digital Information, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum.",
                "Bow: A toolkit for statistical language modeling, text retrieval, classification and clustering. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell.",
                "Machine Learning.",
                "McGraw Hill, 1997. [16] E. Rasmussen.",
                "Clustering algorithms.",
                "In W. B. Frakes and R. Baeza-Yates, editors, Information Retrieval: Data Structures and Algorithms, pages 419-442.",
                "Prentice Hall, 1992. [17] R. Tibshirani, G. Walther, and T. Hastie.",
                "Estimating the number of clusters in a dataset via the gap statistic, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik.",
                "The Nature of Statistical Learning Theory.",
                "Springer, 2000. 159"
            ],
            "original_annotated_samples": [
                "What is increasingly clear, however, as digital libraries grow in scope and complexity, is the applicability of these techniques to problems at the front-end of systems such as information architecture and <br>interface design</br>."
            ],
            "translated_annotated_samples": [
                "Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el <br>diseño de interfaces</br>."
            ],
            "translated_text": "Aprendizaje automático para la arquitectura de la información en un sitio web gubernamental grande ∗ Miles Efron Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 efrom@ils.unc.edu Jonathan Elsas Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 jelsas@email.unc.edu Gary Marchionini Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 march@ils.unc.edu Junliang Zhang Escuela de Información y Biblioteconomía CB#3360, 100 Manning Hall Universidad de Carolina del Norte en Chapel Hill, NC 27599-3360 junliang@email.unc.edu RESUMEN Este artículo describe una investigación en curso sobre la aplicación de técnicas de aprendizaje automático para mejorar el acceso a la información gubernamental en bibliotecas digitales complejas. Bajo los auspicios del Proyecto GovStat, nuestro objetivo es identificar un pequeño número de conceptos semánticamente válidos que abarquen adecuadamente el dominio intelectual de una colección. El objetivo de este descubrimiento es doble. Primero deseamos una ayuda práctica para arquitectos de la información. Segundo, las relaciones de conceptos de documentos derivadas automáticamente son un requisito necesario para la implementación en el mundo real de muchas interfaces dinámicas. El estudio actual compara estrategias de aprendizaje de conceptos basadas en tres representaciones de documentos: palabras clave, títulos y texto completo. En estudios estadísticos y basados en usuarios, las palabras clave creadas por humanos proporcionan mejoras significativas en el aprendizaje de conceptos tanto en comparación con representaciones solo de títulos como de texto completo. Categorías y Descriptores de Asignaturas H.3.7 [Almacenamiento y Recuperación de Información]: Bibliotecas Digitales - Problemas de Sistemas, Problemas de Usuarios; H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda de Información y Recuperación - Agrupamiento Términos Generales Diseño, Experimentación 1. INTRODUCCIÓN El Proyecto GovStat es un esfuerzo conjunto del Laboratorio de Diseño de Interacción de la Universidad de Carolina del Norte y el Laboratorio de Interacción Humano-Computadora de la Universidad de Maryland. Citando la dificultad de los usuarios finales para encontrar información gubernamental (especialmente datos estadísticos) en línea, el proyecto busca crear un modelo integrado de acceso de usuarios a información estadística del gobierno de EE. UU. que esté basado en modelos de datos realistas e interfaces de usuario innovadoras. Para habilitar tales modelos e interfaces, proponemos un enfoque basado en datos, utilizando técnicas de minería de datos y aprendizaje automático. En particular, nuestro trabajo analiza una biblioteca digital en particular: el sitio web de la Oficina de Estadísticas Laborales (BLS), en un esfuerzo por descubrir un pequeño número de conceptos lingüísticamente significativos, o contenedores, que resuman colectivamente el dominio semántico del sitio. El objetivo del proyecto es clasificar el contenido de los sitios web de acuerdo con estos conceptos inferidos como un paso inicial hacia el filtrado de datos a través de interfaces de usuario activas (cf. [13]). Muchas bibliotecas digitales ya hacen uso de la clasificación de contenido, tanto de forma explícita como implícita; dividen sus recursos manualmente por relación temática; organizan el contenido en sistemas de archivos orientados jerárquicamente. El objetivo de la presente investigación es desarrollar otro medio para explorar el contenido de estas colecciones. Al analizar la distribución de términos en los documentos, nuestro objetivo es complementar las estructuras de información preexistentes de la agencia. Las tecnologías de aprendizaje estadístico son atractivas en este contexto en la medida en que tienen el potencial de definir una estructura de navegación basada en datos en lugar de en la agencia. Nuestro enfoque combina técnicas de aprendizaje supervisado y no supervisado. Un enfoque de agrupamiento de documentos puro [12] para una colección tan grande y diversa como BLS dio como resultado pobres resultados en pruebas iniciales [6]. Pero las técnicas estrictamente supervisadas [5] también son inapropiadas. Aunque los diseñadores de BLS han definido encabezados de alto nivel para sus colecciones, como discutimos en la Sección 2, este esquema es menos que óptimo. Así esperamos aprender un conjunto adicional de conceptos dejando que los datos hablen por sí mismos. El resto de este documento describe los detalles de nuestros esfuerzos de descubrimiento de conceptos y la evaluación posterior. En la Sección 2 describimos la estructura conceptual previamente existente, creada por humanos, del sitio web de BLS. Esta sección también describe evidencia de que esta estructura deja espacio para mejoras. A continuación (Secciones 3-5), pasamos a una descripción de los conceptos derivados a través de la agrupación de contenido bajo tres representaciones de documentos: palabras clave, solo título y texto completo. La sección 6 describe una evaluación de dos partes de las estructuras conceptuales derivadas. Finalmente, concluimos en la Sección 7 delineando el trabajo próximo en el proyecto. 2. ESTRUCTURANDO EL ACCESO AL SITIO WEB DE LA BLS La Oficina de Estadísticas Laborales es una agencia del gobierno federal encargada de recopilar y publicar estadísticas relacionadas con el trabajo y la producción en los Estados Unidos y en el extranjero. Dado este amplio mandato, la BLS publica una amplia gama de información, destinada a audiencias diversas. El sitio web de la agencia actúa como un centro de intercambio para este proceso. Con más de 15,000 documentos de texto/HTML (y muchos más documentos si se incluyen hojas de cálculo e informes compuestos), proporcionar acceso a la colección representa un desafío considerable para los arquitectos de la información. 2.1 El Navegador de Relaciones El punto de partida de este trabajo es la idea de que el acceso a la información en el sitio web de BLS podría mejorarse mediante la adición de una interfaz dinámica como el navegador de relaciones descrito por Marchionini y Brunk [13]. El navegador de relaciones permite a los usuarios recorrer conjuntos de datos complejos al dividir iterativamente los datos a lo largo de varios temas. En la Figura 1 vemos una instancia prototipo del navegador de relaciones, aplicado al sitio web FedStats. El navegador de relaciones apoya la búsqueda de información al permitir a los usuarios formular consultas de manera gradual, dividiendo y volviendo a dividir los datos según lo dicten sus intereses. Su motivación está en línea con la sugerencia de Shneiderman de que las consultas y sus resultados deben estar estrechamente vinculados [2]. Por lo tanto, en la Figura 3 http://www.fedstats.gov Figura 1: Prototipo de Navegador de Relaciones, los usuarios podrían limitar su conjunto de búsqueda a aquellos documentos sobre energía. Dentro de este subconjunto de la colección, podrían eliminar además los documentos publicados hace más de un año. Finalmente, podrían solicitar ver solo documentos publicados en formato PDF. Como discuten Marchionini y Brunk, capturar la fecha de publicación y el formato de los documentos es trivial. Pero las implementaciones exitosas del navegador de relaciones también dependen de la clasificación temática. Esto presenta dos obstáculos para los diseñadores de sistemas: • Los arquitectos de la información deben definir el conjunto adecuado de temas para su colección • Los encargados del mantenimiento del sitio deben clasificar cada documento en sus categorías apropiadas. Estas tareas son similares a problemas comunes en la comunidad de metadatos: definir elementos apropiados y marcar documentos para respaldar el acceso a la información consciente de los metadatos. Dada una colección de más de 15,000 documentos, estos obstáculos son especialmente desafiantes, y los métodos automáticos para abordarlos son altamente deseables. 2.2 Una Estructura Preexistente Antes de nuestra participación en el proyecto, los diseñadores de BLS crearon una estructura clasificatoria superficial para los documentos más importantes en su sitio web. Como se ve en la Figura 2, la página de inicio de la BLS organiza 65 documentos de nivel superior en 15 categorías. Estos incluyen temas como Empleo y Desempleo, Productividad e Inflación y Gasto. Esperábamos inicialmente que estas categorías predefinidas pudieran ser utilizadas para entrenar un clasificador de documentos de 15 vías, automatizando así el proceso de completar por completo el navegador de relaciones. Sin embargo, este enfoque resultó insatisfactorio. En reuniones personales, los funcionarios de BLS expresaron su insatisfacción con los temas existentes. Se argumentaba que su forma se debía tanto a la estructura institucional de BLS como a la topología inherente del espacio de información de los sitios web. En otras palabras, los temas reflejaban divisiones oficiales en lugar de agrupaciones semánticas. Los agentes de la BLS sugirieron que sería deseable rediseñar esta estructura de clasificación. Las dudas de los agentes se confirmaron en el análisis posterior. Los temas de la BLS comprenden una estructura clasificatoria superficial; cada una de las 15 categorías de nivel superior está vinculada a un pequeño número de páginas relacionadas. Por lo tanto, hay 7 páginas asociadas con la Inflación. En total, la estructura de enlaces de este sistema clasificatorio contiene 65 documentos; es decir, excluyendo los enlaces de navegación, hay 65 documentos enlazados desde la página de inicio de BLS, donde cada hipervínculo conecta un documento con un tema (las páginas pueden estar enlazadas a múltiples temas). Basándonos en esta estructura de hipervínculos, definimos M, una matriz simétrica de 65×65, donde mij cuenta el número de temas en los que los documentos i y j están clasificados en la página de inicio de BLS. Para analizar la redundancia inherente en la estructura preexistente, derivamos los componentes principales de M (cf. [11]). La Figura 3 muestra el gráfico de escombros resultante. Dado que los 65 documentos pertenecen al menos a un tema de BLS, un gráfico de pantalla A muestra la magnitud del k-ésimo valor propio versus su rango. Durante el análisis de componentes principales, los gráficos de scree visualizan la cantidad de varianza capturada por cada componente. El rango de M está garantizado de ser menor o igual a 15 (por lo tanto, los valores propios 16...65 = 0). Lo sorprendente de la Figura 3, sin embargo, es la abrupta disminución en magnitud entre los primeros cuatro autovalores. Los cuatro valores propios más grandes representan el 62.2% de la varianza total en los datos. Este hecho sugiere un alto grado de redundancia entre los temas. La redundancia temática no es problemática en sí misma. Sin embargo, los documentos en esta estructura clasificatoria muy superficial son casi todos pasarelas a información más específica. Por lo tanto, la clasificación del Índice de Precios al Productor en tres categorías podría resultar confusa para los usuarios del sitio. A la luz de esta posible confusión y la solicitud de rediseño de la agencia, asumimos la tarea de descubrimiento de temas descrita en las siguientes secciones. 3. Un enfoque híbrido para el descubrimiento de temas Para ayudar en el descubrimiento de un nuevo conjunto de temas de alto nivel para el sitio web de BLS, recurrimos a métodos de aprendizaje automático no supervisado. En un esfuerzo por permitir que los datos hablen por sí mismos, deseábamos un medio de descubrimiento de conceptos que se basara no en la estructura de la agencia, sino en el contenido del material. Para comenzar este proceso, rastreamos el sitio web de la BLS, descargando todos los documentos de tipo MIME text/html. Esto dio lugar a un corpus de 15,165 documentos. Basándonos en este corpus, esperábamos derivar aproximadamente k ≈ 10 categorías temáticas, de modo que cada documento di se asignara a una o más clases. El agrupamiento de documentos (cf. [16]) proporcionó una solución obvia, pero solo parcial, al problema de automatizar este tipo de descubrimiento de arquitectura de información de alto nivel. Los problemas con el agrupamiento estándar son triples. 1. Los grupos mutuamente excluyentes no son apropiados para identificar el contenido temático de los documentos, ya que los documentos pueden tratar sobre muchos temas. Debido a la heterogeneidad de los datos alojados en la colección de la BLS (tablas, listas, encuestas, etc.), muchos términos de documentos proporcionan información temática ruidosa. 3. Para la aplicación en el navegador de relaciones, requerimos un pequeño número (k ≈ 10) de temas. Sin una reducción significativa de datos, el agrupamiento basado en términos tiende a generar agrupaciones a un nivel de granularidad demasiado fino. A la luz de estos problemas, adoptamos un enfoque híbrido para descubrir temas. Primero, limitamos el proceso de agrupamiento a una muestra de toda la colección, descrita en la Sección 4. Trabajar en un subconjunto enfocado de los datos ayuda a superar los problemas dos y tres, mencionados anteriormente. Para abordar el problema de la exclusividad mutua, combinamos métodos de aprendizaje no supervisado con supervisado, como se describe en la Sección 5.4. CENTRÁNDOSE EN DOCUMENTOS RICOS EN CONTENIDO Para derivar temas respaldados empíricamente, inicialmente recurrimos al análisis de conglomerados. Sea A la matriz de datos n×p con n observaciones en p variables. Así, aij muestra la medición para la i-ésima observación en la variable j-ésima. Como se describe en [12], el objetivo del análisis de conglomerados es asignar cada una de las n observaciones a uno de un pequeño número k de grupos, cada uno de los cuales se caracteriza por una alta correlación intra-cluster y una baja correlación inter-cluster. Aunque los algoritmos para lograr tal disposición son numerosos, nuestro análisis se centra en el agrupamiento k-means, durante el cual, cada observación oi se asigna al clúster Ck cuyo centroide está más cercano a ella en términos de distancia euclidiana. Los lectores interesados en los detalles del algoritmo pueden consultar [12] para un tratamiento exhaustivo del tema. El agrupamiento por k-medias está bien estudiado en la literatura estadística y ha mostrado buenos resultados para el análisis de texto (cf. [8, 16]). Sin embargo, el agrupamiento k-means requiere que el investigador especifique k, el número de clústeres a definir. Al aplicar k-means a nuestra colección de 15,000 documentos, indicadores como la estadística de brecha [17] y un análisis de la distancia cuadrada media a través de los valores de k sugirieron que k ≈ 80 era óptimo. Esta parametrización condujo a agrupaciones semánticamente inteligibles. Sin embargo, 80 grupos son demasiados para aplicar a una interfaz como la relación 5. Nos hemos centrado en k-means en lugar de otros algoritmos de agrupamiento por varias razones. Uno de los principales beneficios es la eficiencia computacional que ofrece el enfoque de k-medias. Dado que solo necesitamos un agrupamiento plano, hay poco que ganar con los algoritmos jerárquicos más costosos. En trabajos futuros recurriremos al agrupamiento basado en modelos [7] como un método más fundamentado para seleccionar el número de grupos y representar los grupos. Además, la granularidad de estos grupos era inadecuadamente fina. Por ejemplo, la solución de 80 clústeres derivó un clúster cuyas palabras más asociadas (en términos de razón de logaritmo de probabilidades [1]) fueron droga, farmacia y químico. Estas palabras están ciertamente relacionadas, pero lo están a un nivel de especificidad mucho menor del que buscábamos. Para remediar la alta dimensionalidad de los datos, decidimos limitar el algoritmo a un subconjunto de la colección. En consulta con empleados de la BLS, continuamos nuestro análisis sobre documentos que forman una serie titulada Desde el Escritorio de los Editores. Estos son artículos breves, escritos por empleados de la BLS. Los agentes de BLS sugirieron que nos enfoquemos en el Escritorio de Editores porque está destinado a abarcar el ámbito intelectual de la agencia. La columna se publica diariamente, y cada entrada describe un tema actual importante en el dominio de la BLS. La columna de la Mesa de Editores ha sido escrita diariamente (cinco veces por semana) desde 1998. Por lo tanto, trabajamos con un conjunto de N = 1279 documentos. Limitar la atención a estos 1279 documentos no solo redujo la dimensionalidad del problema. También permitió que el proceso de agrupamiento aprendiera en un conjunto de datos relativamente limpio. Si bien toda la colección de BLS contiene una gran cantidad de texto no literario (es decir, tablas, listas, etc.), los documentos de la mesa de redacción están escritos en un claro y periodístico estilo literario. Cada documento es altamente relevante, lo que ayuda aún más en el descubrimiento de relaciones entre términos. Finalmente, la columna de la Mesa de Editores proporcionó un entorno de aprendizaje ideal porque está bien abastecida con metadatos relevantes. Cada uno de los 1279 documentos contiene una lista de una o más palabras clave. Además, un subconjunto de los documentos (1112) contenía un encabezado de tema. Estos metadatos informaron nuestro aprendizaje y evaluación, como se describe en la Sección 6.1. 5. COMBINANDO APRENDIZAJE SUPERVISADO Y NO SUPERVISADO PARA DESCUBRIMIENTO DE TEMAS Para derivar temas adecuadamente generales para la aplicación de una interfaz dinámica a la colección de BLS, combinamos técnicas de agrupamiento de documentos con clasificación de texto. Específicamente, utilizando k-means, agrupamos cada uno de los 1279 documentos en uno de los k grupos, con el número de grupos elegido mediante el análisis de la distancia cuadrada media dentro del grupo en diferentes valores de k (ver Sección 6.1). La construcción de grupos mutuamente excluyentes viola nuestra suposición de que los documentos pueden pertenecer a múltiples clases. Sin embargo, estos grupos marcan solo el primer paso en un proceso de identificación de temas de dos fases. Al final del proceso, la afinidad del grupo de documentos se mide mediante un número de valor real. Una vez que los documentos de la mesa de editores fueron asignados a grupos, construimos un clasificador de k-vías que estima la fuerza de la evidencia de que un nuevo documento di es miembro de la clase Ck. Probamos tres técnicas de clasificación estadística: Rocchio probabilístico (prind), Bayes ingenuo y máquinas de vectores de soporte (SVMs). Todos fueron implementados utilizando la biblioteca de clasificación de texto BOW de McCallums [14]. Prind es una versión probabilística del algoritmo de clasificación Rocchio [9]. Se recomienda a los lectores interesados consultar el artículo de Joachims para obtener más detalles sobre el método de clasificación. Al igual que prind, el algoritmo de Naive Bayes intenta clasificar documentos en la clase más probable. Se describe detalladamente en [15]. Finalmente, las máquinas de vectores de soporte fueron explicadas detalladamente por Vapnik [18], y aplicadas específicamente al texto en [10]. Definen un límite de decisión al encontrar el hiperplano de separación máxima en un espacio vectorial de alta dimensión en el que las clases de documentos se vuelven linealmente separables. Habiendo agrupado los documentos y entrenado un clasificador adecuado, los 14,000 documentos restantes en la colección son etiquetados mediante clasificación automática. Es decir, para cada documento di derivamos un vector de k dimensiones, cuantificando la asociación entre di y cada clase C1 . . . I'm sorry, but \"Ck\" is not a complete sentence in English. Could you please provide more context or a complete sentence for me to translate into Spanish? La obtención de puntajes de temas a través de Naive Bayes para toda la colección de 15,000 documentos requirió menos de dos horas de tiempo de CPU. La salida de este proceso es una puntuación para cada documento en la colección en cada uno de los temas descubiertos automáticamente. Estas puntuaciones pueden ser utilizadas para poblar una interfaz de navegador de relaciones, o pueden ser añadidas a un sistema tradicional de recuperación de información. Para utilizar estos pesos en el navegador de relaciones, actualmente asignamos a cada documento los dos temas en los que obtuvo la puntuación más alta. En trabajos futuros adoptaremos un método más riguroso para derivar los umbrales de peso de los temas de los documentos. Además, se llevará a cabo la evaluación de la utilidad de los temas aprendidos para los usuarios. 6. EVALUACIÓN DEL DESCUBRIMIENTO DE CONCEPTOS Antes de implementar una interfaz de navegador de relaciones y llevar a cabo los estudios de usuario correspondientes, es importante evaluar la calidad de los conceptos inferidos y la capacidad del clasificador automático para asignar documentos a los temas apropiados. Para evaluar el éxito del enfoque de dos etapas descrito en la Sección 5, llevamos a cabo dos experimentos. Durante el primer experimento comparamos tres métodos de representación de documentos para la tarea de agrupamiento. El objetivo aquí era comparar la calidad de los grupos de documentos derivados del análisis de documentos de texto completo, documentos representados solo por sus títulos y documentos representados por metadatos de palabras clave creados por humanos. Durante el segundo experimento, analizamos la capacidad de los clasificadores estadísticos para discernir el tema de los documentos de partes de la base de datos además de la sección de la Mesa del Editor. 6.1 Comparación de Representaciones de Documentos Los documentos de la columna de la Mesa del Editor venían con metadatos de palabras clave generados por humanos. Además, los títulos de los documentos de la mesa del editor tienden a ser pertinentes al tema de sus respectivos artículos. Con una amplia gama de evidencia destilada sobre el tema de cada documento, llevamos a cabo una comparación de las representaciones de los documentos para descubrir temas mediante agrupamiento. Hemos hipotetizado que el agrupamiento basado en palabras clave proporcionaría un modelo útil. Pero esperábamos ver si se podía lograr un rendimiento comparable con métodos que no requirieran una indexación humana extensa, como las representaciones solo de título o de texto completo. Para probar esta hipótesis, definimos tres modos de representación de documentos: texto completo, solo título y solo palabras clave, generamos tres conjuntos de temas, Tfull, Ttitle y Tkw, respectivamente. Los temas basados en documentos de texto completo fueron derivados mediante la aplicación de agrupamiento k-means a los 1279 documentos del Editor, donde cada documento fue representado por un vector dimensional de 1908. Estas dimensiones de 1908 capturaron los pesos TF.IDF [3] de cada término ti en el documento dj, para todos los términos que ocurrieron al menos tres veces en los datos. Para llegar al número apropiado de grupos para estos datos, inspeccionamos la distancia cuadrada media dentro del grupo para cada valor de k = 1 . . . 20. A medida que k se acercaba a 10, la reducción del error con la adición de más grupos disminuyó notablemente, lo que sugiere que k ≈ 10 produciría buenas divisiones. Para seleccionar un único valor entero, calculamos qué valor de k resultó en la menor variación en el tamaño del grupo. Esta métrica surgió de un deseo de suprimir el resultado común donde un gran clúster emerge del algoritmo k-means, acompañado de varios clústeres pequeños en consecuencia. Sin motivo para creer que algún tema en particular debería tener probabilidades previas dramáticamente altas de pertenencia al documento, esta heurística llevó a kfull = 10. Los grupos basados en los títulos de los documentos fueron construidos de manera similar. Sin embargo, en este caso, cada documento fue representado en el espacio vectorial abarcado por los 397 términos que ocurren al menos dos veces en los títulos de los documentos. Utilizando el mismo método de minimizar la varianza en la membresía del clúster, ktitle, el número de clústeres en la representación basada en títulos, también se estableció en 10. La dimensionalidad del agrupamiento basado en palabras clave fue muy similar a la del enfoque basado en títulos. Había 299 palabras clave en los datos, todas las cuales fueron retenidas. El número medio de palabras clave por documento fue de 7, donde una palabra clave se entiende como una sola palabra o un término compuesto como índice de precios al consumidor. Vale la pena señalar que las palabras clave no fueron extraídas de ningún vocabulario controlado; fueron asignadas a los documentos por los editores en la BLS. Usando las palabras clave, los documentos fueron agrupados en 10 clases. Para evaluar los grupos derivados por cada método de representación de documentos, utilizamos los encabezados de tema que se incluyeron en 1112 de los documentos del Editor. Cada uno de estos 1112 documentos fue asignado uno o más encabezados de materia, los cuales fueron retenidos de todas las aplicaciones de agrupamiento. Al igual que las palabras clave, los encabezados de materia fueron asignados a los documentos por los editores de BLS. A diferencia de las palabras clave, los encabezamientos de materia se extrajeron de un vocabulario controlado. Nuestro análisis comenzó con la suposición de que los documentos con los mismos encabezados de tema deberían agruparse juntos. Para facilitar este análisis, adoptamos un enfoque conservador; consideramos las clasificaciones de múltiples sujetos como únicas. Por lo tanto, si el documento di fue asignado a un solo tema, precios, mientras que el documento dj fue asignado a dos temas, comparaciones internacionales, precios, los documentos di y dj no se consideran que provienen de la misma clase. La Tabla 1 muestra todos los encabezados de tema de la Mesa de Editores que se asignaron a al menos 10 documentos. Como se señala en la tabla, hay 155 Tabla 1: Principales Encabezados de Asuntos del Escritorio de Editores Cantidad de Asuntos precios 92 desempleo 55 seguridad y salud ocupacional 53 comparaciones internacionales, precios 48 manufactura, precios 45 empleo 44 productividad 40 gastos del consumidor 36 ganancias y salarios 27 empleo y desempleo 27 costos de compensación 25 ganancias y salarios, áreas metropolitanas 18 beneficios, costos de compensación 18 ganancias y salarios, ocupaciones 17 empleo, ocupaciones 14 beneficios 14 ganancias y salarios, regiones 13 paros laborales 12 ganancias y salarios, industrias 11 Total 609 Tabla 2: Tabla de Contingencia para Tres Representaciones de Documentos Representación Correcto Incorrecto Precisión Texto completo 392 217 0.64 Título 441 168 0.72 Palabra clave 601 8 0.98 hubo 19 tales encabezados de asuntos, que en conjunto cubrieron 609 (54%) de los documentos con asignación de temas. Estas combinaciones de documentos y temas formaron la base de nuestro análisis. Limitar el análisis a sujetos con N > 10 mantuvo las pruebas de χ2 resultantes adecuadamente robustas. La agrupación derivada por cada representación de documento fue probada por su capacidad para agrupar documentos con los mismos temas. Por lo tanto, para cada uno de los 19 encabezados de tema en la Tabla 1, calculamos la proporción de documentos asignados a Si que cada agrupamiento co-clasificó. Además, asumimos que cualquier grupo que capturara la mayoría de los documentos para una clase determinada constituía la respuesta correcta para esa clase. Por ejemplo, había 92 documentos cuyo encabezado de tema era precios. Tomando las clasificaciones de los editores de BLS como verdad absoluta, los 92 documentos deberían haber terminado en el mismo grupo. Bajo la representación de texto completo, 52 de estos documentos fueron agrupados en la categoría 5, mientras que 35 estaban en la categoría 3, y 5 documentos estaban en la categoría 6. Tomando el clúster mayoritario como el hogar potencial correcto para estos documentos, consideramos que la precisión de este agrupamiento en este tema es de 52/92 = 0.56. Repetir este proceso para cada tema en las tres representaciones llevó a la tabla de contingencia mostrada en la Tabla 2. La evidente superioridad del agrupamiento basado en palabras clave, demostrada por la Tabla 2, fue confirmada por una prueba de χ2 sobre las proporciones de precisión. Comparando la proporción correcta y la Tabla 3: Los beneficios de los grupos basados en palabras clave y los costos internacionales de los trabajos de compensación de planes de importación de empleo beneficios de los costos de los precios de los trabajadores de los empleados de la juventud de los beneficios del petróleo de las ocupaciones de los precios de la productividad de la seguridad de los trabajadores de los precios de la productividad de los ingresos del índice de salud de los operadores de inflación no agrícola de los gastos ocupacionales de desempleo de los gastos de desempleo de los consumidores de los gastos masivos de desempleo logrados por la agrupación basada en palabras clave y título llevó a p 0.001. Debido a este resultado, en el resto de este documento, centramos nuestra atención en los grupos derivados del análisis de las palabras clave del escritorio de los editores. Los diez grupos basados en palabras clave se muestran en la Tabla 3, representados por los tres términos más asociados con cada grupo, en términos de la razón de logaritmo de probabilidades. Además, a cada grupo se le ha asignado una etiqueta por parte de los investigadores. Evaluar los resultados de la agrupación es notoriamente difícil. Para dotar a nuestro análisis de un rigor y utilidad adecuados, hicimos varias suposiciones simplificadoras. Lo más problemático es el hecho de que hemos asumido que cada documento pertenece a una sola categoría. Esta suposición es ciertamente falsa. Sin embargo, al adoptar una visión extremadamente rígida de lo que constituye un sujeto, es decir, al tomar un encabezado de sujeto completamente calificado y a menudo compuesto como nuestra unidad de análisis, mitigamos este problema. Análogamente, esto es similar a considerar la ubicación de los libros en un estante de biblioteca. Aunque un libro dado pueda abarcar muchos temas, un sistema de clasificación debería ser capaz de agrupar libros que sean extremadamente similares, como por ejemplo libros sobre seguridad y salud ocupacional. La responsabilidad más grave de esta evaluación, entonces, es el hecho de que hemos comprimido múltiples encabezados de tema, digamos precios: internacionales, en un solo tema. Esta aplanamiento oculta la multivalencia de los documentos. Nos dirigimos a una evaluación más realista de las relaciones entre clases de documentos en la Sección 6.2. 6.2 Precisión de los clasificadores de documentos. Aunque los grupos basados en palabras clave parecen clasificar muy bien los documentos de la sección de la Mesa del Editor, su descubrimiento solo resolvió la mitad del problema necesario para la implementación exitosa de una interfaz de usuario dinámica como el navegador de relaciones. El asunto de aproximadamente catorce mil documentos no clasificados aún quedaba por abordar. Para resolver este problema, entrenamos los clasificadores estadísticos descritos anteriormente en la Sección 5. Para cada documento en la colección di, estos clasificadores dan pi, un vector k de probabilidades o distancias (dependiendo del método de clasificación utilizado), donde pik cuantifica la fuerza de asociación entre el documento i y la clase k. Todos los clasificadores fueron entrenados con el texto completo de cada documento, independientemente de la representación utilizada para descubrir los grupos iniciales. Los diferentes conjuntos de entrenamiento fueron construidos simplemente cambiando la Tabla 4: Resultados de Validación Cruzada para 3 Clasificadores Método Av. Porcentaje de precisión SE Prind 59.07 1.07 Naive Bayes 75.57 0.4 SVM 75.08 0.68 variable de clase para cada instancia (documento) para reflejar su clúster asignado bajo un modelo dado. Para probar la capacidad de cada clasificador para localizar documentos correctamente, primero realizamos una validación cruzada de 10 pliegues en los documentos del Escritorio de Editores. Durante la validación cruzada, los datos se dividen aleatoriamente en n subconjuntos (en este caso n = 10). El proceso avanza iterativamente dejando de lado cada uno de los n subconjuntos como una colección de prueba para un modelo entrenado en los restantes n − 1 subconjuntos. La validación cruzada se describe en [15]. Utilizando esta metodología, comparamos el rendimiento de los tres modelos de clasificación descritos anteriormente. La tabla 4 muestra los resultados de la validación cruzada. Aunque el Bayes ingenuo no es significativamente más preciso para estos datos que el clasificador SVM, limitamos el resto de nuestra atención al análisis de su rendimiento. Nuestra elección de Naive Bayes se debe al hecho de que parece funcionar de manera comparable al enfoque de SVM para estos datos, siendo mucho más simple, tanto en teoría como en implementación. Dado que solo tenemos 1279 documentos y 10 clases, el número de documentos de entrenamiento por clase es relativamente pequeño. Además de los modelos ajustados a los datos del escritorio de los editores, construimos un cuarto modelo, complementando los conjuntos de entrenamiento de cada clase mediante consultas al motor de búsqueda de Google y aplicando el método de Bayes ingenuo al conjunto de pruebas aumentado. Para cada clase, creamos una consulta al enviar los tres términos con la mayor razón de logaritmo de probabilidades con esa clase. Además, cada consulta estaba limitada al dominio www.bls.gov. Para cada clase recuperamos hasta 400 documentos de Google (el número real variaba dependiendo del tamaño del conjunto de resultados devuelto por Google). Esto resultó en un conjunto de entrenamiento de 4113 documentos en el modelo aumentado, como lo llamamos a continuación. La validación cruzada sugirió que el modelo aumentado disminuyó la precisión de clasificación (precisión= 58.16%, con error estándar= 0.32). Como discutimos a continuación, sin embargo, aumentar el conjunto de entrenamiento pareció ayudar a la generalización durante nuestro segundo experimento. Los resultados de nuestro experimento de validación cruzada son alentadores. Sin embargo, el éxito de nuestros clasificadores en los documentos de la mesa de redacción que informaron el estudio de validación cruzada puede que no sean buenos predictores del rendimiento de los modelos en el resto del sitio web de la BLS. Para probar la generalidad del clasificador de Bayes ingenuo, solicitamos la opinión de 11 jueces humanos que estaban familiarizados con el sitio web de BLS. La muestra fue seleccionada por conveniencia y consistió en profesores y estudiantes de posgrado que trabajan en el proyecto GovStat. Sin embargo, ninguno de los revisores tenía conocimiento previo del resultado de la clasificación antes de su participación. Para el experimento, se extrajo una muestra aleatoria de 100 documentos de toda la colección de BLS. En promedio, cada re7 http://www.google.com 8 Un tratamiento más formal de la combinación de datos etiquetados y no etiquetados está disponible en [4]. Tabla 5: Acuerdo entre el modelo y los humanos en 100 documentos de muestra. El espectador clasificó 83 documentos, colocando cada documento en tantas de las categorías mostradas en la Tabla 3 como consideró adecuado. Los resultados de este experimento sugieren que aún queda margen de mejora en lo que respecta a la generalización de toda la colección a partir de los modelos de clase ajustados a los documentos del escritorio de editores. En la Tabla 5, vemos, para cada clasificador, el número de documentos para los cuales su clase más probable en primer o segundo lugar fue votada como la mejor o la segunda mejor por los 11 jueces humanos. En el contexto de este experimento, consideramos que una clasificación en primer o segundo lugar por la máquina es precisa porque la interfaz del navegador de relaciones opera en una clasificación de múltiples vías, donde cada documento se clasifica en múltiples categorías. Por lo tanto, un documento con la clase correcta como segunda opción seguiría estando fácilmente disponible para un usuario. Asimismo, una clasificación correcta en la categoría más popular o la segunda más popular entre los jueces humanos se considera correcta en los casos en los que un documento dado fue clasificado en múltiples clases. Había 72 documentos multiclase en nuestra muestra, como se muestra en la Figura 4. Los 28 documentos restantes fueron asignados a 1 o 0 clases. Bajo esta premisa, el clasificador de Bayes ingenuo aumentado agrupó correctamente 73 documentos, mientras que el modelo más pequeño (no aumentado por una búsqueda en Google) clasificó correctamente 50. La prueba de χ2 resultante dio p = 0.001, lo que sugiere que aumentar el conjunto de entrenamiento mejoró la capacidad del modelo de Bayes ingenuo para generalizar desde los documentos del Editor a la colección en su totalidad. Sin embargo, la mejora proporcionada por el modelo aumentado conlleva cierto costo. En particular, el modelo aumentado es significativamente inferior al modelo entrenado únicamente con documentos de la mesa de editores si nos enfocamos solo en documentos seleccionados por la mayoría de revisores humanos, es decir, solo las clases de primera elección. Limitar las respuestas correctas a la columna izquierda de la Tabla 5 da como resultado p = 0.02 a favor del modelo no aumentado. Para los propósitos de aplicar el navegador de relaciones al contenido complejo de una biblioteca digital (donde los documentos serán clasificados en múltiples categorías), el modelo aumentado es preferible. Pero esto no es necesariamente el caso en general. También hay que decir que un 73% de precisión bajo una condición de prueba bastante liberal deja margen para mejorar en nuestra asignación de temas a categorías. Podemos comenzar a entender las deficiencias de las técnicas descritas consultando la Figura 5, que muestra la distribución de categorías en los documentos proporcionados por humanos y por el modelo de Bayes ingenuo aumentado. La mayoría de los revisores clasificaron los documentos en solo tres categorías: trabajos, beneficios y ocupaciones. Por otro lado, el clasificador de Bayes ingenuo distribuyó las clases de manera más equitativa entre los temas. Este comportamiento sugiere áreas para futuras mejoras. Lo más importante es que observamos una fuerte correlación entre las tres clases más frecuentes entre los jueces humanos (por ejemplo, hubo un 68% de correlación entre beneficios y ocupaciones). Esto sugiere que mejorar el agrupamiento para producir temas más casi ortogonales podría mejorar el rendimiento. CONCLUSIONES Y TRABAJOS FUTUROS Muchos desarrolladores y mantenedores de bibliotecas digitales comparten el problema básico perseguido aquí. Dado el creciente volumen y complejidad de los datos, ¿cómo podemos mejorar el acceso a las colecciones sin incurrir en costos extraordinarios, y al mismo tiempo mantener los sistemas receptivos a los cambios en el contenido con el tiempo? Los métodos de minería de datos y aprendizaje automático prometen mucho con respecto a este problema. Los métodos empíricos de descubrimiento del conocimiento pueden ayudar en la organización y recuperación de la información. Como hemos argumentado en este artículo, estos métodos también pueden ser aplicados en el diseño e implementación de interfaces de usuario avanzadas. Este estudio exploró una técnica híbrida para ayudar a los arquitectos de la información mientras implementan interfaces dinámicas como el navegador de relaciones. Nuestro enfoque combina técnicas de aprendizaje no supervisado, aplicadas a un subconjunto enfocado del sitio web de BLS. El objetivo de esta etapa inicial es descubrir los temas más básicos y de mayor alcance en la colección. Basado en un modelo estadístico de estos temas, la segunda fase de nuestro enfoque utiliza aprendizaje supervisado (en particular, un clasificador de Bayes ingenuo, entrenado en palabras individuales) para asignar relaciones temáticas a los documentos restantes en la colección. En el estudio reportado aquí, este enfoque ha demostrado promesa. A su favor, nuestro enfoque es altamente escalable. También parece dar resultados bastante buenos. Al comparar tres modos de representación de documentos: texto completo, solo título y palabras clave, encontramos una precisión del 98% medida por la colocación de documentos con encabezados de tema idénticos. Si bien no es sorprendente que las palabras clave generadas por el editor proporcionen pruebas sólidas para dicho aprendizaje, su superioridad sobre el texto completo y los títulos fue dramática, lo que sugiere que incluso una pequeña cantidad de metadatos puede ser muy útil para la minería de datos. Sin embargo, también encontramos evidencia de que aprender temas de un subconjunto de la colección puede llevar a modelos sobreajustados. Después de agrupar 1279 documentos del Escritorio de Editores en 10 categorías, ajustamos un clasificador de Bayes ingenuo de 10 vías para categorizar los 14,000 documentos restantes de la colección. Si bien obtuvimos resultados bastante buenos (precisión de clasificación del 75% con respecto a una pequeña muestra de jueces humanos), este experimento nos obligó a reconsiderar la calidad de los temas aprendidos mediante el agrupamiento. La alta correlación entre los juicios humanos en nuestra muestra sugiere que los temas descubiertos por el análisis del Escritorio de Editores no eran independientes. Si bien no deseamos categorías mutuamente excluyentes en nuestra configuración, sí deseamos independencia entre los temas que modelamos. En general, entonces, las técnicas descritas aquí ofrecen un comienzo alentador para nuestro trabajo de adquisición de metadatos de sujeto para interfaces dinámicas de forma automática. También sugiere que un enfoque de modelado más sofisticado podría producir mejores resultados en el futuro. En el próximo trabajo experimentaremos con la optimización de la técnica de dos fases descrita aquí. En lugar de agrupar documentos para encontrar temas y luego ajustar un modelo a los grupos aprendidos, nuestro objetivo es ampliar la parte no supervisada de nuestro análisis más allá de un subconjunto estrecho de la colección, como el escritorio de los editores. En el trabajo actual hemos definido algoritmos para identificar documentos que probablemente ayuden en la tarea de descubrimiento de temas. Suministrados con un conjunto de entrenamiento más completo, esperamos experimentar con el agrupamiento basado en modelos, que combina los procesos de agrupamiento y clasificación en un único procedimiento de modelado. El descubrimiento de temas y la clasificación de documentos han sido reconocidos durante mucho tiempo como problemas fundamentales en la recuperación de información y otras formas de minería de texto. Lo que resulta cada vez más claro, sin embargo, a medida que las bibliotecas digitales crecen en alcance y complejidad, es la aplicabilidad de estas técnicas a problemas en el frente de los sistemas, como la arquitectura de la información y el <br>diseño de interfaces</br>. Finalmente, en trabajos futuros construiremos sobre los estudios de usuario realizados por Marchionini y Brunk en un esfuerzo por evaluar la utilidad de interfaces dinámicas automáticamente pobladas para los usuarios de bibliotecas digitales. 8. REFERENCIAS [1] A. Agresti. Una introducción al análisis de datos categóricos. Wiley, Nueva York, 1996. [2] C. Ahlberg, C. Williamson y B. Shneiderman. Consultas dinámicas para la exploración de información: una implementación y evaluación. En Actas de la conferencia SIGCHI sobre Factores Humanos en Sistemas Informáticos, páginas 619-626, 1992. [3] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press, 1999. [4] A. Blum y T. Mitchell. Combinando datos etiquetados y no etiquetados con co-entrenamiento. En Actas de la undécima conferencia anual sobre teoría computacional del aprendizaje, páginas 92-100. ACM Press, 1998. [5] H. Chen y S. Dumais. Clasificación jerárquica de contenido web. En Actas de la 23ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 256-263, 2000. [6] M. Efron, G. Marchionini y J. Zhang. Implicaciones del problema de representación recursiva para la identificación automática de conceptos en la información gubernamental en línea. En Actas del Grupo de Interés Especial de ASIST sobre Investigación en Clasificación (ASIST SIG-CR), 2003. [7] C. Fraley y A. E. Raftery. ¿Cuántos grupos? ¿Qué método de agrupamiento? respuestas a través del análisis de agrupamiento basado en modelos. The Computer Journal, 41(8):578-588, 1998. [8] A. K. Jain, M. N. Murty, y P. J. Flynn. Agrupamiento de datos: una revisión. ACM Computing Surveys, 31(3):264-323, septiembre de 1999. [9] T. Joachims. Un análisis probabilístico del algoritmo de Rocchio con TFIDF para la categorización de textos. En D. H. Fisher, editor, Actas de ICML-97, 14ª Conferencia Internacional sobre Aprendizaje Automático, páginas 143-151, Nashville, EE. UU., 1997. Morgan Kaufmann Publishers, San Francisco, EE. UU. [10] T. Joachims. Categorización de texto con máquinas de vectores de soporte: aprendizaje con muchas características relevantes. En C. N´edellec y C. Rouveirol, editores, Actas de ECML-98, 10ª Conferencia Europea sobre Aprendizaje Automático, páginas 137-142, Chemnitz, DE, 1998. Springer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. \n\nSpringer Verlag, Heidelberg, DE. [11] I. T. Jolliffe. Análisis de Componentes Principales. Springer, 2da edición, 2002. [12] L. Kaufman y P. J. Rosseeuw. Encontrando grupos en los datos: una introducción al análisis de clusters. Wiley, 1990. [13] G. Marchionini y B. Brunk. Hacia un navegador de relaciones generales: una interfaz gráfica de usuario para arquitectos de la información. Revista de Información Digital, 4(1), 2003. http://jodi.ecs.soton.ac.uk/Articles/v04/i01/Marchionini/. [14] A. K. McCallum. Bow: Un conjunto de herramientas para modelado de lenguaje estadístico, recuperación de texto, clasificación y agrupamiento. http://www.cs.cmu.edu/˜mccallum/bow, 1996. [15] T. Mitchell. Aprendizaje automático. McGraw Hill, 1997. [16] E. Rasmussen. \n\nMcGraw Hill, 1997. [16] E. Rasmussen. Algoritmos de agrupamiento. En W. B. Frakes y R. Baeza-Yates, editores, Recuperación de Información: Estructuras de Datos y Algoritmos, páginas 419-442. Prentice Hall, 1992. [17] R. Tibshirani, G. Walther y T. Hastie. Estimando el número de grupos en un conjunto de datos a través de la estadística de brecha, 2000. http://citeseer.nj.nec.com/tibshirani00estimating.html. [18] V. N. Vapnik. La naturaleza de la teoría del aprendizaje estadístico. Springer, 2000. 159\n\nSpringer, 2000. 159 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}