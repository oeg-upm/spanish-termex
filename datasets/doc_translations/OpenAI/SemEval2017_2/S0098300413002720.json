{
    "id": "S0098300413002720",
    "original_text": "Artificial Neural Networks (ANN) have been widely used in science and engineering problems. They attempt to model the ability of biological nervous systems to recognize patterns and objects. ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa. Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996). During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error. Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996). We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer.",
    "original_translation": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta.",
    "original_sentences": [
        "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
        "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
        "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
        "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
        "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
        "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
        "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
    ],
    "translated_text_sentences": [
        "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería.",
        "Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos.",
        "La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa.",
        "Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996).",
        "Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error.",
        "La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996).",
        "Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta."
    ],
    "error_count": 1,
    "keys": {
        "adjusted if the separation of inputs and predefined classes incurs an error": {
            "translated_key": "los pesos de conexión",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are <br>adjusted if the separation of inputs and predefined classes incurs an error</br>.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "During training network connection weights are <br>adjusted if the separation of inputs and predefined classes incurs an error</br>."
            ],
            "translated_annotated_samples": [
                "Durante el entrenamiento, <br>los pesos de conexión</br> de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, <br>los pesos de conexión</br> de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ANN": {
            "translated_key": "",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (<br>ANN</br>) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "<br>ANN</br> basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "Artificial Neural Networks (<br>ANN</br>) have been widely used in science and engineering problems.",
                "<br>ANN</br> basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "Las <br>Redes Neuronales Artificiales</br> (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería.",
                "La arquitectura básica de las ANN consiste en <br>redes de funciones primitivas</br> capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Las <br>Redes Neuronales Artificiales</br> (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en <br>redes de funciones primitivas</br> capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    "Redes Neuronales Artificiales",
                    "redes de funciones primitivas"
                ]
            ]
        },
        "ANN basic architecture": {
            "translated_key": "arquitectura básica de las ANN",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "<br>ANN basic architecture</br> consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>ANN basic architecture</br> consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "La <br>arquitectura básica de las ANN</br> consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La <br>arquitectura básica de las ANN</br> consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Artificial Neural Networks": {
            "translated_key": "Redes Neuronales Artificiales",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>Artificial Neural Networks</br> (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>Artificial Neural Networks</br> (ANN) have been widely used in science and engineering problems."
            ],
            "translated_annotated_samples": [
                "Las <br>Redes Neuronales Artificiales</br> (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería."
            ],
            "translated_text": "Las <br>Redes Neuronales Artificiales</br> (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Convergence": {
            "translated_key": "convergencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "<br>Convergence</br> proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>Convergence</br> proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_annotated_samples": [
                "La <br>convergencia</br> continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La <br>convergencia</br> continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Different types of primitive functions and network configurations": {
            "translated_key": "funciones primitivas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "<br>Different types of primitive functions and network configurations</br> result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>Different types of primitive functions and network configurations</br> result in varying models (Hastie et al., 2009; Rojas, 1996)."
            ],
            "translated_annotated_samples": [
                "Diferentes tipos de <br>funciones primitivas</br> y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996)."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de <br>funciones primitivas</br> y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "feed-forward networks with a single hidden layer of nodes": {
            "translated_key": "Perceptrón Multicapa",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use <br>feed-forward networks with a single hidden layer of nodes</br>, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use <br>feed-forward networks with a single hidden layer of nodes</br>, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas <br>Perceptrón Multicapa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas <br>Perceptrón Multicapa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "MLP": {
            "translated_key": "Perceptrón Multicapa",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (<br>MLP</br>) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (<br>MLP</br>) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas <br>Perceptrón Multicapa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas <br>Perceptrón Multicapa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "model the ability of biological nervous systems to recognize patterns and objects": {
            "translated_key": "modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to <br>model the ability of biological nervous systems to recognize patterns and objects</br>.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "They attempt to <br>model the ability of biological nervous systems to recognize patterns and objects</br>."
            ],
            "translated_annotated_samples": [
                "Intentan <br>modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos</br>."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan <br>modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos</br>. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Multi-Layer Perceptron": {
            "translated_key": "Perceptrón Multicapa",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called <br>Multi-Layer Perceptron</br> (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use feed-forward networks with a single hidden layer of nodes, a so called <br>Multi-Layer Perceptron</br> (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas <br>Perceptrón Multicapa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas <br>Perceptrón Multicapa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "networks of primitive functions": {
            "translated_key": "redes de funciones primitivas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of <br>networks of primitive functions</br> capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "ANN basic architecture consists of <br>networks of primitive functions</br> capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "La arquitectura básica de las ANN consiste en <br>redes de funciones primitivas</br> capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en <br>redes de funciones primitivas</br> capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "receiving multiple weighted inputs": {
            "translated_key": "entradas ponderadas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of <br>receiving multiple weighted inputs</br> that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "ANN basic architecture consists of networks of primitive functions capable of <br>receiving multiple weighted inputs</br> that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples <br>entradas ponderadas</br> que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples <br>entradas ponderadas</br> que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "science and engineering problems": {
            "translated_key": "ciencia e ingeniería",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in <br>science and engineering problems</br>.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "Artificial Neural Networks (ANN) have been widely used in <br>science and engineering problems</br>."
            ],
            "translated_annotated_samples": [
                "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de <br>ciencia e ingeniería</br>."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de <br>ciencia e ingeniería</br>. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "select one of two possible parameters": {
            "translated_key": "número de nodos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and <br>select one of two possible parameters</br>: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and <br>select one of two possible parameters</br>: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el <br>número de nodos</br> en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el <br>número de nodos</br> en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "the reduction in error between iterations reaches a decay threshold": {
            "translated_key": "umbral de decaimiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until <br>the reduction in error between iterations reaches a decay threshold</br> (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "Convergence proceeds until <br>the reduction in error between iterations reaches a decay threshold</br> (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_annotated_samples": [
                "La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un <br>umbral de decaimiento</br> (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un <br>umbral de decaimiento</br> (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "training network connection": {
            "translated_key": "pesos de conexión de la red",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During <br>training network connection</br> weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "During <br>training network connection</br> weights are adjusted if the separation of inputs and predefined classes incurs an error."
            ],
            "translated_annotated_samples": [
                "Durante el entrenamiento, los <br>pesos de conexión de la red</br> se ajustan si la separación de las entradas y las clases predefinidas incurre en un error."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los <br>pesos de conexión de la red</br> se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "weights": {
            "translated_key": "pesos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection <br>weights</br> are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "During training network connection <br>weights</br> are adjusted if the separation of inputs and predefined classes incurs an error."
            ],
            "translated_annotated_samples": [
                "Durante el entrenamiento, los <br>pesos</br> de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (ANN) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los <br>pesos</br> de conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de alimentación directa con una sola capa oculta de nodos, llamadas Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}